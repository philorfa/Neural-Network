{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# A.           Στοιχεία Ομάδας\n\n> ### ΟΜΑΔΑ A5\n\n> Αριστείδης Μπακούρος 03113138\n\n> Ορφανουδάκης Φίλιππος 03113140\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# B.  Εισαγωγή του dataset"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Αρχικά κάνουμε upgrade στις βιβλοθήκες που θα χρειαστούμε"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "!pip install --upgrade pip #upgrade pip package installer\n!pip install scikit-learn --upgrade #upgrade scikit-learn package\n!pip install numpy --upgrade #upgrade numpy package\n!pip install pandas --upgrade #upgrade pandas package",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already up-to-date: pip in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (18.1)\nRequirement already up-to-date: scikit-learn in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (0.20.1)\nRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from scikit-learn) (1.15.4)\nRequirement already satisfied, skipping upgrade: scipy>=0.13.3 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from scikit-learn) (1.1.0)\nRequirement already up-to-date: numpy in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (1.15.4)\nRequirement already up-to-date: pandas in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (0.23.4)\nRequirement already satisfied, skipping upgrade: numpy>=1.9.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from pandas) (1.15.4)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from pandas) (2.7.5)\nRequirement already satisfied, skipping upgrade: pytz>=2011k in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from pandas) (2018.7)\nRequirement already satisfied, skipping upgrade: six>=1.5 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Ύστερα αρχιζουμε να μελετάμε το dataset μας το οποίο αντιστοιχεί στο S06 και ονομάζεται Japanese Credit Screening , αλλά καθώς ανοίγουμε τις πληροφορίες του δηλαδή το Data folder και παρατηρήσουμε με ποιό dataset θα δουλέψουμε καταλήγουμε ότι ονομάζεται Credit Approval.\n\nΗ πληροφορία που μεταφέρει αυτο το dataset με λίγα λόγια ειναι η εξής , αιτήσεις για δάνεια και αν τελικά έγιναν δεκτές ή όχι.\nΠιο συγκεκριμένα έχουμε 690 αιτήσεις - instances κάθε μια διαθέτει 15 κρυπτογραφημένα χαρακτηριστικά - attributes (για προστασία των προσωπικών δεδομένων) για τον αιτουντα και ένα έξτρα χαρακτηριστικό το οποίο εκφράζει αν τελικά πήρε έγκριση (+) ή όχι (-).\nΑυτό μας οδηγεί και στο συμπέρασμα ότι έχουμε 2 κλάσεις στο dataset μας.\n\nΆλλες πληροφορίες που παίρνουμε είναι ότι : \n   * Εχουμε 37 περιπτώσεις με απουσιάζουσες τιμές το οποίο αντιστοιχεί στο 5% του dataset μας\n   * Το dataset μας είναι ισορροπημένο καθώς έχουμε συχνότητα εμφάνισης   + -> 307 (44.5%) και   - -> 383 (55.5%)\n   * Διαθέτουμε attributes κατηγορικά, μη διατεταγμένα αλλα και διατεταγμένα οπως φαινεται παρακάτω :\n    \n A1:\tb, a.\n \n A2:\tcontinuous.\n \n A3:\tcontinuous.\n \n A4:\tu, y, l, t.\n \n A5:\tg, p, gg.\n \n A6:\tc, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n \n A7:\tv, h, bb, j, n, z, dd, ff, o.\n \n A8:\tcontinuous.\n \n A9:\tt, f.\n \n A10:\tt, f.\n \n A11:\tcontinuous.\n \n A12:\tt, f.\n \n A13:\tg, p, s.\n \n A14:\tcontinuous.\n \n A15:\tcontinuous."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Για να εισάγουμε το dataset μας κατεβάζουμε το αρχείο crx.data το ανεβάζουμε στο ιδιο directory με αυτό το notebook"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "!ls",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "1.1_Classification.ipynb\t   Lab 6 Clustering exercise solution.ipynb\r\n1.2_Pima_Indians_exercise_A.ipynb  Lab 6 Clustering.ipynb\r\n1.3_Classification.ipynb\t   Lab 7 Text mining exercise.ipynb\r\n2.0 Classification.ipynb\t   Lab_7_Text_Mining.ipynb\r\n2.1_Classification.ipynb\t   mydoc.txt\r\nA5-B12.ipynb\t\t\t   pythoncode.py\r\naskhsh1_small-Copy-Copy.ipynb\t   sample.csv\r\naskhsh1_small-Copy.ipynb\t   Small.ipynb\r\naskhsh1_small.ipynb\t\t   Solution_1.2_Pima_Indians_exercise_Á.ipynb\r\naskhsh1_task_small.ipynb\t   SOM_with_Somoclu.ipynb\r\nClassification_3.ipynb\t\t   task1clone.ipynb\r\ncrx.data\t\t\t   task1.ipynb\r\ndoc.txt\t\t\t\t   task_big.ipynb\r\nexample.csv\t\t\t   task.ipynb\r\ngobig.ipynb\t\t\t   task_small.ipynb\r\nhepatitis.data\t\t\t   temp\r\nisolet1.data\t\t\t   tmp\r\nisolet5.data\t\t\t   Untitled.ipynb\r\nLab_2_Notebooks_intro.ipynb\t   wdbc.data\r\nLab_2_Python_Intro.ipynb\t   wdbc.names\r\nLab_6_Clustering_exercise.ipynb    wpbc.data\r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Διαβάζουμε το dataset μας και επειδή έχουμε ενημερωθεί για τις missing values και οτι μεταφράζονται με ερωτηματικό ? στο dataset , τις αναγνωρίζουμε κατα την ανάγωση ."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\n\ndf = pd.read_csv(\"crx.data\",na_values = [\"?\"])\ndf.head()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>b</th>\n      <th>30.83</th>\n      <th>0</th>\n      <th>u</th>\n      <th>g</th>\n      <th>w</th>\n      <th>v</th>\n      <th>1.25</th>\n      <th>t</th>\n      <th>t.1</th>\n      <th>01</th>\n      <th>f</th>\n      <th>g.1</th>\n      <th>00202</th>\n      <th>0.1</th>\n      <th>+</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>3.04</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>f</td>\n      <td>g</td>\n      <td>43.0</td>\n      <td>560</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>1.50</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>280.0</td>\n      <td>824</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b</td>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.75</td>\n      <td>t</td>\n      <td>t</td>\n      <td>5</td>\n      <td>t</td>\n      <td>g</td>\n      <td>100.0</td>\n      <td>3</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.71</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>s</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b</td>\n      <td>32.08</td>\n      <td>4.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>m</td>\n      <td>v</td>\n      <td>2.50</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>360.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   b  30.83      0  u  g  w  v  1.25  t t.1  01  f g.1  00202  0.1  +\n0  a  58.67  4.460  u  g  q  h  3.04  t   t   6  f   g   43.0  560  +\n1  a  24.50  0.500  u  g  q  h  1.50  t   f   0  f   g  280.0  824  +\n2  b  27.83  1.540  u  g  w  v  3.75  t   t   5  t   g  100.0    3  +\n3  b  20.17  5.625  u  g  w  v  1.71  t   f   0  f   s  120.0    0  +\n4  b  32.08  4.000  u  g  m  v  2.50  t   f   0  t   g  360.0    0  +"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Παρατηρούμε ότι η πρώτη γραμμή δεν ειναι επικεφαλίδα και δεν δίνει κάποια ονομασία στα attributes , αλλά αποτελεί ένα instance οπότε το χρειαζόμαστε . Επίσης βλέπουμε ότι η αρίθμηση γίνεται αριστερά των instances."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = pd.read_csv(\"crx.data\", header=None,na_values = [\"?\"])\ndf.head()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b</td>\n      <td>30.83</td>\n      <td>0.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.25</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>f</td>\n      <td>g</td>\n      <td>202.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>3.04</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>f</td>\n      <td>g</td>\n      <td>43.0</td>\n      <td>560</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>1.50</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>280.0</td>\n      <td>824</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.75</td>\n      <td>t</td>\n      <td>t</td>\n      <td>5</td>\n      <td>t</td>\n      <td>g</td>\n      <td>100.0</td>\n      <td>3</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b</td>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.71</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>s</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  202.0    0  +\n1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g   43.0  560  +\n2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  280.0  824  +\n3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  100.0    3  +\n4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  120.0    0  +"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Έχουμε\", len(df), \"δείγματα\")\nprint(\"Με το καθένα να έχει \", df.shape[1], \"χαρακτηριστικά\")",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Έχουμε 690 δείγματα\nΜε το καθένα να έχει  16 χαρακτηριστικά\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Παρακάτω φαινονται όλα τα instances που διαθέτουν 1 ή παραπανω missing value"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "null_columns=df.columns[df.isnull().any()]\nprint(df[df.isnull().any(axis=1)][null_columns].head(37))",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "      0      1    3    4    5    6       13\n71     b  34.83    u    g    d   bb     NaN\n83     a    NaN    u    g    d    v   300.0\n86     b    NaN    u    g    d    v   928.0\n92     b    NaN    y    p   aa    v     0.0\n97     b    NaN    u    g    c   bb   320.0\n202    b  24.83    u    g    c    v     NaN\n206    a  71.58  NaN  NaN  NaN  NaN     NaN\n243    a  18.75    u    g    q    v     NaN\n248  NaN  24.50    u    g    c   bb    73.0\n254    b    NaN    u    g    k    v   380.0\n270    b  37.58  NaN  NaN  NaN  NaN     NaN\n278    b  24.58    y    p   ff   ff     NaN\n286    a    NaN    u    g   ff   ff   200.0\n327  NaN  40.83    u    g    i   bb  1160.0\n329    b    NaN    y    p    i    v   411.0\n330    b  20.42  NaN  NaN  NaN  NaN     NaN\n346  NaN  32.25    u    g    c    v   372.0\n374  NaN  28.17    u    g   aa    v   260.0\n406    a  40.33    y    p    k    v     NaN\n445    a    NaN    u    g   ff   ff     NaN\n450    b    NaN    y    p    i   bb     0.0\n453  NaN  29.75    u    g    w    v   300.0\n456    b  34.58  NaN  NaN  NaN  NaN     NaN\n479  NaN  26.50    y    p  NaN  NaN    80.0\n489  NaN  45.33    u    g    q    v   263.0\n500    b    NaN    u    g    x    v   290.0\n515    b    NaN    u    g    x    v     0.0\n520  NaN  20.42    u    g    k    v   160.0\n539    b  80.25    u    g  NaN  NaN     0.0\n592    b  23.17  NaN  NaN  NaN  NaN     NaN\n598  NaN  20.08    u    g    q    v   240.0\n601  NaN  42.25    y    p  NaN  NaN   150.0\n608    b    NaN    y    p    d    v   460.0\n622    a  25.58  NaN  NaN  NaN  NaN     NaN\n626    b  22.00    y    p    i   bb     NaN\n641  NaN  33.17    y    p   cc    v   200.0\n673  NaN  29.50    y    p    e    h   256.0\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Και αναλυτικά πόσα attributes έχουν missing values "
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "import numpy as np\n\ndf_1 = pd.read_csv(\"crx.data\",header=None,na_values = [\"?\"])\nnull_columns=df_1.columns[df_1.isnull().any()]\ndf_1[null_columns].isnull().sum()",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "0     12\n1     12\n3      6\n4      6\n5      9\n6      9\n13    13\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print ('Οι απουσιάζουσες τιμές είναι',df_1[null_columns].isnull().sum().sum())",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Οι απουσιάζουσες τιμές είναι 67\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Έχω 67 missing values το οποίο αντιστοιχεί σε 37 attributes δηλαδή το 5% του συνολικού μας dataset , αποτελεί ένα μικρό ποσοστό το οποίο αποφασίζουμε να το χειριστούμε με διαγραφή. "
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "df1=df.dropna()\ndf1",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b</td>\n      <td>30.83</td>\n      <td>0.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.250</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>f</td>\n      <td>g</td>\n      <td>202.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>3.040</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>f</td>\n      <td>g</td>\n      <td>43.0</td>\n      <td>560</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>1.500</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>280.0</td>\n      <td>824</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.750</td>\n      <td>t</td>\n      <td>t</td>\n      <td>5</td>\n      <td>t</td>\n      <td>g</td>\n      <td>100.0</td>\n      <td>3</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b</td>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.710</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>s</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>b</td>\n      <td>32.08</td>\n      <td>4.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>m</td>\n      <td>v</td>\n      <td>2.500</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>360.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>b</td>\n      <td>33.17</td>\n      <td>1.040</td>\n      <td>u</td>\n      <td>g</td>\n      <td>r</td>\n      <td>h</td>\n      <td>6.500</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>164.0</td>\n      <td>31285</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>a</td>\n      <td>22.92</td>\n      <td>11.585</td>\n      <td>u</td>\n      <td>g</td>\n      <td>cc</td>\n      <td>v</td>\n      <td>0.040</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>80.0</td>\n      <td>1349</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>b</td>\n      <td>54.42</td>\n      <td>0.500</td>\n      <td>y</td>\n      <td>p</td>\n      <td>k</td>\n      <td>h</td>\n      <td>3.960</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>180.0</td>\n      <td>314</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>b</td>\n      <td>42.50</td>\n      <td>4.915</td>\n      <td>y</td>\n      <td>p</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.165</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>52.0</td>\n      <td>1442</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>b</td>\n      <td>22.08</td>\n      <td>0.830</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>h</td>\n      <td>2.165</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>128.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>b</td>\n      <td>29.92</td>\n      <td>1.835</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>h</td>\n      <td>4.335</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>260.0</td>\n      <td>200</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>a</td>\n      <td>38.25</td>\n      <td>6.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>k</td>\n      <td>v</td>\n      <td>1.000</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>b</td>\n      <td>48.08</td>\n      <td>6.040</td>\n      <td>u</td>\n      <td>g</td>\n      <td>k</td>\n      <td>v</td>\n      <td>0.040</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>2690</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>a</td>\n      <td>45.83</td>\n      <td>10.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>v</td>\n      <td>5.000</td>\n      <td>t</td>\n      <td>t</td>\n      <td>7</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>b</td>\n      <td>36.67</td>\n      <td>4.415</td>\n      <td>y</td>\n      <td>p</td>\n      <td>k</td>\n      <td>v</td>\n      <td>0.250</td>\n      <td>t</td>\n      <td>t</td>\n      <td>10</td>\n      <td>t</td>\n      <td>g</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>b</td>\n      <td>28.25</td>\n      <td>0.875</td>\n      <td>u</td>\n      <td>g</td>\n      <td>m</td>\n      <td>v</td>\n      <td>0.960</td>\n      <td>t</td>\n      <td>t</td>\n      <td>3</td>\n      <td>t</td>\n      <td>g</td>\n      <td>396.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>a</td>\n      <td>23.25</td>\n      <td>5.875</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>v</td>\n      <td>3.170</td>\n      <td>t</td>\n      <td>t</td>\n      <td>10</td>\n      <td>f</td>\n      <td>g</td>\n      <td>120.0</td>\n      <td>245</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>b</td>\n      <td>21.83</td>\n      <td>0.250</td>\n      <td>u</td>\n      <td>g</td>\n      <td>d</td>\n      <td>h</td>\n      <td>0.665</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>a</td>\n      <td>19.17</td>\n      <td>8.585</td>\n      <td>u</td>\n      <td>g</td>\n      <td>cc</td>\n      <td>h</td>\n      <td>0.750</td>\n      <td>t</td>\n      <td>t</td>\n      <td>7</td>\n      <td>f</td>\n      <td>g</td>\n      <td>96.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>b</td>\n      <td>25.00</td>\n      <td>11.250</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>2.500</td>\n      <td>t</td>\n      <td>t</td>\n      <td>17</td>\n      <td>f</td>\n      <td>g</td>\n      <td>200.0</td>\n      <td>1208</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>b</td>\n      <td>23.25</td>\n      <td>1.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>0.835</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>s</td>\n      <td>300.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>a</td>\n      <td>47.75</td>\n      <td>8.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>7.875</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>1260</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>a</td>\n      <td>27.42</td>\n      <td>14.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>x</td>\n      <td>h</td>\n      <td>3.085</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>f</td>\n      <td>g</td>\n      <td>120.0</td>\n      <td>11</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>a</td>\n      <td>41.17</td>\n      <td>6.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>v</td>\n      <td>0.500</td>\n      <td>t</td>\n      <td>t</td>\n      <td>3</td>\n      <td>t</td>\n      <td>g</td>\n      <td>145.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>a</td>\n      <td>15.83</td>\n      <td>0.585</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>h</td>\n      <td>1.500</td>\n      <td>t</td>\n      <td>t</td>\n      <td>2</td>\n      <td>f</td>\n      <td>g</td>\n      <td>100.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>a</td>\n      <td>47.00</td>\n      <td>13.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>i</td>\n      <td>bb</td>\n      <td>5.165</td>\n      <td>t</td>\n      <td>t</td>\n      <td>9</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>b</td>\n      <td>56.58</td>\n      <td>18.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>d</td>\n      <td>bb</td>\n      <td>15.000</td>\n      <td>t</td>\n      <td>t</td>\n      <td>17</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>b</td>\n      <td>57.42</td>\n      <td>8.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>e</td>\n      <td>h</td>\n      <td>7.000</td>\n      <td>t</td>\n      <td>t</td>\n      <td>3</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>b</td>\n      <td>42.08</td>\n      <td>1.040</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>5.000</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>t</td>\n      <td>g</td>\n      <td>500.0</td>\n      <td>10000</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>659</th>\n      <td>a</td>\n      <td>28.58</td>\n      <td>3.750</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>0.250</td>\n      <td>f</td>\n      <td>t</td>\n      <td>1</td>\n      <td>t</td>\n      <td>g</td>\n      <td>40.0</td>\n      <td>154</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>660</th>\n      <td>b</td>\n      <td>22.25</td>\n      <td>9.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>aa</td>\n      <td>v</td>\n      <td>0.085</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>661</th>\n      <td>b</td>\n      <td>29.83</td>\n      <td>3.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>0.165</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>216.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>662</th>\n      <td>a</td>\n      <td>23.50</td>\n      <td>1.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>0.875</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>160.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>663</th>\n      <td>b</td>\n      <td>32.08</td>\n      <td>4.000</td>\n      <td>y</td>\n      <td>p</td>\n      <td>cc</td>\n      <td>v</td>\n      <td>1.500</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>664</th>\n      <td>b</td>\n      <td>31.08</td>\n      <td>1.500</td>\n      <td>y</td>\n      <td>p</td>\n      <td>w</td>\n      <td>v</td>\n      <td>0.040</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>s</td>\n      <td>160.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>665</th>\n      <td>b</td>\n      <td>31.83</td>\n      <td>0.040</td>\n      <td>y</td>\n      <td>p</td>\n      <td>m</td>\n      <td>v</td>\n      <td>0.040</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>666</th>\n      <td>a</td>\n      <td>21.75</td>\n      <td>11.750</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>0.250</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>180.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>a</td>\n      <td>17.92</td>\n      <td>0.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>1.750</td>\n      <td>f</td>\n      <td>t</td>\n      <td>1</td>\n      <td>t</td>\n      <td>g</td>\n      <td>80.0</td>\n      <td>5</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>668</th>\n      <td>b</td>\n      <td>30.33</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>d</td>\n      <td>h</td>\n      <td>0.085</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>s</td>\n      <td>252.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>669</th>\n      <td>b</td>\n      <td>51.83</td>\n      <td>2.040</td>\n      <td>y</td>\n      <td>p</td>\n      <td>ff</td>\n      <td>ff</td>\n      <td>1.500</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>120.0</td>\n      <td>1</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>670</th>\n      <td>b</td>\n      <td>47.17</td>\n      <td>5.835</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>5.500</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>465.0</td>\n      <td>150</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>671</th>\n      <td>b</td>\n      <td>25.83</td>\n      <td>12.835</td>\n      <td>u</td>\n      <td>g</td>\n      <td>cc</td>\n      <td>v</td>\n      <td>0.500</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>672</th>\n      <td>a</td>\n      <td>50.25</td>\n      <td>0.835</td>\n      <td>u</td>\n      <td>g</td>\n      <td>aa</td>\n      <td>v</td>\n      <td>0.500</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>240.0</td>\n      <td>117</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>674</th>\n      <td>a</td>\n      <td>37.33</td>\n      <td>2.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>i</td>\n      <td>h</td>\n      <td>0.210</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>260.0</td>\n      <td>246</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>675</th>\n      <td>a</td>\n      <td>41.58</td>\n      <td>1.040</td>\n      <td>u</td>\n      <td>g</td>\n      <td>aa</td>\n      <td>v</td>\n      <td>0.665</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>240.0</td>\n      <td>237</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>676</th>\n      <td>a</td>\n      <td>30.58</td>\n      <td>10.665</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>0.085</td>\n      <td>f</td>\n      <td>t</td>\n      <td>12</td>\n      <td>t</td>\n      <td>g</td>\n      <td>129.0</td>\n      <td>3</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>677</th>\n      <td>b</td>\n      <td>19.42</td>\n      <td>7.250</td>\n      <td>u</td>\n      <td>g</td>\n      <td>m</td>\n      <td>v</td>\n      <td>0.040</td>\n      <td>f</td>\n      <td>t</td>\n      <td>1</td>\n      <td>f</td>\n      <td>g</td>\n      <td>100.0</td>\n      <td>1</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>678</th>\n      <td>a</td>\n      <td>17.92</td>\n      <td>10.210</td>\n      <td>u</td>\n      <td>g</td>\n      <td>ff</td>\n      <td>ff</td>\n      <td>0.000</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>50</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>679</th>\n      <td>a</td>\n      <td>20.08</td>\n      <td>1.250</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>0.000</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>680</th>\n      <td>b</td>\n      <td>19.50</td>\n      <td>0.290</td>\n      <td>u</td>\n      <td>g</td>\n      <td>k</td>\n      <td>v</td>\n      <td>0.290</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>280.0</td>\n      <td>364</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>b</td>\n      <td>27.83</td>\n      <td>1.000</td>\n      <td>y</td>\n      <td>p</td>\n      <td>d</td>\n      <td>h</td>\n      <td>3.000</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>176.0</td>\n      <td>537</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>b</td>\n      <td>17.08</td>\n      <td>3.290</td>\n      <td>u</td>\n      <td>g</td>\n      <td>i</td>\n      <td>v</td>\n      <td>0.335</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>140.0</td>\n      <td>2</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>683</th>\n      <td>b</td>\n      <td>36.42</td>\n      <td>0.750</td>\n      <td>y</td>\n      <td>p</td>\n      <td>d</td>\n      <td>v</td>\n      <td>0.585</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>240.0</td>\n      <td>3</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>684</th>\n      <td>b</td>\n      <td>40.58</td>\n      <td>3.290</td>\n      <td>u</td>\n      <td>g</td>\n      <td>m</td>\n      <td>v</td>\n      <td>3.500</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>s</td>\n      <td>400.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>b</td>\n      <td>21.08</td>\n      <td>10.085</td>\n      <td>y</td>\n      <td>p</td>\n      <td>e</td>\n      <td>h</td>\n      <td>1.250</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>260.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>a</td>\n      <td>22.67</td>\n      <td>0.750</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>2.000</td>\n      <td>f</td>\n      <td>t</td>\n      <td>2</td>\n      <td>t</td>\n      <td>g</td>\n      <td>200.0</td>\n      <td>394</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>a</td>\n      <td>25.25</td>\n      <td>13.500</td>\n      <td>y</td>\n      <td>p</td>\n      <td>ff</td>\n      <td>ff</td>\n      <td>2.000</td>\n      <td>f</td>\n      <td>t</td>\n      <td>1</td>\n      <td>t</td>\n      <td>g</td>\n      <td>200.0</td>\n      <td>1</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>688</th>\n      <td>b</td>\n      <td>17.92</td>\n      <td>0.205</td>\n      <td>u</td>\n      <td>g</td>\n      <td>aa</td>\n      <td>v</td>\n      <td>0.040</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>280.0</td>\n      <td>750</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>689</th>\n      <td>b</td>\n      <td>35.00</td>\n      <td>3.375</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>h</td>\n      <td>8.290</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n  </tbody>\n</table>\n<p>653 rows × 16 columns</p>\n</div>",
            "text/plain": "    0      1       2  3  4   5   6       7  8  9   10 11 12     13     14 15\n0    b  30.83   0.000  u  g   w   v   1.250  t  t   1  f  g  202.0      0  +\n1    a  58.67   4.460  u  g   q   h   3.040  t  t   6  f  g   43.0    560  +\n2    a  24.50   0.500  u  g   q   h   1.500  t  f   0  f  g  280.0    824  +\n3    b  27.83   1.540  u  g   w   v   3.750  t  t   5  t  g  100.0      3  +\n4    b  20.17   5.625  u  g   w   v   1.710  t  f   0  f  s  120.0      0  +\n5    b  32.08   4.000  u  g   m   v   2.500  t  f   0  t  g  360.0      0  +\n6    b  33.17   1.040  u  g   r   h   6.500  t  f   0  t  g  164.0  31285  +\n7    a  22.92  11.585  u  g  cc   v   0.040  t  f   0  f  g   80.0   1349  +\n8    b  54.42   0.500  y  p   k   h   3.960  t  f   0  f  g  180.0    314  +\n9    b  42.50   4.915  y  p   w   v   3.165  t  f   0  t  g   52.0   1442  +\n10   b  22.08   0.830  u  g   c   h   2.165  f  f   0  t  g  128.0      0  +\n11   b  29.92   1.835  u  g   c   h   4.335  t  f   0  f  g  260.0    200  +\n12   a  38.25   6.000  u  g   k   v   1.000  t  f   0  t  g    0.0      0  +\n13   b  48.08   6.040  u  g   k   v   0.040  f  f   0  f  g    0.0   2690  +\n14   a  45.83  10.500  u  g   q   v   5.000  t  t   7  t  g    0.0      0  +\n15   b  36.67   4.415  y  p   k   v   0.250  t  t  10  t  g  320.0      0  +\n16   b  28.25   0.875  u  g   m   v   0.960  t  t   3  t  g  396.0      0  +\n17   a  23.25   5.875  u  g   q   v   3.170  t  t  10  f  g  120.0    245  +\n18   b  21.83   0.250  u  g   d   h   0.665  t  f   0  t  g    0.0      0  +\n19   a  19.17   8.585  u  g  cc   h   0.750  t  t   7  f  g   96.0      0  +\n20   b  25.00  11.250  u  g   c   v   2.500  t  t  17  f  g  200.0   1208  +\n21   b  23.25   1.000  u  g   c   v   0.835  t  f   0  f  s  300.0      0  +\n22   a  47.75   8.000  u  g   c   v   7.875  t  t   6  t  g    0.0   1260  +\n23   a  27.42  14.500  u  g   x   h   3.085  t  t   1  f  g  120.0     11  +\n24   a  41.17   6.500  u  g   q   v   0.500  t  t   3  t  g  145.0      0  +\n25   a  15.83   0.585  u  g   c   h   1.500  t  t   2  f  g  100.0      0  +\n26   a  47.00  13.000  u  g   i  bb   5.165  t  t   9  t  g    0.0      0  +\n27   b  56.58  18.500  u  g   d  bb  15.000  t  t  17  t  g    0.0      0  +\n28   b  57.42   8.500  u  g   e   h   7.000  t  t   3  f  g    0.0      0  +\n29   b  42.08   1.040  u  g   w   v   5.000  t  t   6  t  g  500.0  10000  +\n..  ..    ...     ... .. ..  ..  ..     ... .. ..  .. .. ..    ...    ... ..\n659  a  28.58   3.750  u  g   c   v   0.250  f  t   1  t  g   40.0    154  -\n660  b  22.25   9.000  u  g  aa   v   0.085  f  f   0  f  g    0.0      0  -\n661  b  29.83   3.500  u  g   c   v   0.165  f  f   0  f  g  216.0      0  -\n662  a  23.50   1.500  u  g   w   v   0.875  f  f   0  t  g  160.0      0  -\n663  b  32.08   4.000  y  p  cc   v   1.500  f  f   0  t  g  120.0      0  -\n664  b  31.08   1.500  y  p   w   v   0.040  f  f   0  f  s  160.0      0  -\n665  b  31.83   0.040  y  p   m   v   0.040  f  f   0  f  g    0.0      0  -\n666  a  21.75  11.750  u  g   c   v   0.250  f  f   0  t  g  180.0      0  -\n667  a  17.92   0.540  u  g   c   v   1.750  f  t   1  t  g   80.0      5  -\n668  b  30.33   0.500  u  g   d   h   0.085  f  f   0  t  s  252.0      0  -\n669  b  51.83   2.040  y  p  ff  ff   1.500  f  f   0  f  g  120.0      1  -\n670  b  47.17   5.835  u  g   w   v   5.500  f  f   0  f  g  465.0    150  -\n671  b  25.83  12.835  u  g  cc   v   0.500  f  f   0  f  g    0.0      2  -\n672  a  50.25   0.835  u  g  aa   v   0.500  f  f   0  t  g  240.0    117  -\n674  a  37.33   2.500  u  g   i   h   0.210  f  f   0  f  g  260.0    246  -\n675  a  41.58   1.040  u  g  aa   v   0.665  f  f   0  f  g  240.0    237  -\n676  a  30.58  10.665  u  g   q   h   0.085  f  t  12  t  g  129.0      3  -\n677  b  19.42   7.250  u  g   m   v   0.040  f  t   1  f  g  100.0      1  -\n678  a  17.92  10.210  u  g  ff  ff   0.000  f  f   0  f  g    0.0     50  -\n679  a  20.08   1.250  u  g   c   v   0.000  f  f   0  f  g    0.0      0  -\n680  b  19.50   0.290  u  g   k   v   0.290  f  f   0  f  g  280.0    364  -\n681  b  27.83   1.000  y  p   d   h   3.000  f  f   0  f  g  176.0    537  -\n682  b  17.08   3.290  u  g   i   v   0.335  f  f   0  t  g  140.0      2  -\n683  b  36.42   0.750  y  p   d   v   0.585  f  f   0  f  g  240.0      3  -\n684  b  40.58   3.290  u  g   m   v   3.500  f  f   0  t  s  400.0      0  -\n685  b  21.08  10.085  y  p   e   h   1.250  f  f   0  f  g  260.0      0  -\n686  a  22.67   0.750  u  g   c   v   2.000  f  t   2  t  g  200.0    394  -\n687  a  25.25  13.500  y  p  ff  ff   2.000  f  t   1  t  g  200.0      1  -\n688  b  17.92   0.205  u  g  aa   v   0.040  f  f   0  f  g  280.0    750  -\n689  b  35.00   3.375  u  g   c   h   8.290  f  f   0  t  g    0.0      0  -\n\n[653 rows x 16 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "Πλέον έχουμε 652 instances όπως φαινετα, και αποφασσίζουμε να δώσουμε όνομα σε κάθε χαρακτηριστικό"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df1.columns = [\n  'A1',\n  'A2',\n    'A3',\n    'A4',\n    'A5',\n    'A6',\n    'A7',\n    'A8',\n    'A9',\n    'A10',\n    'A11',\n    'A12',\n    'A13',\n    'A14',\n    'A15',\n    'GRANTED'\n]",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df1",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A1</th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A4</th>\n      <th>A5</th>\n      <th>A6</th>\n      <th>A7</th>\n      <th>A8</th>\n      <th>A9</th>\n      <th>A10</th>\n      <th>A11</th>\n      <th>A12</th>\n      <th>A13</th>\n      <th>A14</th>\n      <th>A15</th>\n      <th>GRANTED</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b</td>\n      <td>30.83</td>\n      <td>0.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.250</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>f</td>\n      <td>g</td>\n      <td>202.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>3.040</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>f</td>\n      <td>g</td>\n      <td>43.0</td>\n      <td>560</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>a</td>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>1.500</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>280.0</td>\n      <td>824</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b</td>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.750</td>\n      <td>t</td>\n      <td>t</td>\n      <td>5</td>\n      <td>t</td>\n      <td>g</td>\n      <td>100.0</td>\n      <td>3</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b</td>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>1.710</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>s</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>b</td>\n      <td>32.08</td>\n      <td>4.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>m</td>\n      <td>v</td>\n      <td>2.500</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>360.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>b</td>\n      <td>33.17</td>\n      <td>1.040</td>\n      <td>u</td>\n      <td>g</td>\n      <td>r</td>\n      <td>h</td>\n      <td>6.500</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>164.0</td>\n      <td>31285</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>a</td>\n      <td>22.92</td>\n      <td>11.585</td>\n      <td>u</td>\n      <td>g</td>\n      <td>cc</td>\n      <td>v</td>\n      <td>0.040</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>80.0</td>\n      <td>1349</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>b</td>\n      <td>54.42</td>\n      <td>0.500</td>\n      <td>y</td>\n      <td>p</td>\n      <td>k</td>\n      <td>h</td>\n      <td>3.960</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>180.0</td>\n      <td>314</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>b</td>\n      <td>42.50</td>\n      <td>4.915</td>\n      <td>y</td>\n      <td>p</td>\n      <td>w</td>\n      <td>v</td>\n      <td>3.165</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>52.0</td>\n      <td>1442</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>b</td>\n      <td>22.08</td>\n      <td>0.830</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>h</td>\n      <td>2.165</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>128.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>b</td>\n      <td>29.92</td>\n      <td>1.835</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>h</td>\n      <td>4.335</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>260.0</td>\n      <td>200</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>a</td>\n      <td>38.25</td>\n      <td>6.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>k</td>\n      <td>v</td>\n      <td>1.000</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>b</td>\n      <td>48.08</td>\n      <td>6.040</td>\n      <td>u</td>\n      <td>g</td>\n      <td>k</td>\n      <td>v</td>\n      <td>0.040</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>2690</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>a</td>\n      <td>45.83</td>\n      <td>10.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>v</td>\n      <td>5.000</td>\n      <td>t</td>\n      <td>t</td>\n      <td>7</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>b</td>\n      <td>36.67</td>\n      <td>4.415</td>\n      <td>y</td>\n      <td>p</td>\n      <td>k</td>\n      <td>v</td>\n      <td>0.250</td>\n      <td>t</td>\n      <td>t</td>\n      <td>10</td>\n      <td>t</td>\n      <td>g</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>b</td>\n      <td>28.25</td>\n      <td>0.875</td>\n      <td>u</td>\n      <td>g</td>\n      <td>m</td>\n      <td>v</td>\n      <td>0.960</td>\n      <td>t</td>\n      <td>t</td>\n      <td>3</td>\n      <td>t</td>\n      <td>g</td>\n      <td>396.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>a</td>\n      <td>23.25</td>\n      <td>5.875</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>v</td>\n      <td>3.170</td>\n      <td>t</td>\n      <td>t</td>\n      <td>10</td>\n      <td>f</td>\n      <td>g</td>\n      <td>120.0</td>\n      <td>245</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>b</td>\n      <td>21.83</td>\n      <td>0.250</td>\n      <td>u</td>\n      <td>g</td>\n      <td>d</td>\n      <td>h</td>\n      <td>0.665</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>a</td>\n      <td>19.17</td>\n      <td>8.585</td>\n      <td>u</td>\n      <td>g</td>\n      <td>cc</td>\n      <td>h</td>\n      <td>0.750</td>\n      <td>t</td>\n      <td>t</td>\n      <td>7</td>\n      <td>f</td>\n      <td>g</td>\n      <td>96.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>b</td>\n      <td>25.00</td>\n      <td>11.250</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>2.500</td>\n      <td>t</td>\n      <td>t</td>\n      <td>17</td>\n      <td>f</td>\n      <td>g</td>\n      <td>200.0</td>\n      <td>1208</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>b</td>\n      <td>23.25</td>\n      <td>1.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>0.835</td>\n      <td>t</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>s</td>\n      <td>300.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>a</td>\n      <td>47.75</td>\n      <td>8.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>7.875</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>1260</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>a</td>\n      <td>27.42</td>\n      <td>14.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>x</td>\n      <td>h</td>\n      <td>3.085</td>\n      <td>t</td>\n      <td>t</td>\n      <td>1</td>\n      <td>f</td>\n      <td>g</td>\n      <td>120.0</td>\n      <td>11</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>a</td>\n      <td>41.17</td>\n      <td>6.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>v</td>\n      <td>0.500</td>\n      <td>t</td>\n      <td>t</td>\n      <td>3</td>\n      <td>t</td>\n      <td>g</td>\n      <td>145.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>a</td>\n      <td>15.83</td>\n      <td>0.585</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>h</td>\n      <td>1.500</td>\n      <td>t</td>\n      <td>t</td>\n      <td>2</td>\n      <td>f</td>\n      <td>g</td>\n      <td>100.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>a</td>\n      <td>47.00</td>\n      <td>13.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>i</td>\n      <td>bb</td>\n      <td>5.165</td>\n      <td>t</td>\n      <td>t</td>\n      <td>9</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>b</td>\n      <td>56.58</td>\n      <td>18.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>d</td>\n      <td>bb</td>\n      <td>15.000</td>\n      <td>t</td>\n      <td>t</td>\n      <td>17</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>b</td>\n      <td>57.42</td>\n      <td>8.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>e</td>\n      <td>h</td>\n      <td>7.000</td>\n      <td>t</td>\n      <td>t</td>\n      <td>3</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>b</td>\n      <td>42.08</td>\n      <td>1.040</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>5.000</td>\n      <td>t</td>\n      <td>t</td>\n      <td>6</td>\n      <td>t</td>\n      <td>g</td>\n      <td>500.0</td>\n      <td>10000</td>\n      <td>+</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>659</th>\n      <td>a</td>\n      <td>28.58</td>\n      <td>3.750</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>0.250</td>\n      <td>f</td>\n      <td>t</td>\n      <td>1</td>\n      <td>t</td>\n      <td>g</td>\n      <td>40.0</td>\n      <td>154</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>660</th>\n      <td>b</td>\n      <td>22.25</td>\n      <td>9.000</td>\n      <td>u</td>\n      <td>g</td>\n      <td>aa</td>\n      <td>v</td>\n      <td>0.085</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>661</th>\n      <td>b</td>\n      <td>29.83</td>\n      <td>3.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>0.165</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>216.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>662</th>\n      <td>a</td>\n      <td>23.50</td>\n      <td>1.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>0.875</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>160.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>663</th>\n      <td>b</td>\n      <td>32.08</td>\n      <td>4.000</td>\n      <td>y</td>\n      <td>p</td>\n      <td>cc</td>\n      <td>v</td>\n      <td>1.500</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>664</th>\n      <td>b</td>\n      <td>31.08</td>\n      <td>1.500</td>\n      <td>y</td>\n      <td>p</td>\n      <td>w</td>\n      <td>v</td>\n      <td>0.040</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>s</td>\n      <td>160.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>665</th>\n      <td>b</td>\n      <td>31.83</td>\n      <td>0.040</td>\n      <td>y</td>\n      <td>p</td>\n      <td>m</td>\n      <td>v</td>\n      <td>0.040</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>666</th>\n      <td>a</td>\n      <td>21.75</td>\n      <td>11.750</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>0.250</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>180.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>a</td>\n      <td>17.92</td>\n      <td>0.540</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>1.750</td>\n      <td>f</td>\n      <td>t</td>\n      <td>1</td>\n      <td>t</td>\n      <td>g</td>\n      <td>80.0</td>\n      <td>5</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>668</th>\n      <td>b</td>\n      <td>30.33</td>\n      <td>0.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>d</td>\n      <td>h</td>\n      <td>0.085</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>s</td>\n      <td>252.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>669</th>\n      <td>b</td>\n      <td>51.83</td>\n      <td>2.040</td>\n      <td>y</td>\n      <td>p</td>\n      <td>ff</td>\n      <td>ff</td>\n      <td>1.500</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>120.0</td>\n      <td>1</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>670</th>\n      <td>b</td>\n      <td>47.17</td>\n      <td>5.835</td>\n      <td>u</td>\n      <td>g</td>\n      <td>w</td>\n      <td>v</td>\n      <td>5.500</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>465.0</td>\n      <td>150</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>671</th>\n      <td>b</td>\n      <td>25.83</td>\n      <td>12.835</td>\n      <td>u</td>\n      <td>g</td>\n      <td>cc</td>\n      <td>v</td>\n      <td>0.500</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>672</th>\n      <td>a</td>\n      <td>50.25</td>\n      <td>0.835</td>\n      <td>u</td>\n      <td>g</td>\n      <td>aa</td>\n      <td>v</td>\n      <td>0.500</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>240.0</td>\n      <td>117</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>674</th>\n      <td>a</td>\n      <td>37.33</td>\n      <td>2.500</td>\n      <td>u</td>\n      <td>g</td>\n      <td>i</td>\n      <td>h</td>\n      <td>0.210</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>260.0</td>\n      <td>246</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>675</th>\n      <td>a</td>\n      <td>41.58</td>\n      <td>1.040</td>\n      <td>u</td>\n      <td>g</td>\n      <td>aa</td>\n      <td>v</td>\n      <td>0.665</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>240.0</td>\n      <td>237</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>676</th>\n      <td>a</td>\n      <td>30.58</td>\n      <td>10.665</td>\n      <td>u</td>\n      <td>g</td>\n      <td>q</td>\n      <td>h</td>\n      <td>0.085</td>\n      <td>f</td>\n      <td>t</td>\n      <td>12</td>\n      <td>t</td>\n      <td>g</td>\n      <td>129.0</td>\n      <td>3</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>677</th>\n      <td>b</td>\n      <td>19.42</td>\n      <td>7.250</td>\n      <td>u</td>\n      <td>g</td>\n      <td>m</td>\n      <td>v</td>\n      <td>0.040</td>\n      <td>f</td>\n      <td>t</td>\n      <td>1</td>\n      <td>f</td>\n      <td>g</td>\n      <td>100.0</td>\n      <td>1</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>678</th>\n      <td>a</td>\n      <td>17.92</td>\n      <td>10.210</td>\n      <td>u</td>\n      <td>g</td>\n      <td>ff</td>\n      <td>ff</td>\n      <td>0.000</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>50</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>679</th>\n      <td>a</td>\n      <td>20.08</td>\n      <td>1.250</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>0.000</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>680</th>\n      <td>b</td>\n      <td>19.50</td>\n      <td>0.290</td>\n      <td>u</td>\n      <td>g</td>\n      <td>k</td>\n      <td>v</td>\n      <td>0.290</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>280.0</td>\n      <td>364</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>b</td>\n      <td>27.83</td>\n      <td>1.000</td>\n      <td>y</td>\n      <td>p</td>\n      <td>d</td>\n      <td>h</td>\n      <td>3.000</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>176.0</td>\n      <td>537</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>b</td>\n      <td>17.08</td>\n      <td>3.290</td>\n      <td>u</td>\n      <td>g</td>\n      <td>i</td>\n      <td>v</td>\n      <td>0.335</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>140.0</td>\n      <td>2</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>683</th>\n      <td>b</td>\n      <td>36.42</td>\n      <td>0.750</td>\n      <td>y</td>\n      <td>p</td>\n      <td>d</td>\n      <td>v</td>\n      <td>0.585</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>240.0</td>\n      <td>3</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>684</th>\n      <td>b</td>\n      <td>40.58</td>\n      <td>3.290</td>\n      <td>u</td>\n      <td>g</td>\n      <td>m</td>\n      <td>v</td>\n      <td>3.500</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>s</td>\n      <td>400.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>b</td>\n      <td>21.08</td>\n      <td>10.085</td>\n      <td>y</td>\n      <td>p</td>\n      <td>e</td>\n      <td>h</td>\n      <td>1.250</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>260.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>a</td>\n      <td>22.67</td>\n      <td>0.750</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>v</td>\n      <td>2.000</td>\n      <td>f</td>\n      <td>t</td>\n      <td>2</td>\n      <td>t</td>\n      <td>g</td>\n      <td>200.0</td>\n      <td>394</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>a</td>\n      <td>25.25</td>\n      <td>13.500</td>\n      <td>y</td>\n      <td>p</td>\n      <td>ff</td>\n      <td>ff</td>\n      <td>2.000</td>\n      <td>f</td>\n      <td>t</td>\n      <td>1</td>\n      <td>t</td>\n      <td>g</td>\n      <td>200.0</td>\n      <td>1</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>688</th>\n      <td>b</td>\n      <td>17.92</td>\n      <td>0.205</td>\n      <td>u</td>\n      <td>g</td>\n      <td>aa</td>\n      <td>v</td>\n      <td>0.040</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>f</td>\n      <td>g</td>\n      <td>280.0</td>\n      <td>750</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>689</th>\n      <td>b</td>\n      <td>35.00</td>\n      <td>3.375</td>\n      <td>u</td>\n      <td>g</td>\n      <td>c</td>\n      <td>h</td>\n      <td>8.290</td>\n      <td>f</td>\n      <td>f</td>\n      <td>0</td>\n      <td>t</td>\n      <td>g</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>-</td>\n    </tr>\n  </tbody>\n</table>\n<p>653 rows × 16 columns</p>\n</div>",
            "text/plain": "    A1     A2      A3 A4 A5  A6  A7      A8 A9 A10  A11 A12 A13    A14    A15  \\\n0    b  30.83   0.000  u  g   w   v   1.250  t   t    1   f   g  202.0      0   \n1    a  58.67   4.460  u  g   q   h   3.040  t   t    6   f   g   43.0    560   \n2    a  24.50   0.500  u  g   q   h   1.500  t   f    0   f   g  280.0    824   \n3    b  27.83   1.540  u  g   w   v   3.750  t   t    5   t   g  100.0      3   \n4    b  20.17   5.625  u  g   w   v   1.710  t   f    0   f   s  120.0      0   \n5    b  32.08   4.000  u  g   m   v   2.500  t   f    0   t   g  360.0      0   \n6    b  33.17   1.040  u  g   r   h   6.500  t   f    0   t   g  164.0  31285   \n7    a  22.92  11.585  u  g  cc   v   0.040  t   f    0   f   g   80.0   1349   \n8    b  54.42   0.500  y  p   k   h   3.960  t   f    0   f   g  180.0    314   \n9    b  42.50   4.915  y  p   w   v   3.165  t   f    0   t   g   52.0   1442   \n10   b  22.08   0.830  u  g   c   h   2.165  f   f    0   t   g  128.0      0   \n11   b  29.92   1.835  u  g   c   h   4.335  t   f    0   f   g  260.0    200   \n12   a  38.25   6.000  u  g   k   v   1.000  t   f    0   t   g    0.0      0   \n13   b  48.08   6.040  u  g   k   v   0.040  f   f    0   f   g    0.0   2690   \n14   a  45.83  10.500  u  g   q   v   5.000  t   t    7   t   g    0.0      0   \n15   b  36.67   4.415  y  p   k   v   0.250  t   t   10   t   g  320.0      0   \n16   b  28.25   0.875  u  g   m   v   0.960  t   t    3   t   g  396.0      0   \n17   a  23.25   5.875  u  g   q   v   3.170  t   t   10   f   g  120.0    245   \n18   b  21.83   0.250  u  g   d   h   0.665  t   f    0   t   g    0.0      0   \n19   a  19.17   8.585  u  g  cc   h   0.750  t   t    7   f   g   96.0      0   \n20   b  25.00  11.250  u  g   c   v   2.500  t   t   17   f   g  200.0   1208   \n21   b  23.25   1.000  u  g   c   v   0.835  t   f    0   f   s  300.0      0   \n22   a  47.75   8.000  u  g   c   v   7.875  t   t    6   t   g    0.0   1260   \n23   a  27.42  14.500  u  g   x   h   3.085  t   t    1   f   g  120.0     11   \n24   a  41.17   6.500  u  g   q   v   0.500  t   t    3   t   g  145.0      0   \n25   a  15.83   0.585  u  g   c   h   1.500  t   t    2   f   g  100.0      0   \n26   a  47.00  13.000  u  g   i  bb   5.165  t   t    9   t   g    0.0      0   \n27   b  56.58  18.500  u  g   d  bb  15.000  t   t   17   t   g    0.0      0   \n28   b  57.42   8.500  u  g   e   h   7.000  t   t    3   f   g    0.0      0   \n29   b  42.08   1.040  u  g   w   v   5.000  t   t    6   t   g  500.0  10000   \n..  ..    ...     ... .. ..  ..  ..     ... ..  ..  ...  ..  ..    ...    ...   \n659  a  28.58   3.750  u  g   c   v   0.250  f   t    1   t   g   40.0    154   \n660  b  22.25   9.000  u  g  aa   v   0.085  f   f    0   f   g    0.0      0   \n661  b  29.83   3.500  u  g   c   v   0.165  f   f    0   f   g  216.0      0   \n662  a  23.50   1.500  u  g   w   v   0.875  f   f    0   t   g  160.0      0   \n663  b  32.08   4.000  y  p  cc   v   1.500  f   f    0   t   g  120.0      0   \n664  b  31.08   1.500  y  p   w   v   0.040  f   f    0   f   s  160.0      0   \n665  b  31.83   0.040  y  p   m   v   0.040  f   f    0   f   g    0.0      0   \n666  a  21.75  11.750  u  g   c   v   0.250  f   f    0   t   g  180.0      0   \n667  a  17.92   0.540  u  g   c   v   1.750  f   t    1   t   g   80.0      5   \n668  b  30.33   0.500  u  g   d   h   0.085  f   f    0   t   s  252.0      0   \n669  b  51.83   2.040  y  p  ff  ff   1.500  f   f    0   f   g  120.0      1   \n670  b  47.17   5.835  u  g   w   v   5.500  f   f    0   f   g  465.0    150   \n671  b  25.83  12.835  u  g  cc   v   0.500  f   f    0   f   g    0.0      2   \n672  a  50.25   0.835  u  g  aa   v   0.500  f   f    0   t   g  240.0    117   \n674  a  37.33   2.500  u  g   i   h   0.210  f   f    0   f   g  260.0    246   \n675  a  41.58   1.040  u  g  aa   v   0.665  f   f    0   f   g  240.0    237   \n676  a  30.58  10.665  u  g   q   h   0.085  f   t   12   t   g  129.0      3   \n677  b  19.42   7.250  u  g   m   v   0.040  f   t    1   f   g  100.0      1   \n678  a  17.92  10.210  u  g  ff  ff   0.000  f   f    0   f   g    0.0     50   \n679  a  20.08   1.250  u  g   c   v   0.000  f   f    0   f   g    0.0      0   \n680  b  19.50   0.290  u  g   k   v   0.290  f   f    0   f   g  280.0    364   \n681  b  27.83   1.000  y  p   d   h   3.000  f   f    0   f   g  176.0    537   \n682  b  17.08   3.290  u  g   i   v   0.335  f   f    0   t   g  140.0      2   \n683  b  36.42   0.750  y  p   d   v   0.585  f   f    0   f   g  240.0      3   \n684  b  40.58   3.290  u  g   m   v   3.500  f   f    0   t   s  400.0      0   \n685  b  21.08  10.085  y  p   e   h   1.250  f   f    0   f   g  260.0      0   \n686  a  22.67   0.750  u  g   c   v   2.000  f   t    2   t   g  200.0    394   \n687  a  25.25  13.500  y  p  ff  ff   2.000  f   t    1   t   g  200.0      1   \n688  b  17.92   0.205  u  g  aa   v   0.040  f   f    0   f   g  280.0    750   \n689  b  35.00   3.375  u  g   c   h   8.290  f   f    0   t   g    0.0      0   \n\n    GRANTED  \n0         +  \n1         +  \n2         +  \n3         +  \n4         +  \n5         +  \n6         +  \n7         +  \n8         +  \n9         +  \n10        +  \n11        +  \n12        +  \n13        +  \n14        +  \n15        +  \n16        +  \n17        +  \n18        +  \n19        +  \n20        +  \n21        +  \n22        +  \n23        +  \n24        +  \n25        +  \n26        +  \n27        +  \n28        +  \n29        +  \n..      ...  \n659       -  \n660       -  \n661       -  \n662       -  \n663       -  \n664       -  \n665       -  \n666       -  \n667       -  \n668       -  \n669       -  \n670       -  \n671       -  \n672       -  \n674       -  \n675       -  \n676       -  \n677       -  \n678       -  \n679       -  \n680       -  \n681       -  \n682       -  \n683       -  \n684       -  \n685       -  \n686       -  \n687       -  \n688       -  \n689       -  \n\n[653 rows x 16 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Όπως φαίνεται και από τις πληροφορίες του dataset αλλα και απο το ίδιο το dataset έχουμε ορισμένα μη διατεγμένα χαρακτηριστικά, ο τρόπος χειρισμου τους είναι η αύξηση των στηλών και της διαστατικότητας ετσι ώστε να περιγράφονται απόλυτα τα χαρακτηριστικά .\nΑυτο το επιτυγχάνουμε με την get_dummies"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "pd.get_dummies(df1,columns=['A1','A4','A5','A6','A7','A9','A10','A12','A13'])",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A8</th>\n      <th>A11</th>\n      <th>A14</th>\n      <th>A15</th>\n      <th>GRANTED</th>\n      <th>A1_a</th>\n      <th>A1_b</th>\n      <th>A4_l</th>\n      <th>...</th>\n      <th>A7_z</th>\n      <th>A9_f</th>\n      <th>A9_t</th>\n      <th>A10_f</th>\n      <th>A10_t</th>\n      <th>A12_f</th>\n      <th>A12_t</th>\n      <th>A13_g</th>\n      <th>A13_p</th>\n      <th>A13_s</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30.83</td>\n      <td>0.000</td>\n      <td>1.250</td>\n      <td>1</td>\n      <td>202.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>3.040</td>\n      <td>6</td>\n      <td>43.0</td>\n      <td>560</td>\n      <td>+</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>1.500</td>\n      <td>0</td>\n      <td>280.0</td>\n      <td>824</td>\n      <td>+</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>3.750</td>\n      <td>5</td>\n      <td>100.0</td>\n      <td>3</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>1.710</td>\n      <td>0</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>32.08</td>\n      <td>4.000</td>\n      <td>2.500</td>\n      <td>0</td>\n      <td>360.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>33.17</td>\n      <td>1.040</td>\n      <td>6.500</td>\n      <td>0</td>\n      <td>164.0</td>\n      <td>31285</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>22.92</td>\n      <td>11.585</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>80.0</td>\n      <td>1349</td>\n      <td>+</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>54.42</td>\n      <td>0.500</td>\n      <td>3.960</td>\n      <td>0</td>\n      <td>180.0</td>\n      <td>314</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>42.50</td>\n      <td>4.915</td>\n      <td>3.165</td>\n      <td>0</td>\n      <td>52.0</td>\n      <td>1442</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>22.08</td>\n      <td>0.830</td>\n      <td>2.165</td>\n      <td>0</td>\n      <td>128.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>29.92</td>\n      <td>1.835</td>\n      <td>4.335</td>\n      <td>0</td>\n      <td>260.0</td>\n      <td>200</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>38.25</td>\n      <td>6.000</td>\n      <td>1.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>48.08</td>\n      <td>6.040</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2690</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>45.83</td>\n      <td>10.500</td>\n      <td>5.000</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>36.67</td>\n      <td>4.415</td>\n      <td>0.250</td>\n      <td>10</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>28.25</td>\n      <td>0.875</td>\n      <td>0.960</td>\n      <td>3</td>\n      <td>396.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>23.25</td>\n      <td>5.875</td>\n      <td>3.170</td>\n      <td>10</td>\n      <td>120.0</td>\n      <td>245</td>\n      <td>+</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>21.83</td>\n      <td>0.250</td>\n      <td>0.665</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19.17</td>\n      <td>8.585</td>\n      <td>0.750</td>\n      <td>7</td>\n      <td>96.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>25.00</td>\n      <td>11.250</td>\n      <td>2.500</td>\n      <td>17</td>\n      <td>200.0</td>\n      <td>1208</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>23.25</td>\n      <td>1.000</td>\n      <td>0.835</td>\n      <td>0</td>\n      <td>300.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>47.75</td>\n      <td>8.000</td>\n      <td>7.875</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>1260</td>\n      <td>+</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>27.42</td>\n      <td>14.500</td>\n      <td>3.085</td>\n      <td>1</td>\n      <td>120.0</td>\n      <td>11</td>\n      <td>+</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>41.17</td>\n      <td>6.500</td>\n      <td>0.500</td>\n      <td>3</td>\n      <td>145.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>15.83</td>\n      <td>0.585</td>\n      <td>1.500</td>\n      <td>2</td>\n      <td>100.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>47.00</td>\n      <td>13.000</td>\n      <td>5.165</td>\n      <td>9</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>56.58</td>\n      <td>18.500</td>\n      <td>15.000</td>\n      <td>17</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>57.42</td>\n      <td>8.500</td>\n      <td>7.000</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>42.08</td>\n      <td>1.040</td>\n      <td>5.000</td>\n      <td>6</td>\n      <td>500.0</td>\n      <td>10000</td>\n      <td>+</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>659</th>\n      <td>28.58</td>\n      <td>3.750</td>\n      <td>0.250</td>\n      <td>1</td>\n      <td>40.0</td>\n      <td>154</td>\n      <td>-</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>660</th>\n      <td>22.25</td>\n      <td>9.000</td>\n      <td>0.085</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>661</th>\n      <td>29.83</td>\n      <td>3.500</td>\n      <td>0.165</td>\n      <td>0</td>\n      <td>216.0</td>\n      <td>0</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>662</th>\n      <td>23.50</td>\n      <td>1.500</td>\n      <td>0.875</td>\n      <td>0</td>\n      <td>160.0</td>\n      <td>0</td>\n      <td>-</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>663</th>\n      <td>32.08</td>\n      <td>4.000</td>\n      <td>1.500</td>\n      <td>0</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>664</th>\n      <td>31.08</td>\n      <td>1.500</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>160.0</td>\n      <td>0</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>665</th>\n      <td>31.83</td>\n      <td>0.040</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>666</th>\n      <td>21.75</td>\n      <td>11.750</td>\n      <td>0.250</td>\n      <td>0</td>\n      <td>180.0</td>\n      <td>0</td>\n      <td>-</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>17.92</td>\n      <td>0.540</td>\n      <td>1.750</td>\n      <td>1</td>\n      <td>80.0</td>\n      <td>5</td>\n      <td>-</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>668</th>\n      <td>30.33</td>\n      <td>0.500</td>\n      <td>0.085</td>\n      <td>0</td>\n      <td>252.0</td>\n      <td>0</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>669</th>\n      <td>51.83</td>\n      <td>2.040</td>\n      <td>1.500</td>\n      <td>0</td>\n      <td>120.0</td>\n      <td>1</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>670</th>\n      <td>47.17</td>\n      <td>5.835</td>\n      <td>5.500</td>\n      <td>0</td>\n      <td>465.0</td>\n      <td>150</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>671</th>\n      <td>25.83</td>\n      <td>12.835</td>\n      <td>0.500</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>672</th>\n      <td>50.25</td>\n      <td>0.835</td>\n      <td>0.500</td>\n      <td>0</td>\n      <td>240.0</td>\n      <td>117</td>\n      <td>-</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>674</th>\n      <td>37.33</td>\n      <td>2.500</td>\n      <td>0.210</td>\n      <td>0</td>\n      <td>260.0</td>\n      <td>246</td>\n      <td>-</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>675</th>\n      <td>41.58</td>\n      <td>1.040</td>\n      <td>0.665</td>\n      <td>0</td>\n      <td>240.0</td>\n      <td>237</td>\n      <td>-</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>676</th>\n      <td>30.58</td>\n      <td>10.665</td>\n      <td>0.085</td>\n      <td>12</td>\n      <td>129.0</td>\n      <td>3</td>\n      <td>-</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>677</th>\n      <td>19.42</td>\n      <td>7.250</td>\n      <td>0.040</td>\n      <td>1</td>\n      <td>100.0</td>\n      <td>1</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>678</th>\n      <td>17.92</td>\n      <td>10.210</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>50</td>\n      <td>-</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>679</th>\n      <td>20.08</td>\n      <td>1.250</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>-</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>680</th>\n      <td>19.50</td>\n      <td>0.290</td>\n      <td>0.290</td>\n      <td>0</td>\n      <td>280.0</td>\n      <td>364</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>27.83</td>\n      <td>1.000</td>\n      <td>3.000</td>\n      <td>0</td>\n      <td>176.0</td>\n      <td>537</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>17.08</td>\n      <td>3.290</td>\n      <td>0.335</td>\n      <td>0</td>\n      <td>140.0</td>\n      <td>2</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>683</th>\n      <td>36.42</td>\n      <td>0.750</td>\n      <td>0.585</td>\n      <td>0</td>\n      <td>240.0</td>\n      <td>3</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>684</th>\n      <td>40.58</td>\n      <td>3.290</td>\n      <td>3.500</td>\n      <td>0</td>\n      <td>400.0</td>\n      <td>0</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>21.08</td>\n      <td>10.085</td>\n      <td>1.250</td>\n      <td>0</td>\n      <td>260.0</td>\n      <td>0</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>22.67</td>\n      <td>0.750</td>\n      <td>2.000</td>\n      <td>2</td>\n      <td>200.0</td>\n      <td>394</td>\n      <td>-</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>25.25</td>\n      <td>13.500</td>\n      <td>2.000</td>\n      <td>1</td>\n      <td>200.0</td>\n      <td>1</td>\n      <td>-</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>688</th>\n      <td>17.92</td>\n      <td>0.205</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>280.0</td>\n      <td>750</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>689</th>\n      <td>35.00</td>\n      <td>3.375</td>\n      <td>8.290</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>-</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>653 rows × 47 columns</p>\n</div>",
            "text/plain": "        A2      A3      A8  A11    A14    A15 GRANTED  A1_a  A1_b  A4_l  \\\n0    30.83   0.000   1.250    1  202.0      0       +     0     1     0   \n1    58.67   4.460   3.040    6   43.0    560       +     1     0     0   \n2    24.50   0.500   1.500    0  280.0    824       +     1     0     0   \n3    27.83   1.540   3.750    5  100.0      3       +     0     1     0   \n4    20.17   5.625   1.710    0  120.0      0       +     0     1     0   \n5    32.08   4.000   2.500    0  360.0      0       +     0     1     0   \n6    33.17   1.040   6.500    0  164.0  31285       +     0     1     0   \n7    22.92  11.585   0.040    0   80.0   1349       +     1     0     0   \n8    54.42   0.500   3.960    0  180.0    314       +     0     1     0   \n9    42.50   4.915   3.165    0   52.0   1442       +     0     1     0   \n10   22.08   0.830   2.165    0  128.0      0       +     0     1     0   \n11   29.92   1.835   4.335    0  260.0    200       +     0     1     0   \n12   38.25   6.000   1.000    0    0.0      0       +     1     0     0   \n13   48.08   6.040   0.040    0    0.0   2690       +     0     1     0   \n14   45.83  10.500   5.000    7    0.0      0       +     1     0     0   \n15   36.67   4.415   0.250   10  320.0      0       +     0     1     0   \n16   28.25   0.875   0.960    3  396.0      0       +     0     1     0   \n17   23.25   5.875   3.170   10  120.0    245       +     1     0     0   \n18   21.83   0.250   0.665    0    0.0      0       +     0     1     0   \n19   19.17   8.585   0.750    7   96.0      0       +     1     0     0   \n20   25.00  11.250   2.500   17  200.0   1208       +     0     1     0   \n21   23.25   1.000   0.835    0  300.0      0       +     0     1     0   \n22   47.75   8.000   7.875    6    0.0   1260       +     1     0     0   \n23   27.42  14.500   3.085    1  120.0     11       +     1     0     0   \n24   41.17   6.500   0.500    3  145.0      0       +     1     0     0   \n25   15.83   0.585   1.500    2  100.0      0       +     1     0     0   \n26   47.00  13.000   5.165    9    0.0      0       +     1     0     0   \n27   56.58  18.500  15.000   17    0.0      0       +     0     1     0   \n28   57.42   8.500   7.000    3    0.0      0       +     0     1     0   \n29   42.08   1.040   5.000    6  500.0  10000       +     0     1     0   \n..     ...     ...     ...  ...    ...    ...     ...   ...   ...   ...   \n659  28.58   3.750   0.250    1   40.0    154       -     1     0     0   \n660  22.25   9.000   0.085    0    0.0      0       -     0     1     0   \n661  29.83   3.500   0.165    0  216.0      0       -     0     1     0   \n662  23.50   1.500   0.875    0  160.0      0       -     1     0     0   \n663  32.08   4.000   1.500    0  120.0      0       -     0     1     0   \n664  31.08   1.500   0.040    0  160.0      0       -     0     1     0   \n665  31.83   0.040   0.040    0    0.0      0       -     0     1     0   \n666  21.75  11.750   0.250    0  180.0      0       -     1     0     0   \n667  17.92   0.540   1.750    1   80.0      5       -     1     0     0   \n668  30.33   0.500   0.085    0  252.0      0       -     0     1     0   \n669  51.83   2.040   1.500    0  120.0      1       -     0     1     0   \n670  47.17   5.835   5.500    0  465.0    150       -     0     1     0   \n671  25.83  12.835   0.500    0    0.0      2       -     0     1     0   \n672  50.25   0.835   0.500    0  240.0    117       -     1     0     0   \n674  37.33   2.500   0.210    0  260.0    246       -     1     0     0   \n675  41.58   1.040   0.665    0  240.0    237       -     1     0     0   \n676  30.58  10.665   0.085   12  129.0      3       -     1     0     0   \n677  19.42   7.250   0.040    1  100.0      1       -     0     1     0   \n678  17.92  10.210   0.000    0    0.0     50       -     1     0     0   \n679  20.08   1.250   0.000    0    0.0      0       -     1     0     0   \n680  19.50   0.290   0.290    0  280.0    364       -     0     1     0   \n681  27.83   1.000   3.000    0  176.0    537       -     0     1     0   \n682  17.08   3.290   0.335    0  140.0      2       -     0     1     0   \n683  36.42   0.750   0.585    0  240.0      3       -     0     1     0   \n684  40.58   3.290   3.500    0  400.0      0       -     0     1     0   \n685  21.08  10.085   1.250    0  260.0      0       -     0     1     0   \n686  22.67   0.750   2.000    2  200.0    394       -     1     0     0   \n687  25.25  13.500   2.000    1  200.0      1       -     1     0     0   \n688  17.92   0.205   0.040    0  280.0    750       -     0     1     0   \n689  35.00   3.375   8.290    0    0.0      0       -     0     1     0   \n\n     ...    A7_z  A9_f  A9_t  A10_f  A10_t  A12_f  A12_t  A13_g  A13_p  A13_s  \n0    ...       0     0     1      0      1      1      0      1      0      0  \n1    ...       0     0     1      0      1      1      0      1      0      0  \n2    ...       0     0     1      1      0      1      0      1      0      0  \n3    ...       0     0     1      0      1      0      1      1      0      0  \n4    ...       0     0     1      1      0      1      0      0      0      1  \n5    ...       0     0     1      1      0      0      1      1      0      0  \n6    ...       0     0     1      1      0      0      1      1      0      0  \n7    ...       0     0     1      1      0      1      0      1      0      0  \n8    ...       0     0     1      1      0      1      0      1      0      0  \n9    ...       0     0     1      1      0      0      1      1      0      0  \n10   ...       0     1     0      1      0      0      1      1      0      0  \n11   ...       0     0     1      1      0      1      0      1      0      0  \n12   ...       0     0     1      1      0      0      1      1      0      0  \n13   ...       0     1     0      1      0      1      0      1      0      0  \n14   ...       0     0     1      0      1      0      1      1      0      0  \n15   ...       0     0     1      0      1      0      1      1      0      0  \n16   ...       0     0     1      0      1      0      1      1      0      0  \n17   ...       0     0     1      0      1      1      0      1      0      0  \n18   ...       0     0     1      1      0      0      1      1      0      0  \n19   ...       0     0     1      0      1      1      0      1      0      0  \n20   ...       0     0     1      0      1      1      0      1      0      0  \n21   ...       0     0     1      1      0      1      0      0      0      1  \n22   ...       0     0     1      0      1      0      1      1      0      0  \n23   ...       0     0     1      0      1      1      0      1      0      0  \n24   ...       0     0     1      0      1      0      1      1      0      0  \n25   ...       0     0     1      0      1      1      0      1      0      0  \n26   ...       0     0     1      0      1      0      1      1      0      0  \n27   ...       0     0     1      0      1      0      1      1      0      0  \n28   ...       0     0     1      0      1      1      0      1      0      0  \n29   ...       0     0     1      0      1      0      1      1      0      0  \n..   ...     ...   ...   ...    ...    ...    ...    ...    ...    ...    ...  \n659  ...       0     1     0      0      1      0      1      1      0      0  \n660  ...       0     1     0      1      0      1      0      1      0      0  \n661  ...       0     1     0      1      0      1      0      1      0      0  \n662  ...       0     1     0      1      0      0      1      1      0      0  \n663  ...       0     1     0      1      0      0      1      1      0      0  \n664  ...       0     1     0      1      0      1      0      0      0      1  \n665  ...       0     1     0      1      0      1      0      1      0      0  \n666  ...       0     1     0      1      0      0      1      1      0      0  \n667  ...       0     1     0      0      1      0      1      1      0      0  \n668  ...       0     1     0      1      0      0      1      0      0      1  \n669  ...       0     1     0      1      0      1      0      1      0      0  \n670  ...       0     1     0      1      0      1      0      1      0      0  \n671  ...       0     1     0      1      0      1      0      1      0      0  \n672  ...       0     1     0      1      0      0      1      1      0      0  \n674  ...       0     1     0      1      0      1      0      1      0      0  \n675  ...       0     1     0      1      0      1      0      1      0      0  \n676  ...       0     1     0      0      1      0      1      1      0      0  \n677  ...       0     1     0      0      1      1      0      1      0      0  \n678  ...       0     1     0      1      0      1      0      1      0      0  \n679  ...       0     1     0      1      0      1      0      1      0      0  \n680  ...       0     1     0      1      0      1      0      1      0      0  \n681  ...       0     1     0      1      0      1      0      1      0      0  \n682  ...       0     1     0      1      0      0      1      1      0      0  \n683  ...       0     1     0      1      0      1      0      1      0      0  \n684  ...       0     1     0      1      0      0      1      0      0      1  \n685  ...       0     1     0      1      0      1      0      1      0      0  \n686  ...       0     1     0      0      1      0      1      1      0      0  \n687  ...       0     1     0      0      1      0      1      1      0      0  \n688  ...       0     1     0      1      0      1      0      1      0      0  \n689  ...       0     1     0      1      0      0      1      1      0      0  \n\n[653 rows x 47 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Έτσι καταλήγουμε σε 47 στήλες\n\nΣτη συνέχεια θέλουμε να αντιμετωπίσουμε την binary class μας , και αυτο που κάνουμε είναι η αραιή-sparse αναπαράσταση με 0 όσες αιτήσεις απορρίφθηκαν και 1 όσες αιτήσεις έγιναν δεκτές.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df2=pd.get_dummies(df1,columns=['A1','A4','A5','A6','A7','A9','A10','A12','A13'])\ndf3=df2\ndf3.loc[df3.GRANTED != '+', 'GRANTED'] = 0\ndf3.loc[df3.GRANTED == '+', 'GRANTED'] = 1",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df3",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A8</th>\n      <th>A11</th>\n      <th>A14</th>\n      <th>A15</th>\n      <th>GRANTED</th>\n      <th>A1_a</th>\n      <th>A1_b</th>\n      <th>A4_l</th>\n      <th>...</th>\n      <th>A7_z</th>\n      <th>A9_f</th>\n      <th>A9_t</th>\n      <th>A10_f</th>\n      <th>A10_t</th>\n      <th>A12_f</th>\n      <th>A12_t</th>\n      <th>A13_g</th>\n      <th>A13_p</th>\n      <th>A13_s</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30.83</td>\n      <td>0.000</td>\n      <td>1.250</td>\n      <td>1</td>\n      <td>202.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>3.040</td>\n      <td>6</td>\n      <td>43.0</td>\n      <td>560</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>1.500</td>\n      <td>0</td>\n      <td>280.0</td>\n      <td>824</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>3.750</td>\n      <td>5</td>\n      <td>100.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>1.710</td>\n      <td>0</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>32.08</td>\n      <td>4.000</td>\n      <td>2.500</td>\n      <td>0</td>\n      <td>360.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>33.17</td>\n      <td>1.040</td>\n      <td>6.500</td>\n      <td>0</td>\n      <td>164.0</td>\n      <td>31285</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>22.92</td>\n      <td>11.585</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>80.0</td>\n      <td>1349</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>54.42</td>\n      <td>0.500</td>\n      <td>3.960</td>\n      <td>0</td>\n      <td>180.0</td>\n      <td>314</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>42.50</td>\n      <td>4.915</td>\n      <td>3.165</td>\n      <td>0</td>\n      <td>52.0</td>\n      <td>1442</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>22.08</td>\n      <td>0.830</td>\n      <td>2.165</td>\n      <td>0</td>\n      <td>128.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>29.92</td>\n      <td>1.835</td>\n      <td>4.335</td>\n      <td>0</td>\n      <td>260.0</td>\n      <td>200</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>38.25</td>\n      <td>6.000</td>\n      <td>1.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>48.08</td>\n      <td>6.040</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2690</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>45.83</td>\n      <td>10.500</td>\n      <td>5.000</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>36.67</td>\n      <td>4.415</td>\n      <td>0.250</td>\n      <td>10</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>28.25</td>\n      <td>0.875</td>\n      <td>0.960</td>\n      <td>3</td>\n      <td>396.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>23.25</td>\n      <td>5.875</td>\n      <td>3.170</td>\n      <td>10</td>\n      <td>120.0</td>\n      <td>245</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>21.83</td>\n      <td>0.250</td>\n      <td>0.665</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19.17</td>\n      <td>8.585</td>\n      <td>0.750</td>\n      <td>7</td>\n      <td>96.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>25.00</td>\n      <td>11.250</td>\n      <td>2.500</td>\n      <td>17</td>\n      <td>200.0</td>\n      <td>1208</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>23.25</td>\n      <td>1.000</td>\n      <td>0.835</td>\n      <td>0</td>\n      <td>300.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>47.75</td>\n      <td>8.000</td>\n      <td>7.875</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>1260</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>27.42</td>\n      <td>14.500</td>\n      <td>3.085</td>\n      <td>1</td>\n      <td>120.0</td>\n      <td>11</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>41.17</td>\n      <td>6.500</td>\n      <td>0.500</td>\n      <td>3</td>\n      <td>145.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>15.83</td>\n      <td>0.585</td>\n      <td>1.500</td>\n      <td>2</td>\n      <td>100.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>47.00</td>\n      <td>13.000</td>\n      <td>5.165</td>\n      <td>9</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>56.58</td>\n      <td>18.500</td>\n      <td>15.000</td>\n      <td>17</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>57.42</td>\n      <td>8.500</td>\n      <td>7.000</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>42.08</td>\n      <td>1.040</td>\n      <td>5.000</td>\n      <td>6</td>\n      <td>500.0</td>\n      <td>10000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>659</th>\n      <td>28.58</td>\n      <td>3.750</td>\n      <td>0.250</td>\n      <td>1</td>\n      <td>40.0</td>\n      <td>154</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>660</th>\n      <td>22.25</td>\n      <td>9.000</td>\n      <td>0.085</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>661</th>\n      <td>29.83</td>\n      <td>3.500</td>\n      <td>0.165</td>\n      <td>0</td>\n      <td>216.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>662</th>\n      <td>23.50</td>\n      <td>1.500</td>\n      <td>0.875</td>\n      <td>0</td>\n      <td>160.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>663</th>\n      <td>32.08</td>\n      <td>4.000</td>\n      <td>1.500</td>\n      <td>0</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>664</th>\n      <td>31.08</td>\n      <td>1.500</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>160.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>665</th>\n      <td>31.83</td>\n      <td>0.040</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>666</th>\n      <td>21.75</td>\n      <td>11.750</td>\n      <td>0.250</td>\n      <td>0</td>\n      <td>180.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>17.92</td>\n      <td>0.540</td>\n      <td>1.750</td>\n      <td>1</td>\n      <td>80.0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>668</th>\n      <td>30.33</td>\n      <td>0.500</td>\n      <td>0.085</td>\n      <td>0</td>\n      <td>252.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>669</th>\n      <td>51.83</td>\n      <td>2.040</td>\n      <td>1.500</td>\n      <td>0</td>\n      <td>120.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>670</th>\n      <td>47.17</td>\n      <td>5.835</td>\n      <td>5.500</td>\n      <td>0</td>\n      <td>465.0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>671</th>\n      <td>25.83</td>\n      <td>12.835</td>\n      <td>0.500</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>672</th>\n      <td>50.25</td>\n      <td>0.835</td>\n      <td>0.500</td>\n      <td>0</td>\n      <td>240.0</td>\n      <td>117</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>674</th>\n      <td>37.33</td>\n      <td>2.500</td>\n      <td>0.210</td>\n      <td>0</td>\n      <td>260.0</td>\n      <td>246</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>675</th>\n      <td>41.58</td>\n      <td>1.040</td>\n      <td>0.665</td>\n      <td>0</td>\n      <td>240.0</td>\n      <td>237</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>676</th>\n      <td>30.58</td>\n      <td>10.665</td>\n      <td>0.085</td>\n      <td>12</td>\n      <td>129.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>677</th>\n      <td>19.42</td>\n      <td>7.250</td>\n      <td>0.040</td>\n      <td>1</td>\n      <td>100.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>678</th>\n      <td>17.92</td>\n      <td>10.210</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>50</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>679</th>\n      <td>20.08</td>\n      <td>1.250</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>680</th>\n      <td>19.50</td>\n      <td>0.290</td>\n      <td>0.290</td>\n      <td>0</td>\n      <td>280.0</td>\n      <td>364</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>27.83</td>\n      <td>1.000</td>\n      <td>3.000</td>\n      <td>0</td>\n      <td>176.0</td>\n      <td>537</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>17.08</td>\n      <td>3.290</td>\n      <td>0.335</td>\n      <td>0</td>\n      <td>140.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>683</th>\n      <td>36.42</td>\n      <td>0.750</td>\n      <td>0.585</td>\n      <td>0</td>\n      <td>240.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>684</th>\n      <td>40.58</td>\n      <td>3.290</td>\n      <td>3.500</td>\n      <td>0</td>\n      <td>400.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>21.08</td>\n      <td>10.085</td>\n      <td>1.250</td>\n      <td>0</td>\n      <td>260.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>22.67</td>\n      <td>0.750</td>\n      <td>2.000</td>\n      <td>2</td>\n      <td>200.0</td>\n      <td>394</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>25.25</td>\n      <td>13.500</td>\n      <td>2.000</td>\n      <td>1</td>\n      <td>200.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>688</th>\n      <td>17.92</td>\n      <td>0.205</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>280.0</td>\n      <td>750</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>689</th>\n      <td>35.00</td>\n      <td>3.375</td>\n      <td>8.290</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>653 rows × 47 columns</p>\n</div>",
            "text/plain": "        A2      A3      A8  A11    A14    A15  GRANTED  A1_a  A1_b  A4_l  \\\n0    30.83   0.000   1.250    1  202.0      0        1     0     1     0   \n1    58.67   4.460   3.040    6   43.0    560        1     1     0     0   \n2    24.50   0.500   1.500    0  280.0    824        1     1     0     0   \n3    27.83   1.540   3.750    5  100.0      3        1     0     1     0   \n4    20.17   5.625   1.710    0  120.0      0        1     0     1     0   \n5    32.08   4.000   2.500    0  360.0      0        1     0     1     0   \n6    33.17   1.040   6.500    0  164.0  31285        1     0     1     0   \n7    22.92  11.585   0.040    0   80.0   1349        1     1     0     0   \n8    54.42   0.500   3.960    0  180.0    314        1     0     1     0   \n9    42.50   4.915   3.165    0   52.0   1442        1     0     1     0   \n10   22.08   0.830   2.165    0  128.0      0        1     0     1     0   \n11   29.92   1.835   4.335    0  260.0    200        1     0     1     0   \n12   38.25   6.000   1.000    0    0.0      0        1     1     0     0   \n13   48.08   6.040   0.040    0    0.0   2690        1     0     1     0   \n14   45.83  10.500   5.000    7    0.0      0        1     1     0     0   \n15   36.67   4.415   0.250   10  320.0      0        1     0     1     0   \n16   28.25   0.875   0.960    3  396.0      0        1     0     1     0   \n17   23.25   5.875   3.170   10  120.0    245        1     1     0     0   \n18   21.83   0.250   0.665    0    0.0      0        1     0     1     0   \n19   19.17   8.585   0.750    7   96.0      0        1     1     0     0   \n20   25.00  11.250   2.500   17  200.0   1208        1     0     1     0   \n21   23.25   1.000   0.835    0  300.0      0        1     0     1     0   \n22   47.75   8.000   7.875    6    0.0   1260        1     1     0     0   \n23   27.42  14.500   3.085    1  120.0     11        1     1     0     0   \n24   41.17   6.500   0.500    3  145.0      0        1     1     0     0   \n25   15.83   0.585   1.500    2  100.0      0        1     1     0     0   \n26   47.00  13.000   5.165    9    0.0      0        1     1     0     0   \n27   56.58  18.500  15.000   17    0.0      0        1     0     1     0   \n28   57.42   8.500   7.000    3    0.0      0        1     0     1     0   \n29   42.08   1.040   5.000    6  500.0  10000        1     0     1     0   \n..     ...     ...     ...  ...    ...    ...      ...   ...   ...   ...   \n659  28.58   3.750   0.250    1   40.0    154        0     1     0     0   \n660  22.25   9.000   0.085    0    0.0      0        0     0     1     0   \n661  29.83   3.500   0.165    0  216.0      0        0     0     1     0   \n662  23.50   1.500   0.875    0  160.0      0        0     1     0     0   \n663  32.08   4.000   1.500    0  120.0      0        0     0     1     0   \n664  31.08   1.500   0.040    0  160.0      0        0     0     1     0   \n665  31.83   0.040   0.040    0    0.0      0        0     0     1     0   \n666  21.75  11.750   0.250    0  180.0      0        0     1     0     0   \n667  17.92   0.540   1.750    1   80.0      5        0     1     0     0   \n668  30.33   0.500   0.085    0  252.0      0        0     0     1     0   \n669  51.83   2.040   1.500    0  120.0      1        0     0     1     0   \n670  47.17   5.835   5.500    0  465.0    150        0     0     1     0   \n671  25.83  12.835   0.500    0    0.0      2        0     0     1     0   \n672  50.25   0.835   0.500    0  240.0    117        0     1     0     0   \n674  37.33   2.500   0.210    0  260.0    246        0     1     0     0   \n675  41.58   1.040   0.665    0  240.0    237        0     1     0     0   \n676  30.58  10.665   0.085   12  129.0      3        0     1     0     0   \n677  19.42   7.250   0.040    1  100.0      1        0     0     1     0   \n678  17.92  10.210   0.000    0    0.0     50        0     1     0     0   \n679  20.08   1.250   0.000    0    0.0      0        0     1     0     0   \n680  19.50   0.290   0.290    0  280.0    364        0     0     1     0   \n681  27.83   1.000   3.000    0  176.0    537        0     0     1     0   \n682  17.08   3.290   0.335    0  140.0      2        0     0     1     0   \n683  36.42   0.750   0.585    0  240.0      3        0     0     1     0   \n684  40.58   3.290   3.500    0  400.0      0        0     0     1     0   \n685  21.08  10.085   1.250    0  260.0      0        0     0     1     0   \n686  22.67   0.750   2.000    2  200.0    394        0     1     0     0   \n687  25.25  13.500   2.000    1  200.0      1        0     1     0     0   \n688  17.92   0.205   0.040    0  280.0    750        0     0     1     0   \n689  35.00   3.375   8.290    0    0.0      0        0     0     1     0   \n\n     ...    A7_z  A9_f  A9_t  A10_f  A10_t  A12_f  A12_t  A13_g  A13_p  A13_s  \n0    ...       0     0     1      0      1      1      0      1      0      0  \n1    ...       0     0     1      0      1      1      0      1      0      0  \n2    ...       0     0     1      1      0      1      0      1      0      0  \n3    ...       0     0     1      0      1      0      1      1      0      0  \n4    ...       0     0     1      1      0      1      0      0      0      1  \n5    ...       0     0     1      1      0      0      1      1      0      0  \n6    ...       0     0     1      1      0      0      1      1      0      0  \n7    ...       0     0     1      1      0      1      0      1      0      0  \n8    ...       0     0     1      1      0      1      0      1      0      0  \n9    ...       0     0     1      1      0      0      1      1      0      0  \n10   ...       0     1     0      1      0      0      1      1      0      0  \n11   ...       0     0     1      1      0      1      0      1      0      0  \n12   ...       0     0     1      1      0      0      1      1      0      0  \n13   ...       0     1     0      1      0      1      0      1      0      0  \n14   ...       0     0     1      0      1      0      1      1      0      0  \n15   ...       0     0     1      0      1      0      1      1      0      0  \n16   ...       0     0     1      0      1      0      1      1      0      0  \n17   ...       0     0     1      0      1      1      0      1      0      0  \n18   ...       0     0     1      1      0      0      1      1      0      0  \n19   ...       0     0     1      0      1      1      0      1      0      0  \n20   ...       0     0     1      0      1      1      0      1      0      0  \n21   ...       0     0     1      1      0      1      0      0      0      1  \n22   ...       0     0     1      0      1      0      1      1      0      0  \n23   ...       0     0     1      0      1      1      0      1      0      0  \n24   ...       0     0     1      0      1      0      1      1      0      0  \n25   ...       0     0     1      0      1      1      0      1      0      0  \n26   ...       0     0     1      0      1      0      1      1      0      0  \n27   ...       0     0     1      0      1      0      1      1      0      0  \n28   ...       0     0     1      0      1      1      0      1      0      0  \n29   ...       0     0     1      0      1      0      1      1      0      0  \n..   ...     ...   ...   ...    ...    ...    ...    ...    ...    ...    ...  \n659  ...       0     1     0      0      1      0      1      1      0      0  \n660  ...       0     1     0      1      0      1      0      1      0      0  \n661  ...       0     1     0      1      0      1      0      1      0      0  \n662  ...       0     1     0      1      0      0      1      1      0      0  \n663  ...       0     1     0      1      0      0      1      1      0      0  \n664  ...       0     1     0      1      0      1      0      0      0      1  \n665  ...       0     1     0      1      0      1      0      1      0      0  \n666  ...       0     1     0      1      0      0      1      1      0      0  \n667  ...       0     1     0      0      1      0      1      1      0      0  \n668  ...       0     1     0      1      0      0      1      0      0      1  \n669  ...       0     1     0      1      0      1      0      1      0      0  \n670  ...       0     1     0      1      0      1      0      1      0      0  \n671  ...       0     1     0      1      0      1      0      1      0      0  \n672  ...       0     1     0      1      0      0      1      1      0      0  \n674  ...       0     1     0      1      0      1      0      1      0      0  \n675  ...       0     1     0      1      0      1      0      1      0      0  \n676  ...       0     1     0      0      1      0      1      1      0      0  \n677  ...       0     1     0      0      1      1      0      1      0      0  \n678  ...       0     1     0      1      0      1      0      1      0      0  \n679  ...       0     1     0      1      0      1      0      1      0      0  \n680  ...       0     1     0      1      0      1      0      1      0      0  \n681  ...       0     1     0      1      0      1      0      1      0      0  \n682  ...       0     1     0      1      0      0      1      1      0      0  \n683  ...       0     1     0      1      0      1      0      1      0      0  \n684  ...       0     1     0      1      0      0      1      0      0      1  \n685  ...       0     1     0      1      0      1      0      1      0      0  \n686  ...       0     1     0      0      1      0      1      1      0      0  \n687  ...       0     1     0      0      1      0      1      1      0      0  \n688  ...       0     1     0      1      0      1      0      1      0      0  \n689  ...       0     1     0      1      0      0      1      1      0      0  \n\n[653 rows x 47 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Στη συνέχεια παρατηρύμε οτι η στήλη GRANTED ουσιαστικά αποτελεί την έξοδο μας , βρίσκεται στη μέση και μας δυσκολευει , για διευκόλυνση ορίζουμε ξανά το dataset και την βάζουμε στο τέλος"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cols = list(df3.columns.values) \ncols.pop(cols.index('GRANTED')) \ndf4 = df3[cols+['GRANTED']] ",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df4",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A2</th>\n      <th>A3</th>\n      <th>A8</th>\n      <th>A11</th>\n      <th>A14</th>\n      <th>A15</th>\n      <th>A1_a</th>\n      <th>A1_b</th>\n      <th>A4_l</th>\n      <th>A4_u</th>\n      <th>...</th>\n      <th>A9_f</th>\n      <th>A9_t</th>\n      <th>A10_f</th>\n      <th>A10_t</th>\n      <th>A12_f</th>\n      <th>A12_t</th>\n      <th>A13_g</th>\n      <th>A13_p</th>\n      <th>A13_s</th>\n      <th>GRANTED</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30.83</td>\n      <td>0.000</td>\n      <td>1.250</td>\n      <td>1</td>\n      <td>202.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>58.67</td>\n      <td>4.460</td>\n      <td>3.040</td>\n      <td>6</td>\n      <td>43.0</td>\n      <td>560</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24.50</td>\n      <td>0.500</td>\n      <td>1.500</td>\n      <td>0</td>\n      <td>280.0</td>\n      <td>824</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>27.83</td>\n      <td>1.540</td>\n      <td>3.750</td>\n      <td>5</td>\n      <td>100.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20.17</td>\n      <td>5.625</td>\n      <td>1.710</td>\n      <td>0</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>32.08</td>\n      <td>4.000</td>\n      <td>2.500</td>\n      <td>0</td>\n      <td>360.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>33.17</td>\n      <td>1.040</td>\n      <td>6.500</td>\n      <td>0</td>\n      <td>164.0</td>\n      <td>31285</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>22.92</td>\n      <td>11.585</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>80.0</td>\n      <td>1349</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>54.42</td>\n      <td>0.500</td>\n      <td>3.960</td>\n      <td>0</td>\n      <td>180.0</td>\n      <td>314</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>42.50</td>\n      <td>4.915</td>\n      <td>3.165</td>\n      <td>0</td>\n      <td>52.0</td>\n      <td>1442</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>22.08</td>\n      <td>0.830</td>\n      <td>2.165</td>\n      <td>0</td>\n      <td>128.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>29.92</td>\n      <td>1.835</td>\n      <td>4.335</td>\n      <td>0</td>\n      <td>260.0</td>\n      <td>200</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>38.25</td>\n      <td>6.000</td>\n      <td>1.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>48.08</td>\n      <td>6.040</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2690</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>45.83</td>\n      <td>10.500</td>\n      <td>5.000</td>\n      <td>7</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>36.67</td>\n      <td>4.415</td>\n      <td>0.250</td>\n      <td>10</td>\n      <td>320.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>28.25</td>\n      <td>0.875</td>\n      <td>0.960</td>\n      <td>3</td>\n      <td>396.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>23.25</td>\n      <td>5.875</td>\n      <td>3.170</td>\n      <td>10</td>\n      <td>120.0</td>\n      <td>245</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>21.83</td>\n      <td>0.250</td>\n      <td>0.665</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19.17</td>\n      <td>8.585</td>\n      <td>0.750</td>\n      <td>7</td>\n      <td>96.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>25.00</td>\n      <td>11.250</td>\n      <td>2.500</td>\n      <td>17</td>\n      <td>200.0</td>\n      <td>1208</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>23.25</td>\n      <td>1.000</td>\n      <td>0.835</td>\n      <td>0</td>\n      <td>300.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>47.75</td>\n      <td>8.000</td>\n      <td>7.875</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>1260</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>27.42</td>\n      <td>14.500</td>\n      <td>3.085</td>\n      <td>1</td>\n      <td>120.0</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>41.17</td>\n      <td>6.500</td>\n      <td>0.500</td>\n      <td>3</td>\n      <td>145.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>15.83</td>\n      <td>0.585</td>\n      <td>1.500</td>\n      <td>2</td>\n      <td>100.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>47.00</td>\n      <td>13.000</td>\n      <td>5.165</td>\n      <td>9</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>56.58</td>\n      <td>18.500</td>\n      <td>15.000</td>\n      <td>17</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>57.42</td>\n      <td>8.500</td>\n      <td>7.000</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>42.08</td>\n      <td>1.040</td>\n      <td>5.000</td>\n      <td>6</td>\n      <td>500.0</td>\n      <td>10000</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>659</th>\n      <td>28.58</td>\n      <td>3.750</td>\n      <td>0.250</td>\n      <td>1</td>\n      <td>40.0</td>\n      <td>154</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>660</th>\n      <td>22.25</td>\n      <td>9.000</td>\n      <td>0.085</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>661</th>\n      <td>29.83</td>\n      <td>3.500</td>\n      <td>0.165</td>\n      <td>0</td>\n      <td>216.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>662</th>\n      <td>23.50</td>\n      <td>1.500</td>\n      <td>0.875</td>\n      <td>0</td>\n      <td>160.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>663</th>\n      <td>32.08</td>\n      <td>4.000</td>\n      <td>1.500</td>\n      <td>0</td>\n      <td>120.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>664</th>\n      <td>31.08</td>\n      <td>1.500</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>160.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>665</th>\n      <td>31.83</td>\n      <td>0.040</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>666</th>\n      <td>21.75</td>\n      <td>11.750</td>\n      <td>0.250</td>\n      <td>0</td>\n      <td>180.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>17.92</td>\n      <td>0.540</td>\n      <td>1.750</td>\n      <td>1</td>\n      <td>80.0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>668</th>\n      <td>30.33</td>\n      <td>0.500</td>\n      <td>0.085</td>\n      <td>0</td>\n      <td>252.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>669</th>\n      <td>51.83</td>\n      <td>2.040</td>\n      <td>1.500</td>\n      <td>0</td>\n      <td>120.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>670</th>\n      <td>47.17</td>\n      <td>5.835</td>\n      <td>5.500</td>\n      <td>0</td>\n      <td>465.0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>671</th>\n      <td>25.83</td>\n      <td>12.835</td>\n      <td>0.500</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>672</th>\n      <td>50.25</td>\n      <td>0.835</td>\n      <td>0.500</td>\n      <td>0</td>\n      <td>240.0</td>\n      <td>117</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>674</th>\n      <td>37.33</td>\n      <td>2.500</td>\n      <td>0.210</td>\n      <td>0</td>\n      <td>260.0</td>\n      <td>246</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>675</th>\n      <td>41.58</td>\n      <td>1.040</td>\n      <td>0.665</td>\n      <td>0</td>\n      <td>240.0</td>\n      <td>237</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>676</th>\n      <td>30.58</td>\n      <td>10.665</td>\n      <td>0.085</td>\n      <td>12</td>\n      <td>129.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>677</th>\n      <td>19.42</td>\n      <td>7.250</td>\n      <td>0.040</td>\n      <td>1</td>\n      <td>100.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>678</th>\n      <td>17.92</td>\n      <td>10.210</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>50</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>679</th>\n      <td>20.08</td>\n      <td>1.250</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>680</th>\n      <td>19.50</td>\n      <td>0.290</td>\n      <td>0.290</td>\n      <td>0</td>\n      <td>280.0</td>\n      <td>364</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>681</th>\n      <td>27.83</td>\n      <td>1.000</td>\n      <td>3.000</td>\n      <td>0</td>\n      <td>176.0</td>\n      <td>537</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>682</th>\n      <td>17.08</td>\n      <td>3.290</td>\n      <td>0.335</td>\n      <td>0</td>\n      <td>140.0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>683</th>\n      <td>36.42</td>\n      <td>0.750</td>\n      <td>0.585</td>\n      <td>0</td>\n      <td>240.0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>684</th>\n      <td>40.58</td>\n      <td>3.290</td>\n      <td>3.500</td>\n      <td>0</td>\n      <td>400.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>685</th>\n      <td>21.08</td>\n      <td>10.085</td>\n      <td>1.250</td>\n      <td>0</td>\n      <td>260.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>686</th>\n      <td>22.67</td>\n      <td>0.750</td>\n      <td>2.000</td>\n      <td>2</td>\n      <td>200.0</td>\n      <td>394</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>687</th>\n      <td>25.25</td>\n      <td>13.500</td>\n      <td>2.000</td>\n      <td>1</td>\n      <td>200.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>688</th>\n      <td>17.92</td>\n      <td>0.205</td>\n      <td>0.040</td>\n      <td>0</td>\n      <td>280.0</td>\n      <td>750</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>689</th>\n      <td>35.00</td>\n      <td>3.375</td>\n      <td>8.290</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>653 rows × 47 columns</p>\n</div>",
            "text/plain": "        A2      A3      A8  A11    A14    A15  A1_a  A1_b  A4_l  A4_u  \\\n0    30.83   0.000   1.250    1  202.0      0     0     1     0     1   \n1    58.67   4.460   3.040    6   43.0    560     1     0     0     1   \n2    24.50   0.500   1.500    0  280.0    824     1     0     0     1   \n3    27.83   1.540   3.750    5  100.0      3     0     1     0     1   \n4    20.17   5.625   1.710    0  120.0      0     0     1     0     1   \n5    32.08   4.000   2.500    0  360.0      0     0     1     0     1   \n6    33.17   1.040   6.500    0  164.0  31285     0     1     0     1   \n7    22.92  11.585   0.040    0   80.0   1349     1     0     0     1   \n8    54.42   0.500   3.960    0  180.0    314     0     1     0     0   \n9    42.50   4.915   3.165    0   52.0   1442     0     1     0     0   \n10   22.08   0.830   2.165    0  128.0      0     0     1     0     1   \n11   29.92   1.835   4.335    0  260.0    200     0     1     0     1   \n12   38.25   6.000   1.000    0    0.0      0     1     0     0     1   \n13   48.08   6.040   0.040    0    0.0   2690     0     1     0     1   \n14   45.83  10.500   5.000    7    0.0      0     1     0     0     1   \n15   36.67   4.415   0.250   10  320.0      0     0     1     0     0   \n16   28.25   0.875   0.960    3  396.0      0     0     1     0     1   \n17   23.25   5.875   3.170   10  120.0    245     1     0     0     1   \n18   21.83   0.250   0.665    0    0.0      0     0     1     0     1   \n19   19.17   8.585   0.750    7   96.0      0     1     0     0     1   \n20   25.00  11.250   2.500   17  200.0   1208     0     1     0     1   \n21   23.25   1.000   0.835    0  300.0      0     0     1     0     1   \n22   47.75   8.000   7.875    6    0.0   1260     1     0     0     1   \n23   27.42  14.500   3.085    1  120.0     11     1     0     0     1   \n24   41.17   6.500   0.500    3  145.0      0     1     0     0     1   \n25   15.83   0.585   1.500    2  100.0      0     1     0     0     1   \n26   47.00  13.000   5.165    9    0.0      0     1     0     0     1   \n27   56.58  18.500  15.000   17    0.0      0     0     1     0     1   \n28   57.42   8.500   7.000    3    0.0      0     0     1     0     1   \n29   42.08   1.040   5.000    6  500.0  10000     0     1     0     1   \n..     ...     ...     ...  ...    ...    ...   ...   ...   ...   ...   \n659  28.58   3.750   0.250    1   40.0    154     1     0     0     1   \n660  22.25   9.000   0.085    0    0.0      0     0     1     0     1   \n661  29.83   3.500   0.165    0  216.0      0     0     1     0     1   \n662  23.50   1.500   0.875    0  160.0      0     1     0     0     1   \n663  32.08   4.000   1.500    0  120.0      0     0     1     0     0   \n664  31.08   1.500   0.040    0  160.0      0     0     1     0     0   \n665  31.83   0.040   0.040    0    0.0      0     0     1     0     0   \n666  21.75  11.750   0.250    0  180.0      0     1     0     0     1   \n667  17.92   0.540   1.750    1   80.0      5     1     0     0     1   \n668  30.33   0.500   0.085    0  252.0      0     0     1     0     1   \n669  51.83   2.040   1.500    0  120.0      1     0     1     0     0   \n670  47.17   5.835   5.500    0  465.0    150     0     1     0     1   \n671  25.83  12.835   0.500    0    0.0      2     0     1     0     1   \n672  50.25   0.835   0.500    0  240.0    117     1     0     0     1   \n674  37.33   2.500   0.210    0  260.0    246     1     0     0     1   \n675  41.58   1.040   0.665    0  240.0    237     1     0     0     1   \n676  30.58  10.665   0.085   12  129.0      3     1     0     0     1   \n677  19.42   7.250   0.040    1  100.0      1     0     1     0     1   \n678  17.92  10.210   0.000    0    0.0     50     1     0     0     1   \n679  20.08   1.250   0.000    0    0.0      0     1     0     0     1   \n680  19.50   0.290   0.290    0  280.0    364     0     1     0     1   \n681  27.83   1.000   3.000    0  176.0    537     0     1     0     0   \n682  17.08   3.290   0.335    0  140.0      2     0     1     0     1   \n683  36.42   0.750   0.585    0  240.0      3     0     1     0     0   \n684  40.58   3.290   3.500    0  400.0      0     0     1     0     1   \n685  21.08  10.085   1.250    0  260.0      0     0     1     0     0   \n686  22.67   0.750   2.000    2  200.0    394     1     0     0     1   \n687  25.25  13.500   2.000    1  200.0      1     1     0     0     0   \n688  17.92   0.205   0.040    0  280.0    750     0     1     0     1   \n689  35.00   3.375   8.290    0    0.0      0     0     1     0     1   \n\n      ...     A9_f  A9_t  A10_f  A10_t  A12_f  A12_t  A13_g  A13_p  A13_s  \\\n0     ...        0     1      0      1      1      0      1      0      0   \n1     ...        0     1      0      1      1      0      1      0      0   \n2     ...        0     1      1      0      1      0      1      0      0   \n3     ...        0     1      0      1      0      1      1      0      0   \n4     ...        0     1      1      0      1      0      0      0      1   \n5     ...        0     1      1      0      0      1      1      0      0   \n6     ...        0     1      1      0      0      1      1      0      0   \n7     ...        0     1      1      0      1      0      1      0      0   \n8     ...        0     1      1      0      1      0      1      0      0   \n9     ...        0     1      1      0      0      1      1      0      0   \n10    ...        1     0      1      0      0      1      1      0      0   \n11    ...        0     1      1      0      1      0      1      0      0   \n12    ...        0     1      1      0      0      1      1      0      0   \n13    ...        1     0      1      0      1      0      1      0      0   \n14    ...        0     1      0      1      0      1      1      0      0   \n15    ...        0     1      0      1      0      1      1      0      0   \n16    ...        0     1      0      1      0      1      1      0      0   \n17    ...        0     1      0      1      1      0      1      0      0   \n18    ...        0     1      1      0      0      1      1      0      0   \n19    ...        0     1      0      1      1      0      1      0      0   \n20    ...        0     1      0      1      1      0      1      0      0   \n21    ...        0     1      1      0      1      0      0      0      1   \n22    ...        0     1      0      1      0      1      1      0      0   \n23    ...        0     1      0      1      1      0      1      0      0   \n24    ...        0     1      0      1      0      1      1      0      0   \n25    ...        0     1      0      1      1      0      1      0      0   \n26    ...        0     1      0      1      0      1      1      0      0   \n27    ...        0     1      0      1      0      1      1      0      0   \n28    ...        0     1      0      1      1      0      1      0      0   \n29    ...        0     1      0      1      0      1      1      0      0   \n..    ...      ...   ...    ...    ...    ...    ...    ...    ...    ...   \n659   ...        1     0      0      1      0      1      1      0      0   \n660   ...        1     0      1      0      1      0      1      0      0   \n661   ...        1     0      1      0      1      0      1      0      0   \n662   ...        1     0      1      0      0      1      1      0      0   \n663   ...        1     0      1      0      0      1      1      0      0   \n664   ...        1     0      1      0      1      0      0      0      1   \n665   ...        1     0      1      0      1      0      1      0      0   \n666   ...        1     0      1      0      0      1      1      0      0   \n667   ...        1     0      0      1      0      1      1      0      0   \n668   ...        1     0      1      0      0      1      0      0      1   \n669   ...        1     0      1      0      1      0      1      0      0   \n670   ...        1     0      1      0      1      0      1      0      0   \n671   ...        1     0      1      0      1      0      1      0      0   \n672   ...        1     0      1      0      0      1      1      0      0   \n674   ...        1     0      1      0      1      0      1      0      0   \n675   ...        1     0      1      0      1      0      1      0      0   \n676   ...        1     0      0      1      0      1      1      0      0   \n677   ...        1     0      0      1      1      0      1      0      0   \n678   ...        1     0      1      0      1      0      1      0      0   \n679   ...        1     0      1      0      1      0      1      0      0   \n680   ...        1     0      1      0      1      0      1      0      0   \n681   ...        1     0      1      0      1      0      1      0      0   \n682   ...        1     0      1      0      0      1      1      0      0   \n683   ...        1     0      1      0      1      0      1      0      0   \n684   ...        1     0      1      0      0      1      0      0      1   \n685   ...        1     0      1      0      1      0      1      0      0   \n686   ...        1     0      0      1      0      1      1      0      0   \n687   ...        1     0      0      1      0      1      1      0      0   \n688   ...        1     0      1      0      1      0      1      0      0   \n689   ...        1     0      1      0      0      1      1      0      0   \n\n     GRANTED  \n0          1  \n1          1  \n2          1  \n3          1  \n4          1  \n5          1  \n6          1  \n7          1  \n8          1  \n9          1  \n10         1  \n11         1  \n12         1  \n13         1  \n14         1  \n15         1  \n16         1  \n17         1  \n18         1  \n19         1  \n20         1  \n21         1  \n22         1  \n23         1  \n24         1  \n25         1  \n26         1  \n27         1  \n28         1  \n29         1  \n..       ...  \n659        0  \n660        0  \n661        0  \n662        0  \n663        0  \n664        0  \n665        0  \n666        0  \n667        0  \n668        0  \n669        0  \n670        0  \n671        0  \n672        0  \n674        0  \n675        0  \n676        0  \n677        0  \n678        0  \n679        0  \n680        0  \n681        0  \n682        0  \n683        0  \n684        0  \n685        0  \n686        0  \n687        0  \n688        0  \n689        0  \n\n[653 rows x 47 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "list(df4)",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "['A2',\n 'A3',\n 'A8',\n 'A11',\n 'A14',\n 'A15',\n 'A1_a',\n 'A1_b',\n 'A4_l',\n 'A4_u',\n 'A4_y',\n 'A5_g',\n 'A5_gg',\n 'A5_p',\n 'A6_aa',\n 'A6_c',\n 'A6_cc',\n 'A6_d',\n 'A6_e',\n 'A6_ff',\n 'A6_i',\n 'A6_j',\n 'A6_k',\n 'A6_m',\n 'A6_q',\n 'A6_r',\n 'A6_w',\n 'A6_x',\n 'A7_bb',\n 'A7_dd',\n 'A7_ff',\n 'A7_h',\n 'A7_j',\n 'A7_n',\n 'A7_o',\n 'A7_v',\n 'A7_z',\n 'A9_f',\n 'A9_t',\n 'A10_f',\n 'A10_t',\n 'A12_f',\n 'A12_t',\n 'A13_g',\n 'A13_p',\n 'A13_s',\n 'GRANTED']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Χωρίζουμε το dataset μας σε labels και features"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "label_names = [\"Not Granted\",\"Granted\"]\nlabels_df = df4.iloc[:,[46]]\n##feature_names = list(df4)\nfeatures_df = df4.iloc[:,:45]",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Μετά την διαγραφή των instances με missing values πάμε να ελέγξουμε πάλι την ισορροπία του δείγματος μας"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "labels = labels_df.values.flatten()\nmapping_classes = {0:\"Not_Granted\",1:\"Granted\"}\ndiscrete_classes = list(set(labels))\nfor i in discrete_classes:\n    print ('Εμφανίζεται ποσοστό δειγμάτων %.2f %% για την κλάση %s' % (100.0*sum(labels==i)/len(labels),mapping_classes[i]))\n",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Εμφανίζεται ποσοστό δειγμάτων 54.67 % για την κλάση Not_Granted\nΕμφανίζεται ποσοστό δειγμάτων 45.33 % για την κλάση Granted\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "labels_df_t = df4['GRANTED']\nlabels_df_t = list(map(lambda x : x, labels_df_t))",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "features_df_t=np.asarray(features_df)",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Αφου μετατρέψαμε κατάλληλα το dataset μας και χωρίσαμε σε features και labels είμαστε έτοιμοι να διαχωρίσουμε σε train και test set "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\n\n# Split our data\ntrain, test, train_labels, test_labels = train_test_split(features_df_t, labels_df_t, test_size=0.2,random_state=1)\n",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Γ. Baseline classification"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Θα χρησιμοποιήσουμε τους ταξινομητές kNN και dummy χωρίς καμια βελτιστοποίηση ούτε του dataset ούτε των υπερπαραμέτρων της kNN.\nΠιο συγκεκριμένα στην dummy θα δουλέψουμε όλες τις τακτικές ταξινόμησης που διαθέτει δηλαδή : \n*                                                                                                  uniform\n*                                                                                                  constant 0,1\n*                                                                                                  most frequent\n*                                                                                                  stratified"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.dummy import DummyClassifier",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def function(train_in,train_labels_in,test_in,test_labels_in,fmac,fmic,fwei):\n    credit_accuracy = {}\n\n    dc_uniform = DummyClassifier(strategy=\"uniform\")\n\n# με τη μέθοδο fit \"εκπαιδεύουμε\" τον ταξινομητή στο σύνολο εκπαίδευσης (τα χαρακτηριστικά και τις ετικέτες τους)\n    model = dc_uniform.fit(train_in, train_labels_in)\n\n# με τη μέθοδο predict παράγουμε προβλέψεις για τα δεδομένα ελέγχου (είσοδος τα χαρακτηριστικά μόνο)\n    preds = dc_uniform.predict(test_in)\n\n# υπολογίζουμε την ακρίβεια του συγκεκριμένου μοντέλου dummy classifier\n    credit_accuracy['uniform (random)'] = dc_uniform.score(test_in, test_labels_in)\n\n\n#################\n    print ('Classification report for Dummy Classifier (uniform)')\n    cr_dummy_uni = classification_report(test_labels_in, preds,target_names = label_names)\n    print (cr_dummy_uni)\n\n    scores_weighted = {}\n    scores_macro = {}\n    scores_micro = {}\n\n    scores_weighted['Dummy-Uniform']=precision_recall_fscore_support(test_labels_in,preds,average='weighted')\n    scores_macro['Dummy-Uniform']=precision_recall_fscore_support(test_labels_in,preds,average='macro')\n    scores_micro['Dummy-Uniform']=precision_recall_fscore_support(test_labels_in,preds,average='micro')\n\n\n    print ('Confusion Matrix for Dummy Classifier (uniform)')\n    print (confusion_matrix(test_labels_in, preds))\n\n    acc_dummy_uni = 100*accuracy_score(test_labels_in,preds)\n    print ('Accuracy percentage of this classifier is %.3f %%\\n' % (acc_dummy_uni))\n    \n    fmac[0]=f1_score(test_labels_in,preds,average='macro')\n    fmic[0]=f1_score(test_labels_in,preds,average='micro')\n    fwei[0]=f1_score(test_labels_in,preds,average='weighted')\n    \n    \n    dc_constant_1 = DummyClassifier(strategy=\"constant\", constant=1)\n    model = dc_constant_1.fit(train_in, train_labels_in)\n    preds = dc_constant_1.predict(test_in)\n    credit_accuracy['constant 1'] = dc_constant_1.score(test_in, test_labels_in)\n\n\n#################\n    print ('Classification report for Dummy Classifier (constant-1)')\n    cr_dummy_const1 = classification_report(test_labels_in, preds,target_names = label_names)\n    print (cr_dummy_const1)\n\n    scores_weighted['Dummy-Const1']=precision_recall_fscore_support(test_labels_in,preds,average='weighted')\n    scores_macro['Dummy-Const1']=precision_recall_fscore_support(test_labels_in,preds,average='macro')\n    scores_micro['Dummy-Const1']=precision_recall_fscore_support(test_labels_in,preds,average='micro')\n\n\n    print ('Confusion Matrix for Dummy Classifier (constant-1)')\n    print (confusion_matrix(test_labels_in, preds))\n\n    acc_dummy_const1 = 100*accuracy_score(test_labels_in,preds)\n    print ('Accuracy percentage of this classifier is %.3f %%\\n' % (acc_dummy_const1))\n    \n    fmac[1]=f1_score(test_labels_in,preds,average='macro')\n    fmic[1]=f1_score(test_labels_in,preds,average='micro')\n    fwei[1]=f1_score(test_labels_in,preds,average='weighted')\n    \n    dc_constant_0 = DummyClassifier(strategy=\"constant\", constant=0)\n    model = dc_constant_0.fit(train_in, train_labels_in)\n    preds = dc_constant_0.predict(test_in)\n    credit_accuracy['constant 0'] = dc_constant_0.score(test_in, test_labels_in)\n\n#################\n    print ('Classification report for Dummy Classifier (constant-0)')\n    cr_dummy_const0 = classification_report(test_labels_in, preds,target_names = label_names)\n    print (cr_dummy_const0)\n\n    scores_weighted['Dummy-Const0']=precision_recall_fscore_support(test_labels_in,preds,average='weighted')\n    scores_macro['Dummy-Const0']=precision_recall_fscore_support(test_labels_in,preds,average='macro')\n    scores_micro['Dummy-Const0']=precision_recall_fscore_support(test_labels_in,preds,average='micro')\n\n    print ('Confusion Matrix for Dummy Classifier (constant-0)')\n    print (confusion_matrix(test_labels_in, preds))\n\n    acc_dummy_const0 = 100*accuracy_score(test_labels_in,preds)\n    print ('Accuracy percentage of this classifier is %.3f %%\\n' % (acc_dummy_const0))\n    \n    fmac[2]=f1_score(test_labels_in,preds,average='macro')\n    fmic[2]=f1_score(test_labels_in,preds,average='micro')\n    fwei[2]=f1_score(test_labels_in,preds,average='weighted')\n    \n    dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n    model = dc_most_frequent.fit(train_in, train_labels_in)\n    preds = dc_most_frequent.predict(test_in)\n    credit_accuracy['most_frequent'] = dc_most_frequent.score(test_in, test_labels_in)\n\n#################\n    print ('Classification report for Dummy Classifier (most frequent)')\n    cr_dummy_freq = classification_report(test_labels_in, preds,target_names = label_names)\n    print (cr_dummy_freq)\n\n    scores_weighted['Dummy-Most_Freq']=precision_recall_fscore_support(test_labels_in,preds,average='weighted')\n    scores_macro['Dummy-Most_Freq']=precision_recall_fscore_support(test_labels_in,preds,average='macro')\n    scores_micro['Dummy-Most_Freq']=precision_recall_fscore_support(test_labels_in,preds,average='micro')\n\n    print ('Confusion Matrix for Dummy Classifier (most frequent)')\n    print (confusion_matrix(test_labels_in, preds))\n\n    acc_dummy_freq = 100*accuracy_score(test_labels_in,preds)\n    print ('Accuracy percentage of this classifier is %.3f %%\\n' % (acc_dummy_freq))\n    \n    fmac[3]=f1_score(test_labels_in,preds,average='macro')\n    fmic[3]=f1_score(test_labels_in,preds,average='micro')\n    fwei[3]=f1_score(test_labels_in,preds,average='weighted')\n    \n    \n    \n    dc_stratified = DummyClassifier(strategy=\"stratified\")\n    model = dc_stratified.fit(train_in, train_labels_in)\n    preds = dc_stratified.predict(test_in)\n    credit_accuracy['stratified'] = dc_stratified.score(test_in, test_labels_in)\n\n#################\n    print ('Classification report for Dummy Classifier (stratified)')\n    cr_dummy_strat = classification_report(test_labels_in, preds,target_names = label_names)\n    print (cr_dummy_strat)\n\n    scores_weighted['Dummy-Strat']=precision_recall_fscore_support(test_labels_in,preds,average='weighted')\n    scores_macro['Dummy-Strat']=precision_recall_fscore_support(test_labels_in,preds,average='macro')\n    scores_micro['Dummy-Strat']=precision_recall_fscore_support(test_labels_in,preds,average='macro')\n\n    print ('Confusion Matrix for Dummy Classifier (stratified)')\n    print (confusion_matrix(test_labels_in, preds))\n\n    acc_dummy_strat = 100*accuracy_score(test_labels_in,preds)\n    print ('Accuracy percentage of this classifier is %.3f %%\\n' % (acc_dummy_strat))\n    \n    fmac[4]=f1_score(test_labels_in,preds,average='macro')\n    fmic[4]=f1_score(test_labels_in,preds,average='micro')\n    fwei[4]=f1_score(test_labels_in,preds,average='weighted')\n    \n    from sklearn.neighbors import KNeighborsClassifier\n    knn = KNeighborsClassifier()\n    knn.fit(train_in, train_labels_in)\n    knn_preds = knn.predict(test_in)\n\n\n#################\n    print ('Classification report for kNN')\n    cr_knn_no = classification_report(test_labels_in,knn_preds, target_names=label_names)\n    print (cr_knn_no)\n\n    scores_weighted['kNN-non-opt']=precision_recall_fscore_support(test_labels_in,knn_preds,average='weighted')\n    scores_macro['kNN-non-opt']=precision_recall_fscore_support(test_labels_in,knn_preds,average='macro')\n    scores_micro['kNN-non-opt']=precision_recall_fscore_support(test_labels_in,knn_preds,average='micro')\n\n    print ('Confusion Matrix for non-optimized kNN')\n    print (confusion_matrix(test_labels_in, knn_preds))\n\n    acc_knn_no = 100*accuracy_score(test_labels_in,knn_preds)\n    print ('\\nAccuracy percentage of this classifier is %.3f %%\\n' % (acc_knn_no))\n    \n    fmac[5]=f1_score(test_labels_in,knn_preds,average='macro')\n    fmic[5]=f1_score(test_labels_in,knn_preds,average='micro')\n    fwei[5]=f1_score(test_labels_in,knn_preds,average='weighted')\n    \n    \n    import matplotlib.pyplot as plt\n\n    f1_scores_macro = [item[2] for item in scores_macro.values()]\n    f1_scores_micro = [item[2] for item in scores_micro.values()]\n    f1_scores_weighted = [item[2] for item in scores_weighted.values()]\n\n\n    y_pos = np.arange(len(f1_scores_macro))\n    plt.barh(y_pos, f1_scores_macro, align='center',color='red')\n    plt.yticks(y_pos, scores_macro.keys())\n    plt.title('F1_macro average scores')\n    plt.show()\n\n    y_pos = np.arange(len(f1_scores_micro))\n    plt.barh(y_pos, f1_scores_micro, align='center',color='yellow')\n    plt.yticks(y_pos, scores_micro.keys())\n    plt.title('F1_micro average scores')\n    plt.show()\n\n    \n    y_pos = np.arange(len(f1_scores_weighted))\n    plt.barh(y_pos, f1_scores_weighted, align='center',color='green')\n    plt.yticks(y_pos, scores_weighted.keys())\n    plt.title('F1_weighted average scores')\n    plt.show()\n    \n    \n    return",
      "execution_count": 111,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Έχουμε κατασκευάσει μια συνάρτηση η οποία δέχεται το train, train_labels , test , test labels και εκπαιδεύει τον dummy για κάθε τακτική του και τον kNN που έχει default την υπερπαραπετρο n_neighbors.\n\nΓια κάθε ταξινομήτη εμφανίζεται το classification report του , το confusion matrix του , και το ποσοστό ακρίβειας του.\nΣτο τέλος εμφανίζονται plots που γίνεται συγκριση κάθε τακτικής ταξινομητη για f1_macro avg, f1_micro avg και f1_weighted avg"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "fwei=[0,0,0,0,0,0]\nfmac=[0,0,0,0,0,0]\nfmic=[0,0,0,0,0,0]\nfunction(train,train_labels,test,test_labels,fwei,fmac,fmic)",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Classification report for Dummy Classifier (uniform)\n              precision    recall  f1-score   support\n\n Not Granted       0.58      0.58      0.58        72\n     Granted       0.48      0.47      0.48        59\n\n   micro avg       0.53      0.53      0.53       131\n   macro avg       0.53      0.53      0.53       131\nweighted avg       0.53      0.53      0.53       131\n\nConfusion Matrix for Dummy Classifier (uniform)\n[[42 30]\n [31 28]]\nAccuracy percentage of this classifier is 53.435 %\n\nClassification report for Dummy Classifier (constant-1)\n              precision    recall  f1-score   support\n\n Not Granted       0.00      0.00      0.00        72\n     Granted       0.45      1.00      0.62        59\n\n   micro avg       0.45      0.45      0.45       131\n   macro avg       0.23      0.50      0.31       131\nweighted avg       0.20      0.45      0.28       131\n\nConfusion Matrix for Dummy Classifier (constant-1)\n[[ 0 72]\n [ 0 59]]\nAccuracy percentage of this classifier is 45.038 %\n\nClassification report for Dummy Classifier (constant-0)\n              precision    recall  f1-score   support\n\n Not Granted       0.55      1.00      0.71        72\n     Granted       0.00      0.00      0.00        59\n\n   micro avg       0.55      0.55      0.55       131\n   macro avg       0.27      0.50      0.35       131\nweighted avg       0.30      0.55      0.39       131\n\nConfusion Matrix for Dummy Classifier (constant-0)\n[[72  0]\n [59  0]]\nAccuracy percentage of this classifier is 54.962 %\n\nClassification report for Dummy Classifier (most frequent)\n              precision    recall  f1-score   support\n\n Not Granted       0.55      1.00      0.71        72\n     Granted       0.00      0.00      0.00        59\n\n   micro avg       0.55      0.55      0.55       131\n   macro avg       0.27      0.50      0.35       131\nweighted avg       0.30      0.55      0.39       131\n\nConfusion Matrix for Dummy Classifier (most frequent)\n[[72  0]\n [59  0]]\nAccuracy percentage of this classifier is 54.962 %\n\nClassification report for Dummy Classifier (stratified)\n              precision    recall  f1-score   support\n\n Not Granted       0.51      0.49      0.50        72\n     Granted       0.41      0.44      0.43        59\n\n   micro avg       0.47      0.47      0.47       131\n   macro avg       0.46      0.46      0.46       131\nweighted avg       0.47      0.47      0.47       131\n\nConfusion Matrix for Dummy Classifier (stratified)\n[[35 37]\n [33 26]]\nAccuracy percentage of this classifier is 46.565 %\n\nClassification report for kNN\n              precision    recall  f1-score   support\n\n Not Granted       0.70      0.79      0.75        72\n     Granted       0.70      0.59      0.64        59\n\n   micro avg       0.70      0.70      0.70       131\n   macro avg       0.70      0.69      0.69       131\nweighted avg       0.70      0.70      0.70       131\n\nConfusion Matrix for non-optimized kNN\n[[57 15]\n [24 35]]\n\nAccuracy percentage of this classifier is 70.229 %\n\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n",
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAEICAYAAAAut+/uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3X+cVXW97/HXG9Qg82gmdlNRgrQf/miUEbOsNLXU1KQsf3VsuJ28nqJf5rlZZqZppf3wVpRmniQ9Vnr8FagpaaBFYs3AIKBZCpheu4GkhD9AhM/9Y31Gl+Oe2XuGmb334Pv5eOwHa6/1Xev7WWuGec/3u9eerYjAzMzMYFijCzAzM2sWDkUzM7PkUDQzM0sORTMzs+RQNDMzSw5FMzOz5FA0MzNLDkWzHkhaKulpSU+UHtvltosl3SdpvaS2BpdqZgPEoWjWuyMi4hWlxyO5fj7wcWBuA2urSoWm/H8uaXijaxgokjZpdA02MJryP4tZs4uIH0TEbcDqWveR9BVJ/y3pvyStkrRA0i6SviBpmaSHJL271H6SpHuz7WJJ/6vb8d4nqVPSPyU9IOmQXD9L0rmSZgNPAWMlbSdpmqR/SLpf0sd6qfO9kublcR+S9JXStpslTe7Wfr6k9+fyGyT9Ovu5T9KHSu2mSrpQ0k2SngQO6K2v3OdESQ9KWiHpjBy9H5Tbhkk6Lc99haSrJG3dwzltI+kGSY9nbb/t+mVB0mhJ10panseZUjr+l7L/ZZIuk7RlbhsjKSR9VNJfgd/k+rdI+n32M1/S/qUa2vLruErSEkkn9PQ1sAaKCD/88KPCA1gKHFSlze+AthqP9xWKEH0PsAlwGbAEOB3YFPgYsKTU/r3AOEDAOykCbq/cNgFYCRxM8cvt9sAbctss4K/ArtnPpsDtwA+BEUALsBw4sIc69wd2z+PuAfwdOCq3nQjMLrV9E/A48DJgc+AhYFL2uxfwKLBrtp2aNb8tjz2iSl9vAp4A9gM2A74FrO36mgCfAeYAO2T/PwJ+3sM5fR24KK/FpsDb87oOpxj1X5D1jwD2y33+J3A/MBZ4BXAtcHluGwNEfg03B0bm12AFcFiez8H5fFS2+Sfw+tz/NV3XxY/mejS8AD/8aNYHRSg+kT/0Hweur9Cmr6H469LzI/L4w/P5FvmDdqse9r8e+HQu/wi4oId2s4CzS89HA+uALUrrvg5MrbHu/9PVV9b4JLBTPj8X+EkuHwP8ttu+PwLOzOWpwGV96OvL5ZADXg48UwrFeykFewbNWmCTCsc9G/gl8Lpu6/el+AWh0j63AR8vPX991/FLoTi2tP3zXaFZWncL8JEMxceBDwAjG/297UfPD0+fmvXuqIjYKh9HDcDx/l5afhp4NCLWlZ5DMSpB0qGS5uR03+MUI5Btss1o4IFe+nmotLwd8I+IWFVa9yDFyOZFJO0jaWZOJ64ETu7qN49xI3BsNj8WuCKXdwL2yanDx7PmE4D/0UNdvfaVdT/XPiKeohh5ddkJuK7U170U4f/qCqf1TYpR34ycwjwt148GHoyIZyvssx3FderyIEUglo9fPp+dgA92O//9gNdExJMUvzScDPxN0o2S3lChT2swh6JZE5L0MuAaiinDV0fEVsBNFFN+UPwwHtfLIcoff/MIsLWkLUrrdgT+bw/7/gyYBoyOiC0pph1V2v5z4DhJ+1JMG84s1XR76ZeIraK4Oenfe6irWl9/o5gaBUDSSOBVpX0fAg7t1t+IiHjReUXEqoj4XESMpRihnyLpwDzGjj3cKPMIRdB12RF4lhf+YlM+n4coRorlejaPiG9kDbdExMEUI9o/AT+u0Kc1mEPRrB8kbSZpBMUP8E0ljdDA3uW5GcXrZMuBZyUdCry7tP0/gUmSDswbQrbvaeQREQ8Bvwe+nnXuAXyU50d43W1BMbJcLWkCcHy37TdRhMXZwJURsT7X3wDsIulfJW2aj70lvbGX8+ytr6uBIyS9VdJmwFm8MJwvAs6VtBOApFGS3lepE0mHS3qdJFG8trcuH3+gCN9vSNo8r8/bcrefA5+V9FpJrwC+ludbaVQJ8F9Z73skDc9j7S9pB0mvlnSkpM2BNRTT5ut6OI41kEPRrH9mUEx3vhW4OJffMVAHz2nKTwFXAY9RhMW00vY/UNzQcgHFzSu388JRTXfHUbwO9ghwHcXrfL/uoe3HgbMlraJ4Xe+qbrWtobjp5CCKkV655ndTTKk+Avw/4DyKcO9Jj31FxCLgk8AvKIJrFbCMIlQAvktxTWbk/nOAfXroZ2fgVoowuhP4YUTMyqnrI4DXUdyc9DDFNCfAT4DLgTsobohanfVUlL98vA/4IsUvMw8B/0Hxc3YY8Lm8Lv+guHHq471cF2sQRfhDhs2s+eVo7XFg54hY0uh6bOPkkaKZNS1JR0h6eU47fgtYQHFXsNmgcCiaDSBJv9IL/yxc1+OLja5tiHofxZTjIxRToMeGp7dsEHn61MzMLHmkaGZmlvxHbIeYbbbZJsaMGdPoMszMhpSOjo5HI2JUtXYOxSFmzJgxtLe3N7oMM7MhRdKD1Vt5+tTMzOw5DkUzM7PkUDQzM0sORTMzs+RQNDMzSw5FMzOz5FA0MzNLDkUzM7PkN+8PNR0dIFVvZ2a2ManT3+n2SNHMzCw5FM3MzJJD0czMLDkUzczMkkPRzMwsORTNzMySQ9HMzCw5FM3MzJJD0czMLDkUzczMUlOHoqQxkhZ2W7e/pJB0RGndDZL2z+VZktpL21olzapXzf0haStJH290HWZmL3VNHYq9eBg4vZft20o6tF7FDICtAIeimVmDDZlQlDRW0jxgb2A+sFLSwT00/ybwpRqOOUvSeZL+IOnPkt6e60dIulTSAknzJB2Q69skXSvpZkl/kXR+D8ftbf9f5v73STozd/kGME5Sp6Rv9unCmJnZgBkSn5Ih6fXAL4BJFKOqdwLn5OPXFXa5E5iYYbSqyuE3iYgJkg4DzgQOAj4BEBG7S3oDMEPSLtm+BdgTWAPcJ+n7EfFQt2P2tv8EYDfgKeCPkm4ETgN2i4iWHs7/JOAkgB2rnIyZmfXfUBgpjgJ+CXw4Ijq7VkbEbwG6RncVnEMNo0Xg2vy3AxiTy/sBl2c/fwIeBLpC7baIWBkRq4F7gJ0qHLO3/X8dESsi4unse79qBUbExRHRGhGto2o4ITMz65+hEIorgYeAt1XYdi49vLYYEb8BRgBv6VqXU5qdkm4qNV2T/67j+ZFzbx9YuKa0vA7YRNLEPG6npNYq+3f/ULD6fEiYmZlVNRRC8RngKOBESceXN0TEDOCVwJt72Pdc4H+X2k+KiJaIOKxKn3cAJwDktOeOwH09NY6I6/K4LRHRXmX/gyVtLWlkntdsiineLarUZGZmg2wohCIR8SRwOPBZYMtum88Fduhhv5uA5f3o8ofAcEkLgCuBtohYU2WfWvf/HcXUaidwTUS0R8QKYLakhb7RxsyscRTh2bt6kdQGtEbE5P4eo1WK9urNzMw2LhuYVZI6IqK1WrshMVI0MzOrhyHxloyNRURMBaY2uAwzM+uBR4pmZmbJoWhmZpYcimZmZsmhaGZmlhyKZmZmyaFoZmaW/JaMoWb8eGj32/fNzAaDR4pmZmbJoWhmZpYcimZmZsmhaGZmlhyKZmZmyXefDjUdHSA1ugqzjYc/Ps9KPFI0MzNLDkUzM7PkUDQzM0sORTMzs+RQNDMzSw5FMzOz5FA0MzNLDkUzM7PkUDQzM0sORTMzs9RUoShpnaROSYskzZd0iqSmqhFA0jBJ35O0UNICSX+U9Nrc9sV+HvMzkl4+sJWamVlfNFvgPB0RLRGxK3AwcBhwZoNrquQYYDtgj4jYHZgIPJ7bKoaiCr1d788ADkUzswZqtlB8TkQsA04CJmegtEma0rVd0g2S9s/lJySdJ6lD0q2SJkiaJWmxpCOzTZuk6yVNl7RE0uQcic6TNEfS1pLGSZpb6mNnSR0VynsN8LeIWJ+1PhwRj0n6BjAyR7tXSBoj6V5JPwTmAqMlXSipPUfDZ2U/n6II2ZmSZg7G9TQzs+qaNhQBImIxRY3bVmm6OTArIsYDq4BzKEaaE4GzS+12A44HJgDnAk9FxJ7AncCJEfEAsFJSS7afBEyt0N9VwBEZft+WtGfWexrPj3ZPyLavBy6LiD0j4kHg9IhoBfYA3ilpj4j4HvAIcEBEHNC9M0knZZC2L69yIczMrP+aOhRTLZ+T9Axwcy4vAG6PiLW5PKbUbmZErIqI5cBKYHppn652lwCTJA2nmCb9WffOIuJhirD7ArAeuE3SgT3U9mBEzCk9/1CORucBuwJvqnZyEXFxRLRGROuoao3NzKzfmjoUJY0F1gHLgGd5Yb0jSstrI577ULT1wBqAnN4sf2bkmtLy+tLzcrtrgEOBw4GOiFghaZ8cFXZ2TcdGxJqI+FVE/AfwNeCoHk7jydL5vBY4FTgwIvYAbux2HmZm1kBNG4qSRgEXAVMy8JYCLXnn52iKKdABFxGrgVuAC4FLc91dOSXaEhHTJO0labuscxjFVOiDeYi1kjbt4fD/QhGSKyW9miJ8u6wCthj4MzIzs1ptUr1JXY2U1AlsSjEyvBz4Tm6bDSyhmOpcSHHjymC5Ang/MKOH7dsCP5b0snz+B6DrJqCLgbtzivT08k4RMV/SPGARsJjinCjt9ytJf6v0uqKZmQ0+PT/raF0knQpsGRFnNLqW7lqlaG90EWYbE/8MfEmQ1JE3Ofaq2UaKDSfpOmAc8K5G12JmZvXlUOwmIiY2ugYzM2uMpr3RxszMrN4cimZmZsmhaGZmlhyKZmZmyaFoZmaWHIpmZmbJb8kYasaPh3a/fd/MbDB4pGhmZpYcimZmZsmhaGZmlhyKZmZmyaFoZmaWfPfpUNPRAVKjqzDzRy7ZRskjRTMzs+RQNDMzSw5FMzOz5FA0MzNLDkUzM7PkUDQzM0sORTMzs+RQNDMzSw5FMzOz5FA0MzNLDkUzM7NUNRQlrZPUKWmRpPmSTpHUdGEqaYykkPTV0rptJK2VNKUfx2uRdFiVNm2Sluf16ZR0WX9qNzOz5lBLuD0dES0RsStwMHAYcObgltVvi4HDS88/CCzq57FaKM61mivz+rRExIndN0ryH103Mxsi+jTii4hlwEnAZBXayqMwSTdI2j+Xn5B0nqQOSbdKmiBplqTFko7MNm2Srpc0XdISSZNzJDpP0hxJW0saJ2luqY+dJXX0UOLTwL2SWvP5McBVpX13knSbpLvz3x1z/QclLcyR8B2SNgPOBo7JEeAxfblOeZ5fk3Q78GlJoyRdI+mP+XhbtnuVpBl5vj+S9KCkbSoc7yRJ7ZLal/elEDMz65M+T4NGxOLcb9sqTTcHZkXEeGAVcA7FSHMiReB02Q04HpgAnAs8FRF7AncCJ0bEA8BKSS3ZfhIwtZd+fwEcK2kHYB3wSGnbFOCyiNgDuAL4Xq7/MvCeiHgzcGREPJPrukaBV/bSX1dwdkqaVFq/VUS8MyK+DXwXuCAi9gY+AFySbc4EfpfnOw3YsVIHEXFxRLRGROuoXgoxM7MN09+pvVo+0O8Z4OZcXgCsiYi1khYAY0rtZkbEKmCVpJXA9NI+e+TyJcAkSadQjP4m9NLvzcBXgb8D3cNsX+D9uXw5cH4uzwamSroKuLaGcyu7MiImV1pfWj4IeJOe/xzEf5G0BfCOrnoi4kZJj/WxbzMzG0B9HilKGksxAlsGPNvtGCNKy2sjnvsU0vXAGoCIWM8Lw3hNaXl96Xm53TXAoRSvF3ZExApJ+5RGaEd2HSBHeR3A53K/3kTuczLwJWA00CnpVVX2q8WTpeVhwL6l1x63z18EnqvBzMwar0+hKGkUcBEwJQNvKdAiaZik0fQ+guu3iFgN3AJcCFya6+4qhcy0brt8G/h8RKzotv73wLG5fALwOwBJ4/J4XwYepQjHVcAWA3QKM4DnRpOlqeA7sg4kHQq8coD6MzOzfqglFEd2vSUDuJXiB/xZuW02sIRiqvNbwNzKhxgQV1CMqmZUaxgRiyLipxU2fYpiGvZu4F+BT+f6b0paIGkhRVDNB2ZSTHn2+UabHvptzRt87gFOzvVnAe/IG4neDfx1A/sxM7MNoOdnOJubpFOBLSPijEbXMlgkLQVaI+LRntq0StFev5LMejZEfnaYAUjqiIjWau2GxHvoJF0HjAPe1ehazMxs4zUkQjEiJjay/3yrxae7rZ4dEZ8YyH4iYsxAHs/MzPpmSIRio0XEpeQNPmZmtvFqur9hamZm1igORTMzs+RQNDMzSw5FMzOz5Btthprx46Hd71Q0MxsMHimamZklh6KZmVlyKJqZmSWHopmZWXIompmZJd99OtR0dIDU6CrM/CkZtlHySNHMzCw5FM3MzJJD0czMLDkUzczMkkPRzMwsORTNzMySQ9HMzCw5FM3MzJJD0czMLDkUzczMUl1CUdI6SZ2SFkmaL+kUSU0ZyJJ2kXSTpPsl3SvpKkmvHsDjt0narvT8tZLukvQXSVdK2myg+jIzs76pVzA9HREtEbErcDBwGHBmnfqumaQRwI3AhRHxuoh4I3AhMGoAu2kDtis9Pw+4ICJ2Bh4DPjqAfZmZWR/UfbQWEcuAk4DJKrRJmtK1XdINkvbP5ScknSepQ9KtkiZImiVpsaQjs02bpOslTZe0RNLkHInOkzRH0taSxkmaW+pjZ0kdFco7HrgzIqaX6p0ZEQsljZB0qaQFeewDSv1fK+nmHO2dn+uHS5oqaWHu81lJRwOtwBU5ch4JvAu4Orv7KXDUgF1sMzPrk4ZMYUbE4ux72ypNNwdmRcR4YBVwDsVIcyJwdqndbhSBNgE4F3gqIvYE7gROjIgHgJWSWrL9JGBqhf52AyqFJcAnsvbdgeOAn+bIEqAFOAbYHThG0uhct31E7Jb7XBoRVwPtwAkR0ZLn93hEPJvHeRjYvnvHkk6S1C6pfXkPxZmZ2YZr5Ot6tXz+0TPAzbm8ALg9Itbm8phSu5kRsSoilgMrgemlfbraXQJMkjScIsB+1sd69wMuB4iIPwEPArvkttsiYmVErAbuAXYCFgNjJX1f0iHAPyscs9I1eNHn8UTExRHRGhGtAzmPa2ZmL9SQUJQ0FlgHLAOe7VbHiNLy2ojnPrRtPbAGICLW88LPglxTWl5fel5udw1wKHA40BERKyTtk9OYnTkduwgY31PZvZxSuf91wCYR8RjwZmAWxSjzkgr7PQpsJamrxh2AR3rpx8zMBlHdQ1HSKOAiYEoG3lKgRdKwnHacMBj95ijuFoobZy7NdXflDUAtETGNYvT4VknvLdV7iKTdgTuAE3LdLsCOwH099SdpG2BYRFwDnAHslZtWAVtk/wHMBI7ObR8BfjkwZ2xmZn1Vr1Ac2fWWDOBWYAZwVm6bDSyhmOr8FjC38iEGxBUU05MzKm2MiKcpRpKfzJtm7qG4W3QZ8ENguKQFwJVAW0SsqXSctD0wS1InxeuXX8j1U4GLSjfafB44RdL9wKuA/9ygMzQzs37T87OTGz9JpwJbRsQZja6lv1qlaG90EWYAL6GfHTb0SeqIiNZq7Tap1mBjIek6YBzFWyDMzMxe5CUTihExsdE1mJlZc2vKP7VmZmbWCA5FMzOz5FA0MzNLDkUzM7PkUDQzM0sORTMzs/SSeUvGRmP8eGj32/fNzAaDR4pmZmbJoWhmZpYcimZmZsmhaGZmlhyKZmZmyaFoZmaW/JaMoaajA6RGV2FDkT//0KwqjxTNzMySQ9HMzCw5FM3MzJJD0czMLDkUzczMkkPRzMwsORTNzMySQ9HMzCw5FM3MzFJdQlHSOkmdkhZJmi/pFElNGciSdpF0k6T7Jd0r6SpJrx7A47dJ2q70fHL2FZK2Gah+zMys7+oVTE9HREtE7AocDBwGnFmnvmsmaQRwI3BhRLwuIt4IXAiMGsBu2oDtSs9nAwcBDw5gH2Zm1g91H61FxDLgJGCyCm2SpnRtl3SDpP1z+QlJ50nqkHSrpAmSZklaLOnIbNMm6XpJ0yUtyZHXKZLmSZojaWtJ4yTNLfWxs6SOCuUdD9wZEdNL9c6MiIWSRki6VNKCPPYBpf6vlXSzpL9IOj/XD5c0VdLC3Oezko4GWoErcuQ8MiLmRcTSgb7OZmbWdw2ZwoyIxdn3tlWabg7MiojxwCrgHIqR5kTg7FK73SgCbQJwLvBUROwJ3AmcGBEPACsltWT7ScDUCv3tBlQKS4BPZO27A8cBP82RJUALcAywO3CMpNG5bvuI2C33uTQirgbagRNy5Px0lfMHQNJJktoltS+vZQczM+uXRr6uV8tHPTwD3JzLC4DbI2JtLo8ptZsZEasiYjmwEphe2qer3SXAJEnDKQLsZ32sdz/gcoCI+BPFdOcuue22iFgZEauBe4CdgMXAWEnfl3QI8M8+9veciLg4IlojonUg53HNzOyFGhKKksYC64BlwLPd6hhRWl4b8dzn3awH1gBExHpe+LFXa0rL60vPy+2uAQ4FDgc6ImKFpH1yGrMzp2MXAeN7KruXUyr3vw7YJCIeA94MzKIYZV7Sy/5mZtYE6h6KkkYBFwFTMvCWAi2ShuW044TB6DdHcbdQ3Dhzaa67K6cxWyJiGsXo8a2S3luq9xBJuwN3ACfkul2AHYH7euov7yQdFhHXAGcAe+WmVcAWA31+Zma24eoViiO73pIB3ArMAM7KbbOBJRRTnd8C5lY+xIC4Aojs/0XyNb7DgU/mTTP3UNwtugz4ITBc0gLgSqAtItZUOk7aHpglqZPi9csv5PqpwEVdN9pI+pSkh4EdgLsleURpZtYgipfQp3FLOhXYMiLOaHQt/dUqRXuji7Ch6SX0f92sO0kdEdFard0m1RpsLCRdB4wD3tXoWszMrDm9ZEIxIiY2ugYzM2tuTfmn1szMzBrBoWhmZpYcimZmZsmhaGZmlhyKZmZmyaFoZmaWXjJvydhojB8P7X77vpnZYPBI0czMLDkUzczMkkPRzMwsORTNzMySQ9HMzCw5FM3MzJLfkjHUdHSA1OgqzGxD+fMtm5JHimZmZsmhaGZmlhyKZmZmyaFoZmaWHIpmZmbJoWhmZpYcimZmZsmhaGZmlhyKZmZmaUBDUdI6SZ2SFkmaL+kUSU0XvJL2l3RDt3VTJR1dZb8jJZ2Wy6Mk3SVpnqS3D2a9ZmZWHwP9Z96ejogWAEnbAj8DtgTOHOB+GiIipgHT8umBwJ8i4iO17i9peESsG5TizMxsgw3aKC4ilgEnAZNVaJM0pWu7pBsk7Z/LT0g6T1KHpFslTZA0S9JiSUdmmzZJ10uaLmmJpMk5Ep0naY6krSWNkzS31MfOkjr6WrukpZLOkjRX0gJJbyjVMEVSC3A+cFiOjEdKOi7bLpR0XulYT0g6W9JdwL557K9JulNSu6S9JN0i6QFJJ/fvapuZ2UAY1KnNiFicfWxbpenmwKyIGA+sAs4BDgYmAmeX2u0GHA9MAM4FnoqIPYE7gRMj4gFgZYYWwCRgaj/LfzQi9gIuBE7tdl6dwJeBK3Nk/ErgPOBdQAuwt6SjSue2MCL2iYjf5bqHImJf4LdZ39HAW7qd63MknZQB2r68nydjZmbV1eP1vlo+0uEZ4OZcXgDcHhFrc3lMqd3MiFgVEcuBlcD00j5d7S4BJkkaDhxDMYXbXU9/nr68/tr8t6NbDZXsTRHqyyPiWeAK4B25bR1wTbf2XVOwC4C7Sue0WtJWLyoq4uKIaI2I1lFVCjEzs/4b1FCUNJYiFJYBz3brb0RpeW3Ec5+jsh5YAxAR63nh655rSsvrS8/L7a4BDgUOBzoiYoWkfXKaszOnY1dQjO7KtgYerdDXOqq/9tpb8K+u8Dpiue7u5+SP8zIza5BBC0VJo4CLgCkZeEuBFknDJI2mmAIdcBGxGriFYtrz0lx3V0S05GMa8BdgO0lvzFp3At4MdPaz27uAd0raJkeoxwG3b+CpmJlZnQ30qGSkpE5gU4qR4eXAd3LbbGAJxZThQmBuxSMMjCuA9wMzKm2MiDWSPgxcKmkEsBb4t4hY2Z/OIuJvkr4AzKQYNd4UEb/sX+lmZtYoio3w058lnQpsGRFnNLqWgdYqRXujizCzDbcR/uxtZpI6IqK1WruN7vUrSdcB4yjuBDUzM6vZRheKETGx0TWYmdnQ1HR/gs3MzKxRHIpmZmbJoWhmZpYcimZmZsmhaGZmlhyKZmZmaaN7S8ZGb/x4aPfb983MBoNHimZmZsmhaGZmlhyKZmZmyaFoZmaWHIpmZmbJoWhmZpYcimZmZsmhaGZmlhyKZmZmSRHR6BqsDyStAu5rdB39sA3waKOL6AfXXV+uu75eSnXvFBGjqjXyn3kbeu6LiNZGF9FXktpdd/247vpy3fU1mHV7+tTMzCw5FM3MzJJDcei5uNEF9JPrri/XXV+uu74GrW7faGNmZpY8UjQzM0sORTMzs+RQbFKSDpF0n6T7JZ1WYfvLJF2Z2++SNKb+Vb5YDXW/Q9JcSc9KOroRNVZSQ92nSLpH0t2SbpO0UyPq7K6Guk+WtEBSp6TfSXpTI+rsrlrdpXZHSwpJTfG2gRqud5uk5Xm9OyX9WyPq7K6W6y3pQ/k9vkjSz+pdYyU1XO8LStf6z5Ie3+BOI8KPJnsAw4EHgLHAZsB84E3d2nwcuCiXjwWuHCJ1jwH2AC4Djm50zX2o+wDg5bn870Poev9LaflI4OahUHe22wK4A5gDtA6FuoE2YEqja+1H3TsD84BX5vNth0Ld3dp/EvjJhvbrkWJzmgDcHxGLI+IZ4BfA+7q1eR/w01y+GjhQkupYYyVV646IpRFxN7C+EQX2oJa6Z0bEU/l0DrBDnWuspJa6/1l6ujnQDHfW1fL9DfBV4HxgdT2L60WtdTebWur+GPCDiHgMICKW1bnGSvp6vY8Dfr6hnToUm9P2wEOl5w/nuoptIuJZYCXwqrpU17Na6m5Gfa37o8CvBrWi2tRUt6RPSHqAImA+VafaelO1bkl7AqMj4oZ6FlZFrd8nH8hp9qslja5Pab2qpe5dgF0kzZY0R9IhdauuZzX/v8yXM14L/GZDO3UoNqdKI77uv+HX0qbemrGmWtRct6QPA63ANwe1otrUVHdE/CAixgFTKs1EAAABxklEQVSfB7406FVV12vdkoYBFwCfq1tFtanlek8HxkTEHsCtPD+b00i11L0JxRTq/hQjrkskbTXIdVXTl58nxwJXR8S6De3UodicHgbKv2HuADzSUxtJmwBbAv+oS3U9q6XuZlRT3ZIOAk4HjoyINXWqrTd9vd6/AI4a1IpqU63uLYDdgFmSlgJvAaY1wc02Va93RKwofW/8GBhfp9p6U+vPk19GxNqIWELxoQM716m+nvTl+/tYBmDqFPCNNs34oPitbTHFdEDXC8y7dmvzCV54o81VQ6HuUtupNM+NNrVc7z0pXvTfudH19rHunUvLRwDtQ6Hubu1n0Rw32tRyvV9TWp4IzBkidR8C/DSXt6GYtnxVs9ed7V4PLCX/GM0G99voL5gfPX5DHAb8OX8Qn57rzqYYpQCMAP4buB/4AzC20TXXWPfeFL8BPgmsABY1uuYa674V+DvQmY9pja65xrq/CyzKmmf2Fj7NVHe3tk0RijVe76/n9Z6f1/sNja65xroFfAe4B1gAHNvommv9PgG+AnxjoPr0n3kzMzNLfk3RzMwsORTNzMySQ9HMzCw5FM3MzJJD0czMLDkUzczMkkPRzMws/X+7MGGLxitoPAAAAABJRU5ErkJggg==\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Ακρίβεια -Precision- ($P$) είναι ο λόγος των true positives ($T_p$) ως προς τον αριθμό των true positives συν τον αριθμό των false positives ($F_p$).\n$$P = \\frac{T_p}{T_p+F_p}$$\nΑνάκληση -Recall- ($R$) είναι ο λόγος των true positives ($T_p$) ως προς τον αριθμό των true positives συν τον αριθμό των false negatives ($F_n$).\n$$R = \\frac{T_p}{T_p + F_n}$$\nΣυχνά χρησιμοποιούμε και το ($F_1$) score, το οποίο είναι ο αρμονικός μέσος της ακρίβειας και της ανάκλησης.\n$$F1 = 2\\frac{P \\times R}{P+R}$$\nΙδανικά θέλουμε και υψηλή ακρίβεια και υψηλή ανάκληση, ωστόσο μεταξύ της ακρίβειας και της ανάκλησης υπάρχει γενικά trade-off. Στην οριακή περίπτωση του ταξινομητή που επιστρέφει σταθερά μόνο τη θετική κλάση για παράδειγμα, η ανάκληση θα είναι 1 αλλά η ακρίβεια θα έχει τη μικρότερη δυνατή τιμή της. Γενικά, κατεβάζοντας το κατώφλι της απόφασης του ταξινομητή, αυξάνουμε την ανάκληση και μειώνουμε την ακρίβεια και αντιστρόφως. \n\n\n\n### Παρατηρούμε την εμφανή υπεροχή σε όλα τα scores του kNN , αν αγνοήσουμε την constant τακτική του dummy που είναι λογικό να έχει ανεβασμένα νούμερα στα αντίστοιχα classes."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Δ. Βελτιστοποίηση ταξινομητών"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Σε αυτή τη φάση πάμε να βρούμε τη βέλτιστη αρχιτεκτονική για κάθε ταξινομητή.\nΕπειδή ο dummy δεν επιδέχεται βελτίωση θα ασχοληθούμε καθαρά με τον kNN.\n\nΠιο συγκεκριμένα βρίκσουμε τις διαθέσιμες βελτιστοποιήσεις για το dataset μας οι οποιές ειναι : VarianceThreshold,imbalanced-learn MinMaxScaler,StandardScaler και PCA .\n\nΦτιάχνουμε συναρτήσεις που να δέχονται ένα συγκρκιμένο train , test set , και εφαρμόζουν τις βελτιστοποιήσεις πάνω τους.\n\nΓια τις εξόδους των παραπάνων συναρτήσεων εφαρμόζουμε cross validation η οποία θα μας δώσει τη βέλτιστη υπερπαράμερτο n_neighbors για την εφαρμογή του ταξινομητη kNN \n\nΎστερα έχοντας αυτα τα δεδομένα εκπαιδεύω τον kNN και βγάζω τα αποτελεσματα μου."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Αρχικά βλέπουμε αν ειναι ισορροπημενο το train,test set μας , ετσι ωστε αν χρειαστει να κόψω κάποια instances μέσω της imbalanced"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "print('το αρχικο train set εχει ',train_labels.count(0),'δειγματα κατηγοριας 0 - not granted')",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": "το αρχικο train set εχει  285 δειγματα κατηγοριας 0 - not granted\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print('το αρχικο train set εχει ',train_labels.count(1),'δειγματα κατηγοριας 1 - granted')",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": "το αρχικο train set εχει  237 δειγματα κατηγοριας 1 - granted\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Βλέπουμε όπως ειναι αναμενόμενο ότι έχει κρατήσει την ισορροπία του και το train,test set όπως και το αρχικό, επομένως δεν θα χρειαστει αυτή η βελτιστοποίηση ούτε και στη πορεία καθώς όλες οι υπολοιπες βελτιστοποιήσεις δεν επηρεάζουν την ισορροπία"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Πάμε να συνεχίσουμε με τις υπόλοιπες , το σκεπτικό με το οποίο εργαστήκαμε είναι να δημιουργήσουμε όλες τους πιθανους συνδυασμούς των μετασχηματιστών και στη συνέχεια να περάσουμε το set μας στον cross validation και τέλος στον kNN .\n\nTo cross validation όπως και κάθε συνδυασμός έχει υλοποιηθεί 2 φορές , 1 για την f1_macro και 1 για την f1_micro"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.metrics import f1_score\nimport time",
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def variance(train,test,thresh):\n    selector = VarianceThreshold(threshold=thresh)\n    train_reduced = selector.fit_transform(train)\n    mask = selector.get_support()\n    test_reduced = test[:,mask]\n    return train_reduced,test_reduced",
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def min_max(train,test):\n    min_max_scaler = preprocessing.MinMaxScaler()\n    train_scaled = min_max_scaler.fit_transform(train)\n    test_scaled = min_max_scaler.transform(test)\n    return train_scaled,test_scaled",
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def scaled_Standard(train,test):\n\n    scaler = preprocessing.StandardScaler().fit(train)\n    train_scaled = scaler.transform(train)\n    test_scaled = scaler.transform(test)\n\n    return train_scaled,test_scaled",
      "execution_count": 31,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def pca(n,train,test):\n\n    pcaa = PCA(n_components=n)\n\n\n    trainPCA =  pcaa.fit_transform(train)\n    testPCA = pcaa.transform(test)\n\n\n    return trainPCA , testPCA",
      "execution_count": 32,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def cross_macro(train):\n\n    myList = list(range(1,50))\n    neighbors = list(filter(lambda x: x % 2 != 0, myList))\n    cv_scores = []\n    for k in neighbors:\n        knn = KNeighborsClassifier(n_neighbors=k)\n        scores = cross_val_score(knn, train, train_labels, cv=10, scoring='f1_macro')\n        cv_scores.append(scores.mean())\n    mean_error = [1 - x for x in cv_scores]\n    optimal_k = neighbors[mean_error.index(min(mean_error))]\n    return optimal_k",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def cross_micro(train):\n\n    myList = list(range(1,50))\n    neighbors = list(filter(lambda x: x % 2 != 0, myList))\n    cv_scores = []\n    for k in neighbors:\n        knn = KNeighborsClassifier(n_neighbors=k)\n        scores = cross_val_score(knn, train, train_labels, cv=10, scoring='f1_micro')\n        cv_scores.append(scores.mean())\n    mean_error = [1 - x for x in cv_scores]\n    optimal_k = neighbors[mean_error.index(min(mean_error))]\n    return optimal_k",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def acc_macro(train_in,test_in,num):\n    \n    knn = KNeighborsClassifier(n_neighbors = num)\n    knn.fit(train_in, train_labels)\n    knn_preds = knn.predict(test_in)\n    scores_weighted = {}\n    scores_macro = {}\n    scores_micro = {}\n    return f1_score(test_labels,knn_preds,average='macro')\n",
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def acc_micro(train_in,test_in,num):\n    \n    knn = KNeighborsClassifier(n_neighbors = num)\n    knn.fit(train_in, train_labels)\n    knn_preds = knn.predict(test_in)\n    scores_weighted = {}\n    scores_macro = {}\n    scores_micro = {}\n    return f1_score(test_labels,knn_preds,average='micro')\n",
      "execution_count": 36,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def minim(a,b):\n    if a <= b:\n        c = a - 1\n    else:\n        c = b\n    return c",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def knn_macro(maxim,nei,pc,th):\n    k=cross_macro(train)\n    fin=acc_macro(train,test,k)\n    maxim[0]=fin\n    nei[0]=k\n    return",
      "execution_count": 38,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def knn_micro(maxim,nei,pc,th):\n    k=cross_micro(train)\n    fin=acc_micro(train,test,k)\n    maxim[0]=fin\n    nei[0]=k\n    return",
      "execution_count": 39,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def minmax_knn_macro(maxim,nei,pc,th):\n    train_1,test_1=min_max(train,test)\n    k=cross_macro(train_1)\n    fin=acc_macro(train_1,test_1,k)\n    maxim[1]=fin\n    nei[1]=k\n    return",
      "execution_count": 40,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def minmax_knn_micro(maxim,nei,pc,th):\n    train_1,test_1=min_max(train,test)\n    k=cross_micro(train_1)\n    fin=acc_micro(train_1,test_1,k)\n    maxim[1]=fin\n    nei[1]=k\n    return",
      "execution_count": 41,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def standard_knn_macro(maxim,nei,pc,th):\n    train_1,test_1=scaled_Standard(train,test)\n    k=cross_macro(train_1)\n    fin=acc_macro(train_1,test_1,k)\n    maxim[2]=fin\n    nei[2]=k\n    return",
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def standard_knn_micro(maxim,nei,pc,th):\n    train_1,test_1=scaled_Standard(train,test)\n    k=cross_micro(train_1)\n    fin=acc_micro(train_1,test_1,k)\n    maxim[2]=fin\n    nei[2]=k\n    return",
      "execution_count": 43,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def pca_knn_macro(maxim,nei,pc,th):\n    maxim[3]=0\n    maxn_pc = minim(train.shape[0], train.shape[1])\n    for y in range(1,maxn_pc,1):\n        train_1,test_1 = pca(y,train,test)\n        k=cross_macro(train_1)\n        fin=acc_macro(train_1,test_1,k)\n        if fin>maxim[3]:\n            maxim[3]=fin\n            pc[3]=y\n            nei[3]=k\n    return",
      "execution_count": 44,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def pca_knn_micro(maxim,nei,pc,th):\n    maxim[3]=0\n    maxn_pc = minim(train.shape[0], train.shape[1])\n    for y in range(1,maxn_pc,1):\n        train_1,test_1 = pca(y,train,test)\n        k=cross_micro(train_1)\n        fin=acc_micro(train_1,test_1,k)\n        if fin>maxim[3]:\n            maxim[3]=fin\n            pc[3]=y\n            nei[3]=k\n    return",
      "execution_count": 45,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def minmax_pca_knn_macro(maxim,nei,pc,th):\n    maxim[4]=0\n    train_1,test_1=min_max(train,test)\n    maxn_pc = minim(train_1.shape[0], train_1.shape[1])\n    for y in range(1,maxn_pc,1):\n        train_2,test_2 = pca(y,train_1,test_1)\n        k=cross_macro(train_2)\n        fin=acc_macro(train_2,test_2,k)\n        if fin>maxim[4]:\n            maxim[4]=fin\n            pc[4]=y\n            nei[4]=k\n    return",
      "execution_count": 46,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def minmax_pca_knn_micro(maxim,nei,pc,th):\n    maxim[4]=0\n    train_1,test_1=min_max(train,test)\n    maxn_pc = minim(train_1.shape[0], train_1.shape[1])\n    for y in range(1,maxn_pc,1):\n        train_2,test_2 = pca(y,train_1,test_1)\n        k=cross_micro(train_2)\n        fin=acc_micro(train_2,test_2,k)\n        if fin>maxim[4]:\n            maxim[4]=fin\n            pc[4]=y\n            nei[4]=k\n    return",
      "execution_count": 47,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def standard_pca_knn_macro(maxim,nei,pc,th):\n    maxim[5]=0\n    train_1,test_1=scaled_Standard(train,test)\n    maxn_pc = minim(train_1.shape[0], train_1.shape[1])\n    for y in range(1,maxn_pc,1):\n        train_2,test_2 = pca(y,train_1,test_1)\n        k=cross_macro(train_2)\n        fin=acc_macro(train_2,test_2,k)\n        if fin>maxim[5]:\n            maxim[5]=fin\n            pc[5]=y\n            nei[5]=k\n    return",
      "execution_count": 48,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def standard_pca_knn_micro(maxim,nei,pc,th):\n    maxim[5]=0\n    train_1,test_1=scaled_Standard(train,test)\n    maxn_pc = minim(train_1.shape[0], train_1.shape[1])\n    for y in range(1,maxn_pc,1):\n        train_2,test_2 = pca(y,train_1,test_1)\n        k=cross_micro(train_2)\n        fin=acc_micro(train_2,test_2,k)\n        if fin>maxim[5]:\n            maxim[5]=fin\n            pc[5]=y\n            nei[5]=k\n    return",
      "execution_count": 49,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def thres_knn_macro(maxim,nei,pc,th,a,b,c):   \n    maxim[6]=0\n    for x in np.arange(a,b,c):\n        train_1,test_1=variance(train,test,x)\n        k=cross_macro(train_1)\n        fin=acc_macro(train_1,test_1,k)\n        if fin>maxim[6]:\n            maxim[6]=fin\n            th[6]=x\n            nei[6]=k\n    return",
      "execution_count": 50,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def thres_knn_micro(maxim,nei,pc,th,a,b,c):   \n    maxim[6]=0\n    for x in np.arange(a,b,c):\n        train_1,test_1=variance(train,test,x)\n        k=cross_micro(train_1)\n        fin=acc_micro(train_1,test_1,k)\n        if fin>maxim[6]:\n            maxim[6]=fin\n            th[6]=x\n            nei[6]=k\n    return",
      "execution_count": 51,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def thres_minmax_knn_macro(maxim,nei,pc,th,a,b,c):   \n    maxim[7]=0\n    for x in np.arange(a,b,c):\n        train_1,test_1=variance(train,test,x)\n        train_1,test_1=min_max(train_1,test_1)\n        k=cross_macro(train_1)\n        fin=acc_macro(train_1,test_1,k)\n        if fin>maxim[7]:\n            maxim[7]=fin\n            th[7]=x\n            nei[7]=k\n    return",
      "execution_count": 52,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def thres_minmax_knn_micro(maxim,nei,pc,th,a,b,c):   \n    maxim[7]=0\n    for x in np.arange(a,b,c):\n        train_1,test_1=variance(train,test,x)\n        train_1,test_1=min_max(train_1,test_1)\n        k=cross_micro(train_1)\n        fin=acc_micro(train_1,test_1,k)\n        if fin>maxim[7]:\n            maxim[7]=fin\n            th[7]=x\n            nei[7]=k\n    return",
      "execution_count": 53,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def thres_standard_knn_macro(maxim,nei,pc,th,a,b,c) :   \n    maxim[8]=0\n    for x in np.arange(a,b,c):\n        train_1,test_1=variance(train,test,x)\n        train_1,test_1=scaled_Standard(train_1,test_1)\n        k=cross_macro(train_1)\n        fin=acc_macro(train_1,test_1,k)\n        if fin>maxim[8]:\n            maxim[8]=fin\n            th[8]=x\n            nei[8]=k\n    return",
      "execution_count": 54,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def thres_standard_knn_micro(maxim,nei,pc,th,a,b,c) :   \n    maxim[8]=0\n    for x in np.arange(a,b,c):\n        train_1,test_1=variance(train,test,x)\n        train_1,test_1=scaled_Standard(train_1,test_1)\n        k=cross_micro(train_1)\n        fin=acc_micro(train_1,test_1,k)\n        if fin>maxim[8]:\n            maxim[8]=fin\n            th[8]=x\n            nei[8]=k\n    return",
      "execution_count": 55,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def thres_minmax_pca_knn_macro(maxim,nei,pc,th,a,b,c):    \n    maxim[9]=0\n    for x in np.arange(a,b,c):\n        train_1,test_1=variance(train,test,x)\n        train_1,test_1=min_max(train_1,test_1)\n        maxn_pc = minim(train_1.shape[0], train_1.shape[1])\n        for y in range(1,maxn_pc,1):\n            train_2,test_2 = pca(y,train_1,test_1)\n            k=cross_macro(train_2)\n            fin=acc_macro(train_2,test_2,k)\n            if fin>maxim[9]:\n                maxim[9]=fin\n                th[9]=x\n                pc[9]=y\n                nei[9]=k\n    return",
      "execution_count": 56,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def thres_minmax_pca_knn_micro(maxim,nei,pc,th,a,b,c):    \n    maxim[9]=0\n    for x in np.arange(a,b,c):\n        train_1,test_1=variance(train,test,x)\n        train_1,test_1=min_max(train_1,test_1)\n        maxn_pc = minim(train_1.shape[0], train_1.shape[1])\n        for y in range(1,maxn_pc,1):\n            train_2,test_2 = pca(y,train_1,test_1)\n            k=cross_micro(train_2)\n            fin=acc_micro(train_2,test_2,k)\n            if fin>maxim[9]:\n                maxim[9]=fin\n                th[9]=x\n                pc[9]=y\n                nei[9]=k\n    return",
      "execution_count": 57,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def thres_standard_pca_knn_macro(maxim,nei,pc,th,a,b,c):    \n    maxim[10]=0\n    for x in np.arange(a,b,c):\n        train_1,test_1=variance(train,test,x)\n        train_1,test_1=scaled_Standard(train_1,test_1)\n        maxn_pc = minim(train_1.shape[0], train_1.shape[1])\n        for y in range(1,maxn_pc,1):\n            train_2,test_2 = pca(y,train_1,test_1)\n            k=cross_macro(train_2)\n            fin=acc_macro(train_2,test_2,k)\n            if fin>maxim[10]:\n                maxim[10]=fin\n                th[10]=x\n                pc[10]=y\n                nei[10]=k\n    return ",
      "execution_count": 58,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def thres_standard_pca_knn_micro(maxim,nei,pc,th,a,b,c):    \n    maxim[10]=0\n    for x in np.arange(a,b,c):\n        train_1,test_1=variance(train,test,x)\n        train_1,test_1=scaled_Standard(train_1,test_1)\n        maxn_pc = minim(train_1.shape[0], train_1.shape[1])\n        for y in range(1,maxn_pc,1):\n            train_2,test_2 = pca(y,train_1,test_1)\n            k=cross_micro(train_2)\n            fin=acc_micro(train_2,test_2,k)\n            if fin>maxim[10]:\n                maxim[10]=fin\n                th[10]=x\n                pc[10]=y\n                nei[10]=k\n    return ",
      "execution_count": 59,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def pipe_grid_macro(a,b,c):\n    maxim=[0,0,0,0,0,0,0,0,0,0,0]\n    nei=[0,0,0,0,0,0,0,0,0,0,0]\n    pc=[0,0,0,0,0,0,0,0,0,0,0]\n    th=[0,0,0,0,0,0,0,0,0,0,0]\n    mx=0\n    thes=0\n    knn_macro(maxim,nei,pc,th)\n    print('9%')\n    minmax_knn_macro(maxim,nei,pc,th)\n    print('18%')\n    standard_knn_macro(maxim,nei,pc,th)\n    print('27%')\n    pca_knn_macro(maxim,nei,pc,th)\n    print('36%')\n    minmax_pca_knn_macro(maxim,nei,pc,th)\n    print('45%')\n    standard_pca_knn_macro(maxim,nei,pc,th)\n    print('54%')\n    thres_knn_macro(maxim,nei,pc,th,a,b,c)\n    print('63%')\n    thres_minmax_knn_macro(maxim,nei,pc,th,a,b,c)\n    print('72%')\n    thres_standard_knn_macro(maxim,nei,pc,th,a,b,c)\n    print('81%')\n    thres_minmax_pca_knn_macro(maxim,nei,pc,th,a,b,c)\n    print('90%')\n    thres_standard_pca_knn_macro(maxim,nei,pc,th,a,b,c)\n    print('99%')\n    print('\\n')\n    print('\\n')\n    print('\\n')\n    print(\"!!!!!!!!!\")\n    print(\"H βέλτιστη αρχιτεκτονική για f1_macro ειναι η εξής:\\n\")\n    for i in range(11):\n        if(maxim[i]>mx):\n            thes=i\n            mx=maxim[i]\n    if thes==0:\n        print('kNN με cross validation έχω f_macro=',maxim[0],'για k_neighbors=',nei[0],'\\n')\n    elif thes==1:\n        print('min_max και kNN με cross validation έχω f_macro=',maxim[1],'για k_neighbors=',nei[1],'\\n')\n    elif thes==2:\n        print('scaled_Standard και kNN με cross validation έχω f_macro=',maxim[2],'για k_neighbors=',nei[2],'\\n')\n    elif thes==3:\n        print('pca με n_components=',pc[3],' και kNN με cross validation έχω f_macro=',maxim[3],'για k_neighbors=',nei[3],'\\n')\n    elif thes==4:\n        print('minmax και pca και kNN με n_components=',pc[4],' με cross validation έχω f_macro=',maxim[4],'για k_neighbors=',nei[4],'\\n')\n    elif thes==5:\n        print('scaled_Standard και pca με n_components=',pc[5],' και kNN με cross validation έχω f_macro=',maxim[5],'για k_neighbors=',nei[5],'\\n')\n    elif thes==6:\n        print('Vthreshold με value=',th[6],' και kNN με cross validation έχω f_macro=',maxim[6],'για k_neighbors=',nei[6],'\\n')\n    elif thes==7:\n        print('Vthreshold με value=',th[7],' και min_max και kNN με cross validation έχω f_macro=',maxim[7],'για k_neighbors=',nei[7],'\\n')\n    elif thes==8:\n        print('Vthreshold με value=',th[8],' και scaled_Standard και kNN με cross validation έχω f_macro=',maxim[8],'για k_neighbors=',nei[8],'\\n')\n    elif thes==9:\n        print('Vthreshold με value=',th[9],' και min_max και pca με n_components=',pc[9],'  kNN με cross validation έχω f_macro=',maxim[9],'για k_neighbors=',nei[9],'\\n')\n    elif thes==10:\n        print('Vthreshold με value=',th[10],' και scaled_Standard και pca με n_components=',pc[10],'  kNN με cross validation έχω f_macro=',maxim[10],'για k_neighbors=',nei[10],'\\n')\n    return",
      "execution_count": 60,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def pipe_grid_micro(a,b,c):\n    maxim=[0,0,0,0,0,0,0,0,0,0,0]\n    nei=[0,0,0,0,0,0,0,0,0,0,0]\n    pc=[0,0,0,0,0,0,0,0,0,0,0]\n    th=[0,0,0,0,0,0,0,0,0,0,0]\n    mx=0\n    thes=0\n    knn_micro(maxim,nei,pc,th)\n    print('9%')\n    minmax_knn_micro(maxim,nei,pc,th)\n    print('18%')\n    standard_knn_micro(maxim,nei,pc,th)\n    print('27%')\n    pca_knn_micro(maxim,nei,pc,th)\n    print('36%')\n    minmax_pca_knn_micro(maxim,nei,pc,th)\n    print('45%')\n    standard_pca_knn_micro(maxim,nei,pc,th)\n    print('54%')\n    thres_knn_micro(maxim,nei,pc,th,a,b,c)\n    print('63%')\n    thres_minmax_knn_micro(maxim,nei,pc,th,a,b,c)\n    print('72%')\n    thres_standard_knn_micro(maxim,nei,pc,th,a,b,c)\n    print('81%')\n    thres_minmax_pca_knn_micro(maxim,nei,pc,th,a,b,c)\n    print('90%')\n    thres_standard_pca_knn_micro(maxim,nei,pc,th,a,b,c)\n    print('99%')\n    print('\\n')\n    print('\\n')\n    print('\\n')\n    print(\"!!!!!!!!!\")\n    print(\"H βέλτιστη αρχιτεκτονική για f1_micro ειναι η εξής:\\n\")\n    for i in range(11):\n        if(maxim[i]>mx):\n            thes=i\n            mx=maxim[i]\n    if thes==0:\n        print('kNN με cross validation έχω f_micro=',maxim[0],'για k_neighbors=',nei[0],'\\n')\n    elif thes==1:\n        print('min_max και kNN με cross validation έχω f_micro=',maxim[1],'για k_neighbors=',nei[1],'\\n')\n    elif thes==2:\n        print('scaled_Standard και kNN με cross validation έχω f_micro=',maxim[2],'για k_neighbors=',nei[2],'\\n')\n    elif thes==3:\n        print('pca με n_components=',pc[3],' και kNN με cross validation έχω f_micro=',maxim[3],'για k_neighbors=',nei[3],'\\n')\n    elif thes==4:\n        print('minmax και pca και kNN με n_components=',pc[4],' με cross validation έχω f_micro=',maxim[4],'για k_neighbors=',nei[4],'\\n')\n    elif thes==5:\n        print('scaled_Standard και pca με n_components=',pc[5],' και kNN με cross validation έχω f_micro=',maxim[5],'για k_neighbors=',nei[5],'\\n')\n    elif thes==6:\n        print('Vthreshold με value=',th[6],' και kNN με cross validation έχω f_micro=',maxim[6],'για k_neighbors=',nei[6],'\\n')\n    elif thes==7:\n        print('Vthreshold με value=',th[7],' και min_max και kNN με cross validation έχω f_micro=',maxim[7],'για k_neighbors=',nei[7],'\\n')\n    elif thes==8:\n        print('Vthreshold με value=',th[8],' και scaled_Standard και kNN με cross validation έχω f_micro=',maxim[8],'για k_neighbors=',nei[8],'\\n')\n    elif thes==9:\n        print('Vthreshold με value=',th[9],' και min_max και pca με n_components=',pc[9],'  kNN με cross validation έχω f_micro=',maxim[9],'για k_neighbors=',nei[9],'\\n')\n    elif thes==10:\n        print('Vthreshold με value=',th[10],' και scaled_Standard και pca με n_components=',pc[10],'  kNN με cross validation έχω f_micro=',maxim[10],'για k_neighbors=',nei[10],'\\n')\n    return",
      "execution_count": 61,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Πάμε να βρούμε τη διακύμανση του set μας έτσι ώστε να προσαρμόσουμε κατάλληλα το κάλεσμα της Variance Threshold"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_variance = train.var(axis=0)\nprint(train_variance)\nprint(np.max(train_variance))",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[1.49508285e+02 2.42014570e+01 1.21170006e+01 1.96205869e+01\n 2.79434513e+04 1.03734130e+07 2.15469532e-01 2.15469532e-01\n 1.91203887e-03 1.82120785e-01 1.81118891e-01 1.82120785e-01\n 1.91203887e-03 1.81118891e-01 6.74975411e-02 1.64090369e-01\n 5.75446632e-02 3.50736190e-02 4.21199043e-02 7.87752675e-02\n 8.03570118e-02 1.69441141e-02 6.42092747e-02 4.90487515e-02\n 1.00251758e-01 3.81673786e-03 8.96933398e-02 4.73275495e-02\n 7.71861834e-02 1.13621350e-02 8.34984806e-02 1.66321692e-01\n 1.50907943e-02 3.81673786e-03 1.91203887e-03 2.45504323e-01\n 1.32301346e-02 2.48223749e-01 2.48223749e-01 2.46473187e-01\n 2.46473187e-01 2.48058602e-01 2.48058602e-01 7.55897594e-02\n 1.91203887e-03]\n10373412.95494774\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "start_time = time.time()",
      "execution_count": 63,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "pipe_grid_macro(1,1000,100)",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": "9%\n18%\n27%\n36%\n45%\n54%\n63%\n72%\n81%\n90%\n99%\n\n\n\n\n\n\n!!!!!!!!!\nH βέλτιστη αρχιτεκτονική για f1_macro ειναι η εξής:\n\nscaled_Standard και pca με n_components= 19  και kNN με cross validation έχω f_macro= 0.891709966934341 για k_neighbors= 49 \n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pipe_grid_micro(1,1000,100)",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": "9%\n18%\n27%\n36%\n45%\n54%\n63%\n72%\n81%\n90%\n99%\n\n\n\n\n\n\n!!!!!!!!!\nH βέλτιστη αρχιτεκτονική για f1_micro ειναι η εξής:\n\nscaled_Standard και pca με n_components= 6  και kNN με cross validation έχω f_micro= 0.8931297709923665 για k_neighbors= 47 \n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pipe_grid_macro(0.1,1,0.05)",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": "9%\n18%\n27%\n36%\n45%\n54%\n63%\n72%\n81%\n90%\n99%\n\n\n\n\n\n\n!!!!!!!!!\nH βέλτιστη αρχιτεκτονική για f1_macro ειναι η εξής:\n\nVthreshold με value= 0.15000000000000002  και scaled_Standard και pca με n_components= 10   kNN με cross validation έχω f_macro= 0.8999236058059588 για k_neighbors= 35 \n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "pipe_grid_micro(0.1,1,0.05)",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": "9%\n18%\n27%\n36%\n45%\n54%\n63%\n72%\n81%\n90%\n99%\n\n\n\n\n\n\n!!!!!!!!!\nH βέλτιστη αρχιτεκτονική για f1_micro ειναι η εξής:\n\nVthreshold με value= 0.1  και scaled_Standard και pca με n_components= 10   kNN με cross validation έχω f_micro= 0.9007633587786259 για k_neighbors= 39 \n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pipe_grid_macro(1000,10000000,100000)",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": "9%\n18%\n27%\n36%\n45%\n54%\n63%\n72%\n81%\n90%\n99%\n\n\n\n\n\n\n!!!!!!!!!\nH βέλτιστη αρχιτεκτονική για f1_macro ειναι η εξής:\n\nscaled_Standard και pca με n_components= 8  και kNN με cross validation έχω f_macro= 0.8923708920187794 για k_neighbors= 7 \n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pipe_grid_micro(1000,10000000,100000)",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": "9%\n18%\n27%\n36%\n45%\n54%\n63%\n72%\n81%\n90%\n99%\n\n\n\n\n\n\n!!!!!!!!!\nH βέλτιστη αρχιτεκτονική για f1_micro ειναι η εξής:\n\nscaled_Standard και pca με n_components= 11  και kNN με cross validation έχω f_micro= 0.8931297709923665 για k_neighbors= 23 \n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pipe_grid_macro(0,0.1,0.01)",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": "9%\n18%\n27%\n36%\n45%\n54%\n63%\n72%\n81%\n90%\n99%\n\n\n\n\n\n\n!!!!!!!!!\nH βέλτιστη αρχιτεκτονική για f1_macro ειναι η εξής:\n\nVthreshold με value= 0.08  και scaled_Standard και kNN με cross validation έχω f_macro= 0.8996168582375479 για k_neighbors= 19 \n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pipe_grid_micro(0,0.1,0.01)",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": "9%\n18%\n27%\n36%\n45%\n54%\n63%\n72%\n81%\n90%\n99%\n\n\n\n\n\n\n!!!!!!!!!\nH βέλτιστη αρχιτεκτονική για f1_micro ειναι η εξής:\n\nVthreshold με value= 0.08  και scaled_Standard και kNN με cross validation έχω f_micro= 0.9007633587786259 για k_neighbors= 19 \n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Για την εύρεση του κατάλληλου fit για αυτο το training set χρειάστηκαν : %s seconds\" % (time.time() - start_time))\n",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Για την εύρεση του κατάλληλου fit για αυτο το training set χρειάστηκαν : 7956.419920682907 seconds\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Όπως ήταν αναμενόμενο για μεγάλες τιμές του threshold δεν εφαρμόζεται αυτη η βελτιστοποίηση , καθώς χάνουμε μεγάλο ποσοστό απο χαρακτηριστικά που τα είχαμε ορίσει 0 ή 1 με την getdummies , αρα εχουν μικρη διακύμανση.\n\nΕπίσης βλέπουμε να επικρατεί πάντα το scaled Standard αντι του min max που είναι και αυτό αναμενόμενο , αφού ειναι απαραίτητη αυτη η βελτιστοποίηση για να δουλέψει καλύτερα ένας ταξινομητής.\n\nΈπειτα για μια καλύτερη λειτουργία έχουμε το pca που βοηθάει πάρα πολύ για την μείωση της διαστατικότητας."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Επιλέγουμε σαν καταλληλότερο fit την τελευταία επιλογή με Vthreshold με value= 0.08  και scaled_Standard και kNN με cross validation έχω  για k_neighbors= 19 και πάμε να την εφαρμόσουμε "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "fwei1=[0,0,0,0,0,0]\nfmac1=[0,0,0,0,0,0]\nfmic1=[0,0,0,0,0,0]\ntrain_fin,test_fin=variance(train,test,0.08)\ntrain_fin,test_fin=scaled_Standard(train_fin,test_fin)\nnum1=cross_macro(train_fin)",
      "execution_count": 118,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def function1(train_in,train_labels_in,test_in,test_labels_in,num,xron,fwei1,fmac1,fmic1):\n    \n    credit_accuracy = {}\n\n    dc_uniform = DummyClassifier(strategy=\"uniform\")\n\n# με τη μέθοδο fit \"εκπαιδεύουμε\" τον ταξινομητή στο σύνολο εκπαίδευσης (τα χαρακτηριστικά και τις ετικέτες τους)\n    start_time = time.time()\n    model = dc_uniform.fit(train_in, train_labels_in)\n    xron[0]=(time.time() - start_time)\n# με τη μέθοδο predict παράγουμε προβλέψεις για τα δεδομένα ελέγχου (είσοδος τα χαρακτηριστικά μόνο)\n    preds = dc_uniform.predict(test_in)\n\n# υπολογίζουμε την ακρίβεια του συγκεκριμένου μοντέλου dummy classifier\n    credit_accuracy['uniform (random)'] = dc_uniform.score(test_in, test_labels_in)\n\n\n#################\n    print ('Classification report for Dummy Classifier (uniform)')\n    cr_dummy_uni = classification_report(test_labels_in, preds,target_names = label_names)\n    print (cr_dummy_uni)\n\n    scores_weighted = {}\n    scores_macro = {}\n    scores_micro = {}\n\n    scores_weighted['Dummy-Uniform']=precision_recall_fscore_support(test_labels_in,preds,average='weighted')\n    scores_macro['Dummy-Uniform']=precision_recall_fscore_support(test_labels_in,preds,average='macro')\n    scores_micro['Dummy-Uniform']=precision_recall_fscore_support(test_labels_in,preds,average='micro')\n\n\n    print ('Confusion Matrix for Dummy Classifier (uniform)')\n    print (confusion_matrix(test_labels_in, preds))\n\n    acc_dummy_uni = 100*accuracy_score(test_labels_in,preds)\n    print ('Accuracy percentage of this classifier is %.3f %%\\n' % (acc_dummy_uni))\n    \n    fmac1[0]=f1_score(test_labels_in,preds,average='macro')\n    fmic1[0]=f1_score(test_labels_in,preds,average='micro')\n    fwei1[0]=f1_score(test_labels_in,preds,average='weighted')\n    \n    \n    dc_constant_1 = DummyClassifier(strategy=\"constant\", constant=1)\n    start_time = time.time()\n    model = dc_constant_1.fit(train_in, train_labels_in)\n    xron[1]=(time.time() - start_time)\n    preds = dc_constant_1.predict(test_in)\n    credit_accuracy['constant 1'] = dc_constant_1.score(test_in, test_labels_in)\n\n\n#################\n    print ('Classification report for Dummy Classifier (constant-1)')\n    cr_dummy_const1 = classification_report(test_labels_in, preds,target_names = label_names)\n    print (cr_dummy_const1)\n\n    scores_weighted['Dummy-Const1']=precision_recall_fscore_support(test_labels_in,preds,average='weighted')\n    scores_macro['Dummy-Const1']=precision_recall_fscore_support(test_labels_in,preds,average='macro')\n    scores_micro['Dummy-Const1']=precision_recall_fscore_support(test_labels_in,preds,average='micro')\n\n\n    print ('Confusion Matrix for Dummy Classifier (constant-1)')\n    print (confusion_matrix(test_labels_in, preds))\n\n    acc_dummy_const1 = 100*accuracy_score(test_labels_in,preds)\n    print ('Accuracy percentage of this classifier is %.3f %%\\n' % (acc_dummy_const1))\n    \n    fmac1[1]=f1_score(test_labels_in,preds,average='macro')\n    fmic1[1]=f1_score(test_labels_in,preds,average='micro')\n    fwei1[1]=f1_score(test_labels_in,preds,average='weighted')\n    \n    \n    dc_constant_0 = DummyClassifier(strategy=\"constant\", constant=0)\n    start_time = time.time()\n    model = dc_constant_0.fit(train_in, train_labels_in)\n    xron[2]=(time.time() - start_time)\n    preds = dc_constant_0.predict(test_in)\n    credit_accuracy['constant 0'] = dc_constant_0.score(test_in, test_labels_in)\n\n#################\n    print ('Classification report for Dummy Classifier (constant-0)')\n    cr_dummy_const0 = classification_report(test_labels_in, preds,target_names = label_names)\n    print (cr_dummy_const0)\n\n    scores_weighted['Dummy-Const0']=precision_recall_fscore_support(test_labels_in,preds,average='weighted')\n    scores_macro['Dummy-Const0']=precision_recall_fscore_support(test_labels_in,preds,average='macro')\n    scores_micro['Dummy-Const0']=precision_recall_fscore_support(test_labels_in,preds,average='micro')\n\n    print ('Confusion Matrix for Dummy Classifier (constant-0)')\n    print (confusion_matrix(test_labels_in, preds))\n\n    acc_dummy_const0 = 100*accuracy_score(test_labels_in,preds)\n    print ('Accuracy percentage of this classifier is %.3f %%\\n' % (acc_dummy_const0))\n    \n    fmac1[2]=f1_score(test_labels_in,preds,average='macro')\n    fmic1[2]=f1_score(test_labels_in,preds,average='micro')\n    fwei1[2]=f1_score(test_labels_in,preds,average='weighted')\n    \n    \n    dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n    start_time = time.time()\n    model = dc_most_frequent.fit(train_in, train_labels_in)\n    xron[3]=(time.time() - start_time)\n    preds = dc_most_frequent.predict(test_in)\n    credit_accuracy['most_frequent'] = dc_most_frequent.score(test_in, test_labels_in)\n\n#################\n    print ('Classification report for Dummy Classifier (most frequent)')\n    cr_dummy_freq = classification_report(test_labels_in, preds,target_names = label_names)\n    print (cr_dummy_freq)\n\n    scores_weighted['Dummy-Most_Freq']=precision_recall_fscore_support(test_labels_in,preds,average='weighted')\n    scores_macro['Dummy-Most_Freq']=precision_recall_fscore_support(test_labels_in,preds,average='macro')\n    scores_micro['Dummy-Most_Freq']=precision_recall_fscore_support(test_labels_in,preds,average='micro')\n\n    print ('Confusion Matrix for Dummy Classifier (most frequent)')\n    print (confusion_matrix(test_labels_in, preds))\n\n    acc_dummy_freq = 100*accuracy_score(test_labels_in,preds)\n    print ('Accuracy percentage of this classifier is %.3f %%\\n' % (acc_dummy_freq))\n    \n    fmac1[3]=f1_score(test_labels_in,preds,average='macro')\n    fmic1[3]=f1_score(test_labels_in,preds,average='micro')\n    fwei1[3]=f1_score(test_labels_in,preds,average='weighted')\n    \n    \n    \n    dc_stratified = DummyClassifier(strategy=\"stratified\")\n    start_time = time.time()\n    model = dc_stratified.fit(train_in, train_labels_in)\n    xron[4]=(time.time() - start_time)\n    preds = dc_stratified.predict(test_in)\n    credit_accuracy['stratified'] = dc_stratified.score(test_in, test_labels_in)\n\n#################\n    print ('Classification report for Dummy Classifier (stratified)')\n    cr_dummy_strat = classification_report(test_labels_in, preds,target_names = label_names)\n    print (cr_dummy_strat)\n\n    scores_weighted['Dummy-Strat']=precision_recall_fscore_support(test_labels_in,preds,average='weighted')\n    scores_macro['Dummy-Strat']=precision_recall_fscore_support(test_labels_in,preds,average='macro')\n    scores_micro['Dummy-Strat']=precision_recall_fscore_support(test_labels_in,preds,average='macro')\n\n    print ('Confusion Matrix for Dummy Classifier (stratified)')\n    print (confusion_matrix(test_labels_in, preds))\n\n    acc_dummy_strat = 100*accuracy_score(test_labels_in,preds)\n    print ('Accuracy percentage of this classifier is %.3f %%\\n' % (acc_dummy_strat))\n    \n    fmac1[4]=f1_score(test_labels_in,preds,average='macro')\n    fmic1[4]=f1_score(test_labels_in,preds,average='micro')\n    fwei1[4]=f1_score(test_labels_in,preds,average='weighted')\n    \n    from sklearn.neighbors import KNeighborsClassifier\n    start_time = time.time()\n    knn = KNeighborsClassifier(n_neighbors=num)\n    xron[5]=(time.time() - start_time)\n    knn.fit(train_in, train_labels_in)\n    knn_preds = knn.predict(test_in)\n\n\n#################\n    print ('Classification report for opt kNN')\n    cr_knn_no = classification_report(test_labels_in,knn_preds, target_names=label_names)\n    print (cr_knn_no)\n\n    scores_weighted['kNN-opt']=precision_recall_fscore_support(test_labels_in,knn_preds,average='weighted')\n    scores_macro['kNN-opt']=precision_recall_fscore_support(test_labels_in,knn_preds,average='macro')\n    scores_micro['kNN-opt']=precision_recall_fscore_support(test_labels_in,knn_preds,average='micro')\n\n    print ('Confusion Matrix for optimized kNN')\n    print (confusion_matrix(test_labels_in, knn_preds))\n\n    acc_knn_no = 100*accuracy_score(test_labels_in,knn_preds)\n    print ('\\nAccuracy percentage of this classifier is %.3f %%\\n' % (acc_knn_no))\n    \n    fmac1[5]=f1_score(test_labels_in,knn_preds,average='macro')\n    fmic1[5]=f1_score(test_labels_in,knn_preds,average='micro')\n    fwei1[5]=f1_score(test_labels_in,knn_preds,average='weighted')\n    \n    \n    \n    import matplotlib.pyplot as plt\n\n    f1_scores_macro = [item[2] for item in scores_macro.values()]\n    f1_scores_micro = [item[2] for item in scores_micro.values()]\n    f1_scores_weighted = [item[2] for item in scores_weighted.values()]\n\n\n    y_pos = np.arange(len(f1_scores_macro))\n    plt.barh(y_pos, f1_scores_macro, align='center',color='red')\n    plt.yticks(y_pos, scores_macro.keys())\n    plt.title('F1_macro average scores')\n    plt.show()\n\n    y_pos = np.arange(len(f1_scores_micro))\n    plt.barh(y_pos, f1_scores_micro, align='center',color='yellow')\n    plt.yticks(y_pos, scores_micro.keys())\n    plt.title('F1_micro average scores')\n    plt.show()\n\n    \n    y_pos = np.arange(len(f1_scores_weighted))\n    plt.barh(y_pos, f1_scores_weighted, align='center',color='green')\n    plt.yticks(y_pos, scores_weighted.keys())\n    plt.title('F1_weighted average scores')\n    plt.show()\n    \n    \n    return",
      "execution_count": 119,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "xron=[0,0,0,0,0,0]\nfunction1(train_fin,train_labels,test_fin,test_labels,num1,xron,fwei1,fmac1,fmic1)",
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Classification report for Dummy Classifier (uniform)\n              precision    recall  f1-score   support\n\n Not Granted       0.62      0.56      0.58        72\n     Granted       0.52      0.58      0.54        59\n\n   micro avg       0.56      0.56      0.56       131\n   macro avg       0.57      0.57      0.56       131\nweighted avg       0.57      0.56      0.57       131\n\nConfusion Matrix for Dummy Classifier (uniform)\n[[40 32]\n [25 34]]\nAccuracy percentage of this classifier is 56.489 %\n\nClassification report for Dummy Classifier (constant-1)\n              precision    recall  f1-score   support\n\n Not Granted       0.00      0.00      0.00        72\n     Granted       0.45      1.00      0.62        59\n\n   micro avg       0.45      0.45      0.45       131\n   macro avg       0.23      0.50      0.31       131\nweighted avg       0.20      0.45      0.28       131\n\nConfusion Matrix for Dummy Classifier (constant-1)\n[[ 0 72]\n [ 0 59]]\nAccuracy percentage of this classifier is 45.038 %\n\nClassification report for Dummy Classifier (constant-0)\n              precision    recall  f1-score   support\n\n Not Granted       0.55      1.00      0.71        72\n     Granted       0.00      0.00      0.00        59\n\n   micro avg       0.55      0.55      0.55       131\n   macro avg       0.27      0.50      0.35       131\nweighted avg       0.30      0.55      0.39       131\n\nConfusion Matrix for Dummy Classifier (constant-0)\n[[72  0]\n [59  0]]\nAccuracy percentage of this classifier is 54.962 %\n\nClassification report for Dummy Classifier (most frequent)\n              precision    recall  f1-score   support\n\n Not Granted       0.55      1.00      0.71        72\n     Granted       0.00      0.00      0.00        59\n\n   micro avg       0.55      0.55      0.55       131\n   macro avg       0.27      0.50      0.35       131\nweighted avg       0.30      0.55      0.39       131\n\nConfusion Matrix for Dummy Classifier (most frequent)\n[[72  0]\n [59  0]]\nAccuracy percentage of this classifier is 54.962 %\n\nClassification report for Dummy Classifier (stratified)\n              precision    recall  f1-score   support\n\n Not Granted       0.53      0.50      0.51        72\n     Granted       0.43      0.46      0.44        59\n\n   micro avg       0.48      0.48      0.48       131\n   macro avg       0.48      0.48      0.48       131\nweighted avg       0.48      0.48      0.48       131\n\nConfusion Matrix for Dummy Classifier (stratified)\n[[36 36]\n [32 27]]\nAccuracy percentage of this classifier is 48.092 %\n\nClassification report for opt kNN\n              precision    recall  f1-score   support\n\n Not Granted       0.90      0.92      0.91        72\n     Granted       0.90      0.88      0.89        59\n\n   micro avg       0.90      0.90      0.90       131\n   macro avg       0.90      0.90      0.90       131\nweighted avg       0.90      0.90      0.90       131\n\nConfusion Matrix for optimized kNN\n[[66  6]\n [ 7 52]]\n\nAccuracy percentage of this classifier is 90.076 %\n\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n  'precision', 'predicted', average, warn_for)\n",
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcUAAAEICAYAAAAut+/uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzt3X+cXGV99vHPFSIN2BDABNsNgUgKVgm4kDWIVghSHoEiEkVRUEikDbZGrUjrr2IKgi2opVqUlOKTIAYFQTBBhBRNgiIguySQBMojJEEQHwMIMRgIIfn2j/Ndchhmd2c3uzOT3ev9es2LM+fc59zfc7K7F/c9Z2YUEZiZmRkMa3QBZmZmzcKhaGZmlhyKZmZmyaFoZmaWHIpmZmbJoWhmZpYcimZNRNJbJT1QY9spkh4dwFoG9PhmzcihaEOWpDWSnpX0TOnRktsulfSApC2SptWrpoj4aUS8tj+OJWmupPP641hmQ4VD0Ya6d0TEH5cej+X6e4C/A+5uYG1DnqThja6hPw228xmMHIpmVUTE1yPix8BztbSXNCJHnaPz+T9JekHSLvn8PEn/nst/JOnLkn4l6beSZkvaKbe9ZMpS0sGSlkpaL+l7kq6qHP1J+qSktZJ+I2l6rpsBnAL8Y46AF+T6FknXSnpc0mpJHysdZ6ccXT4l6T7gjT2c81clPSLp95I6JL211MezknYvtT1I0hOSXpHPPyTp/uzrZkl7l9qGpI9I+iXwy+76KtV9eR7rfkn/WHENuzznKud0rKT78nr/WtJZpW3vlLQsa3hI0tGl48+X9DtJD0r6m9I+/yzpGknflvR7YJqkYZI+ncd4UtLVndcqf46+neuflnSXpFd39+9g/cuhaNYPIuI54C7g8Fx1GPAw8JbS8yW5fAGwH9AK/BkwFvh85TEl7QhcB8wFdge+A0ytaPYnwKg8xunA1yXtFhGXAvOAC3ME/A5Jw4AFFKPgscCRwN9LenseaxYwIR9vB07r4bTvynPYHbgS+J6kETnavh14d6ntycA1EbFJ0gnAZ4F3AWOAn+a5lZ0AHAK8vru+SnWPB/YBjgI+0HmQGs650jeBMyJiJDAR+EkeZzLwLeAfgF0p/j3X5D7fAR4FWoATgS9KOrJ0zHcC1+R+84CP5fkdnvs8BXw9255G8e85DngV8GHg2S5qtYEQEX74MSQfFH/UngGezsf1Vdr8DJhW4/G+AHwNGA78f+DjwL8CIyj+sI0GBPwBmFDa71BgdS5PAR7N5cOAXwOqqOe8UttngeGl7WuBN+Xy3M62+fwQ4FcVNX8GmJPLq4CjS9tmdNZS4/k/Bbwhl/8a+EkuC3gEOCyf/wg4vbTfMGADsHc+D+BtvehrFfD20ra/Ll3Dbs+5ynF/BZwB7FKx/j+Bi6q0HwdsBkaW1v0LMDeX/xm4tWKf+4EjS8//FNiUPzcfAn4OHNjo34+h+vBI0Ya6EyJi13ycsI3HWkIRVAcDy4H/phgNvAl4MCKeoBgZ7Qx05PTY08BNub5SC/DryL+c6ZGKNk9GxAul5xuAP+6ivr2Bls5+s+/PAp3Tcy0Vx3+4u5PNadv7Ja3LY42iCH4oRkaHqrhx6TCKoPtpqY6vlmr4HUVwju3qPHvoq7Lu8nJP51zp3cCxwMOSlkg6NNePAx6q0r4F+F1ErC+te7i7c8marivVcz9FsL4auAK4GfiupMckXdg55Wz14Rd9zfrPz4HXUkxxLomI+yTtBfwVW6dOn6AY3e0fEb/u4Xi/AcZKUikYu/rjXE3lV+A8QjEi3beb/sYBK/P5Xl0dOF/T+xTFdOTKiNgi6SmKcCMinpa0EHgv8DrgO6VzeAQ4PyLm1VJ7T31l3XsC9+Xzcb0455d2GnEX8M4MopnA1Xm8RyimlSs9BuwuaWQpGPeiGOG/7FxKNX0oIm7rooxzgHMkjQduBB6gmNa1OvBI0awKSTvma1YCXpE3QHT7+xIRG4AO4CNsDcGfU0zHLck2W4D/Ai6StEf2NbaL17hupxhBzJQ0XNI7gcm9OI3fUrzO1ukXwO8lfSpvTtlB0kRJnTfUXA18RtJukvYEPtrNsUcCLwCPA8MlfR7YpaLNlcCpFKOvK0vrZ2c/+wNIGiXpPdvQV7nusRRhVus5vyj/zU+RNCoiNgG/p7j+UITSdElH5o0yYyX9eUQ8QvFv/C/5M3IgxWu73QX+bOB85c1Fksbkvy2SjpB0gKQdsv9NpRqsDhyKZtUtpBjRvRm4NJcPq2G/JcArKP4Ydz4fCdxaavMp4EHgjrwj8RaKEeZLRMTzFDejnE7xmucHgBuAjTWewzeB1+c03fURsRl4B8UNK6spRq2XUUxFQjFCeTi3LaSYyuvKzRSvDf6/3Oc5Xj5NOB/YF/htRNxTOq/rKG42+m6e/wrgmG3o61yKG11WU1zLa8hrVMM5V/ogsCbr+jB5005E/AKYDlwErKP4d+28Y/b9FDf6PEZxY9SsiPjvbs7nqxTXZqGk9cAdFK99QnHj1DUUgXh/9vPtbo5l/UwvfbnCzJqZpDuB2RExp9G1NCtJfwu8LyIO77GxWQWPFM2amKTDJf1JTp+eBhxIcWOOJUl/KuktOa35WuCTFCM2s15zKJr1gqQf6aUfC9f5+OwAdflaivfYraP4Y39iRPxmgPraXu1I8ZaJ9RTvK/wB8I2GVmTbLU+fmpmZJY8UzczMkt+nuJ0ZPXp0jB8/vtFlmJltVzo6Op6IiGofkvESDsXtzPjx42lvb290GWZm2xVJ3X5CUydPn5qZmSWHopmZWXIompmZJYeimZlZciiamZklh6KZmVlyKJqZmSWHopmZWfJnn25n1KLgjEZXYWZWXzFr27JKUkdEtPXUziNFMzOz5FA0MzNLDkUzM7PkUDQzM0sORTMzs+RQNDMzSw5FMzOz5FA0MzNLDkUzM7PkUDQzM0tDNhQljZe0omLdFEkh6R2ldTdImpLLiyW1l7a1SVrcT/VMkfTm/jiWmZn1zZANxW48Cnyum+17SDpmAPqdAjgUzcwayKEISNpH0lLgjcA9wDpJR3XR/EvAP9VwzFZJd0i6V9J1knbL9Ysl/bukn0taIWmypPHAh4FPSFom6a39cmJmZtYrQz4UJb0WuBaYDtyVq8+j6+C7Hdgo6YgeDv0t4FMRcSCwHJhV2vbKiHgz8HfA/42INcBs4KKIaI2In1bUOENSu6R2NvTi5MzMrFeGeiiOAX4AfCAilnWu7AylbkZs3YUmkkYBu0bEklx1OXBYqcl3sp9bgV0k7dpdkRFxaUS0RUQbO/dwRmZm1mdDPRTXAY8Ab6my7Xy6eG0xIn4CjADe1LlO0pyc+ryxhn4rvxjMX2ppZtYEhnooPg+cAJwq6eTyhohYCOwGvKGLfc8H/rHUfnpOfR4bEeuAp0ojzQ8CS0r7ngQg6S+Addl+PTCyH87JzMz6aKiHIhHxB+A44BPAqIrN5wN7drHfjcDj3Rz6NOBLku4FWoFzS9uekvRzitcRT891C4CpvtHGzKxxFOGZu3rK9zWeFRHtPbWtun+LgjP6tyYzs2YXs7YtqyR1RERbT+2G/EjRzMys0/BGFzDURMSURtdgZmbVeaRoZmaWHIpmZmbJoWhmZpYcimZmZsmhaGZmlhyKZmZmyW/J2M5MaplE+6w+ve/fzMx64JGimZlZciiamZklh6KZmVlyKJqZmSWHopmZWfJXR21n/NVRtr3Y1q/6MetP/uooMzOzXnIompmZJYeimZlZciiamZklh6KZmVlyKJqZmSWHopmZWXIompmZJYeimZlZciiamZmlpgpFSZslLZO0UtI9ks6U1FQ1AkgaJulrklZIWi7pLkmvyW2f7eMx/17Szv1bqZmZ9UazBc6zEdEaEfsDRwHHArMaXFM1JwEtwIERcQAwFXg6t1UNRRW6u95/DzgUzcwaqNlC8UURsRaYAczMQJkm6eLO7ZJukDQll5+RdIGkDkm3SJosabGkVZKOzzbTJF0vaYGk1ZJm5kh0qaQ7JO0uaYKku0t97Cupo0p5fwr8JiK2ZK2PRsRTkv4V2ClHu/MkjZd0v6RvAHcD4yRdIqk9R8PnZD8fowjZRZIWDcT1NDOznjVtKAJExCqKGvfooekrgcURMQlYD5xHMdKcCpxbajcROBmYDJwPbIiIg4DbgVMj4iFgnaTWbD8dmFulv6uBd2T4fUXSQVnvp9k62j0l274W+FZEHBQRDwOfy09qPxA4XNKBEfE14DHgiIg4orIzSTMySNvZ0MOVMDOzPmvqUEyqoc3zwE25vBxYEhGbcnl8qd2iiFgfEY8D64AFpX06210GTJe0A8U06ZWVnUXEoxRh9xlgC/BjSUd2UdvDEXFH6fl7czS6FNgfeH1PJxcRl0ZEW0S0eYLVzGzgNHUoStoH2AysBV7gpfWOKC1viq1fDLkF2AiQ05vDS+02lpa3lJ6X210LHAMcB3RExJOSDslR4bLO6diI2BgRP4qIfwC+CJzQxWn8oXQ+rwHOAo6MiAOBH1ach5mZNVDThqKkMcBs4OIMvDVAa975OY5iCrTfRcRzwM3AJcCcXHdnTom2RsR8SQdLask6h1FMhT6ch9gk6RVdHH4XipBcJ+nVFOHbaT0wsv/PyMzMajW85yZ1tZOkZcArKEaGVwD/lttuA1ZTTHWuoLhxZaDMA94FLOxi+x7Af0n6o3z+C6DzJqBLgXtzivRz5Z0i4h5JS4GVwCqKc6K0348k/aba64pmZjbwtHXW0TpJOgsYFRFnN7qWSmpRcEajqzDrWczy3xZrHpI68ibHbjXbSLHhJF0HTADe1uhazMysvhyKFSJiaqNrMDOzxmjaG23MzMzqzaFoZmaWHIpmZmbJoWhmZpYcimZmZsmhaGZmlvyWjO3MpJZJtM9qb3QZZmaDkkeKZmZmyaFoZmaWHIpmZmbJoWhmZpYcimZmZslfHbWd8VdHWS38tU1mL1XrV0d5pGhmZpYcimZmZsmhaGZmlhyKZmZmyaFoZmaWHIpmZmbJoWhmZpYcimZmZsmhaGZmlhyKZmZmyaFoZmaWegxFSZslLZO0UtI9ks6U1HRhKmm8pJD0hdK60ZI2Sbq4D8drlXRsD22mSXo8r88ySd/qS+1mZtYcagm3ZyOiNSL2B44CjgVmDWxZfbYKOK70/D3Ayj4eq5XiXHtyVV6f1og4tXKjpOF97N/MzOqsVyO+iFgLzABmqjCtPAqTdIOkKbn8jKQLJHVIukXSZEmLJa2SdHy2mSbpekkLJK2WNDNHoksl3SFpd0kTJN1d6mNfSR1dlPgscL+kzk9CPwm4urTv3pJ+LOne/O9euf49klbkSPhWSTsC5wIn5QjwpN5cpzzPL0paAnxc0hhJ10q6Kx9vyXavkrQwz/c/JT0saXSV482Q1C6pnQ29qcTMzHqj19OgEbEq99ujh6avBBZHxCRgPXAexUhzKkXgdJoInAxMBs4HNkTEQcDtwKkR8RCwTlJrtp8OzO2m3+8C75O0J7AZeKy07WLgWxFxIDAP+Fqu/zzw9oh4A3B8RDyf6zpHgVd1019ncC6TNL20fteIODwivgJ8FbgoIt4IvBu4LNvMAn6W5zsf2KtaBxFxaUS0RUQbO3dTiZmZbZO+Tu2phjbPAzfl8nJgY0RskrQcGF9qtygi1gPrJa0DFpT2OTCXLwOmSzqTYvQ3uZt+bwK+APwWqAyzQ4F35fIVwIW5fBswV9LVwPdrOLeyqyJiZrX1peW/BF4vvXjZdpE0Ejiss56I+KGkp3rZt5mZ9aNejxQl7UMxAlsLvFBxjBGl5U2x9RuMtwAbASJiCy8N442l5S2l5+V21wLHULxe2BERT0o6pDRCO77zADnK6wA+mft1J3KfDwP/BIwDlkl6VQ/71eIPpeVhwKGl1x7H5v8IvFiDmZk1Xq9CUdIYYDZwcQbeGqBV0jBJ4+h+BNdnEfEccDNwCTAn191ZCpn5Fbt8BfhURDxZsf7nwPty+RTgZwCSJuTxPg88QRGO64GR/XQKC4EXR5OlqeBbsw4kHQPs1k/9mZlZH9QSijt1viUDuIXiD/w5ue02YDXFVOeXgburH6JfzKMYVS3sqWFErIyIy6ts+hjFNOy9wAeBj+f6L0laLmkFRVDdAyyimPLs9Y02XfTbljf43Ad8ONefAxyWNxL9H+BX29iPmZltA22d4Wxuks4CRkXE2Y2uZaBIWgO0RcQTXbZpUXBG/Wqy7VPM2j5+r83qRVJHRLT11G67eA+dpOuACcDbGl2LmZkNXttFKEbE1Eb2n2+1+HjF6tsi4iP92U9EjO/P45mZWe9sF6HYaBExh7zBx8zMBq+m+wxTMzOzRnEompmZJYeimZlZciiamZkl32iznZnUMon2We2NLsPMbFDySNHMzCw5FM3MzJJD0czMLDkUzczMkkPRzMwsbTffkmEFf0uG1cLfkmH2UrV+S4ZHimZmZsmhaGZmlhyKZmZmyaFoZmaWHIpmZmbJoWhmZpYcimZmZsmhaGZmlhyKZmZmyaFoZmaW6hKKkjZLWiZppaR7JJ0pqSkDWdJ+km6U9KCk+yVdLenV/Xj8aZJaSs9fI+lOSb+UdJWkHfurLzMz6516BdOzEdEaEfsDRwHHArPq1HfNJI0AfghcEhF/FhGvAy4BxvRjN9OAltLzC4CLImJf4Cng9H7sy8zMeqHuo7WIWAvMAGaqME3SxZ3bJd0gaUouPyPpAkkdkm6RNFnSYkmrJB2fbaZJul7SAkmrJc3MkehSSXdI2l3SBEl3l/rYV1JHlfJOBm6PiAWlehdFxApJIyTNkbQ8j31Eqf/vS7opR3sX5vodJM2VtCL3+YSkE4E2YF6OnHcC3gZck91dDpzQbxfbzMx6pSFTmBGxKvveo4emrwQWR8QkYD1wHsVIcypwbqndRIpAmwycD2yIiIOA24FTI+IhYJ2k1mw/HZhbpb+JQLWwBPhI1n4A8H7g8hxZArQCJwEHACdJGpfrxkbExNxnTkRcA7QDp0REa57f0xHxQh7nUWBsZceSZkhql9TOhi6qMzOzbdbI1/VUQ5vngZtyeTmwJCI25fL4UrtFEbE+Ih4H1gELSvt0trsMmC5pB4oAu7KX9f4FcAVARPwP8DCwX277cUSsi4jngPuAvYFVwD6S/kPS0cDvqxyz2jV42Xf+RMSlEdEWEW3s3MuqzcysZg0JRUn7AJuBtcALFXWMKC1viq1f+LgF2AgQEVuA4aV2G0vLW0rPy+2uBY4BjgM6IuJJSYfkNOaynI5dCUzqquxuTqnc/2ZgeEQ8BbwBWEwxyrysyn5PALtK6qxxT+CxbvoxM7MBVPdQlDQGmA1cnIG3BmiVNCynHScPRL85iruZ4saZObnuzrwBqDUi5lOMHt8s6a9K9R4t6QDgVuCUXLcfsBfwQFf9SRoNDIuIa4GzgYNz03pgZPYfwCLgxNx2GvCD/jljMzPrrXqF4k6db8kAbgEWAufkttuA1RRTnV8G7q5+iH4xj2J6cmG1jRHxLMVI8qN508x9FHeLrgW+AewgaTlwFTAtIjZWO04aCyyWtIzi9cvP5Pq5wOzSjTafAs6U9CDwKuCb23SGZmbWZ9o6Ozn4SToLGBURZze6lr5Si4IzGl2FNbuYNXR+r81qIakjItp6aje8pwaDhaTrgAkUb4EwMzN7mSETihExtdE1mJlZc2vKj1ozMzNrBIeimZlZciiamZklh6KZmVlyKJqZmSWHopmZWRoyb8kYLCa1TKJ9VnujyzAzG5Q8UjQzM0sORTMzs+RQNDMzSw5FMzOz5FA0MzNLDkUzM7M0pL5PcTDw9yk2D39nodn2o9bvU/RI0czMLDkUzczMkkPRzMwsORTNzMySQ9HMzCw5FM3MzJJD0czMLDkUzczMkkPRzMws1SUUJW2WtEzSSkn3SDpTUlMGsqT9JN0o6UFJ90u6WtKr+/H40yS1lJ7PzL5C0uj+6sfMzHqvXsH0bES0RsT+wFHAscCsOvVdM0kjgB8Cl0TEn0XE64BLgDH92M00oKX0/DbgL4GH+7EPMzPrg7qP1iJiLTADmKnCNEkXd26XdIOkKbn8jKQLJHVIukXSZEmLJa2SdHy2mSbpekkLJK3OkdeZkpZKukPS7pImSLq71Me+kjqqlHcycHtELCjVuygiVkgaIWmOpOV57CNK/X9f0k2Sfinpwly/g6S5klbkPp+QdCLQBszLkfNOEbE0Itb093U2M7Pea8gUZkSsyr736KHpK4HFETEJWA+cRzHSnAqcW2o3kSLQJgPnAxsi4iDgduDUiHgIWCepNdtPB+ZW6W8iUC0sAT6StR8AvB+4PEeWAK3AScABwEmSxuW6sRExMfeZExHXAO3AKTlyfraH8wdA0gxJ7ZLa2VDLHmZm1heNfF1PNbR5Hrgpl5cDSyJiUy6PL7VbFBHrI+JxYB2woLRPZ7vLgOmSdqAIsCt7We9fAFcARMT/UEx37pfbfhwR6yLiOeA+YG9gFbCPpP+QdDTw+17296KIuDQi2iKijZ37ehQzM+tJQ0JR0j7AZmAt8EJFHSNKy5ti63dbbQE2AkTEFmB4qd3G0vKW0vNyu2uBY4DjgI6IeFLSITmNuSynY1cCk7oqu5tTKve/GRgeEU8BbwAWU4wyL+tmfzMzawJ1D0VJY4DZwMUZeGuAVknDctpx8kD0m6O4mylunJmT6+7MaczWiJhPMXp8s6S/KtV7tKQDgFuBU3LdfsBewANd9Zd3kg6LiGuBs4GDc9N6YGR/n5+ZmW27eoXiTp1vyQBuARYC5+S224DVFFOdXwburn6IfjEPiOz/ZfI1vuOAj+ZNM/dR3C26FvgGsIOk5cBVwLSI2FjtOGkssFjSMorXLz+T6+cCsztvtJH0MUmPAnsC90ryiNLMrEG0dXZy8JN0FjAqIs5udC19pRYFZzS6CgOIWUPnd8dseyepIyLaemo3vKcGg4Wk64AJwNsaXYuZmTWnIROKETG10TWYmVlza8qPWjMzM2sEh6KZmVlyKJqZmSWHopmZWXIompmZJYeimZlZGjJvyRgsJrVMon1We6PLMDMblDxSNDMzSw5FMzOz5FA0MzNLDkUzM7PkUDQzM0sORTMzszSkvk9xMPD3KZp1z99zadXU+n2KHimamZklh6KZmVlyKJqZmSWHopmZWXIompmZJYeimZlZciiamZklh6KZmVlyKJqZmaV+DUVJmyUtk7RS0j2SzpTUdMEraYqkGyrWzZV0Yg/7HS/p07k8RtKdkpZKeutA1mtmZvUxvJ+P92xEtAJI2gO4EhgFzOrnfhoiIuYD8/PpkcD/RMRpte4vaYeI2DwgxZmZ2TYbsFFcRKwFZgAzVZgm6eLO7ZJukDQll5+RdIGkDkm3SJosabGkVZKOzzbTJF0vaYGk1ZJm5kh0qaQ7JO0uaYKku0t97Cupo7e1S1oj6RxJd0taLunPSzVcLKkVuBA4NkfGO0l6f7ZdIemC0rGekXSupDuBQ/PYX5R0u6R2SQdLulnSQ5I+3LerbWZm/WFApzYjYlX2sUcPTV8JLI6IScB64DzgKGAqcG6p3UTgZGAycD6wISIOAm4HTo2Ih4B1GVoA04G5fSz/iYg4GLgEOKvivJYBnweuypHxbsAFwNuAVuCNkk4onduKiDgkIn6W6x6JiEOBn2Z9JwJvqjjXF0makQHazoY+no2ZmfWoHq/3qYY2zwM35fJyYElEbMrl8aV2iyJifUQ8DqwDFpT26Wx3GTBd0g7ASRRTuJW6+hj98vrv5387Kmqo5o0Uof54RLwAzAMOy22bgWsr2ndOwS4H7iyd03OSdn1ZURGXRkRbRLSxcw+VmJlZnw1oKErahyIU1gIvVPQ3orS8KbZ+h9UWYCNARGzhpa97biwtbyk9L7e7FjgGOA7oiIgnJR2S05zLcjr2SYrRXdnuwBNV+tpMz6+9dhf8z1V5HbFcd+U59ffrvGZmVqMBC0VJY4DZwMUZeGuAVknDJI2jmALtdxHxHHAzxbTnnFx3Z0S05mM+8EugRdLrsta9gTcAy/rY7Z3A4ZJG5wj1/cCSbTwVMzOrs/4elewkaRnwCoqR4RXAv+W224DVFFOGK4C7qx6hf8wD3gUsrLYxIjZK+gAwR9IIYBPw1xGxri+dRcRvJH0GWEQxarwxIn7Qt9LNzKxRtHXWcvCQdBYwKiLObnQt/U0tCs5odBVmzStmDb6/abbtJHVERFtP7Qbd61eSrgMmUNwJamZmVrNBF4oRMbXRNZiZ2fap6T6CzczMrFEcimZmZsmhaGZmlhyKZmZmyaFoZmaWHIpmZmZp0L0lY7Cb1DKJ9lntjS7DzGxQ8kjRzMwsORTNzMySQ9HMzCw5FM3MzJJD0czMLDkUzczMkkPRzMwsORTNzMySQ9HMzCwpIhpdg/WCpPXAA42uo0mNBp5odBFNytema7421Q2267J3RIzpqZE/5m3780BEtDW6iGYkqd3Xpjpfm6752lQ3VK+Lp0/NzMySQ9HMzCw5FLc/lza6gCbma9M1X5uu+dpUNySvi2+0MTMzSx4pmpmZJYeimZlZcig2KUlHS3pA0oOSPl1l+x9Juiq33ylpfP2rbIwars2Zku6TdK+kH0vauxF1NkJP16bU7kRJIWlI3HJfy3WR9N78uVkp6cp619goNfw+7SVpkaSl+Tt1bCPqrJuI8KPJHsAOwEPAPsCOwD3A6yva/B0wO5ffB1zV6Lqb6NocAeycy3/ra/OydiOBW4E7gLZG190M1wXYF1gK7JbP92h03U10bS4F/jaXXw+saXTdA/nwSLE5TQYejIhVEfE88F3gnRVt3glcnsvXAEdKUh1rbJQer01ELIqIDfn0DmDPOtfYKLX83AB8AbgQeK6exTVQLdflb4CvR8RTABGxts41Nkot1yaAXXJ5FPBYHeurO4dicxoLPFJ6/miuq9omIl4A1gGvqkt1jVXLtSk7HfjRgFbUPHq8NpIOAsZFxA31LKzBavmZ2Q/YT9Jtku6QdHTdqmusWq7NPwMfkPQocCPw0fqU1hj+mLfmVG3EV/nemVraDEY1n7ekDwBtwOEDWlHz6PbaSBoGXARMq1dBTaKWn5nhFFOoUyhmFn4qaWJEPD3AtTVaLdfm/cDciPiKpEM352tcAAABZklEQVSBK/LabBn48urPI8Xm9CgwrvR8T14+ZfFiG0nDKaY1fleX6hqrlmuDpL8EPgccHxEb61Rbo/V0bUYCE4HFktYAbwLmD4GbbWr9ffpBRGyKiNUUH7q/b53qa6Rars3pwNUAEXE7MILiw8IHJYdic7oL2FfSayTtSHEjzfyKNvOB03L5ROAnka+ED3I9XpucIvxPikAcKq8NQQ/XJiLWRcToiBgfEeMpXm89PiLaG1Nu3dTy+3Q9xQ1aSBpNMZ26qq5VNkYt1+ZXwJEAkl5HEYqP17XKOnIoNqF8jXAmcDNwP3B1RKyUdK6k47PZN4FXSXoQOBPo8vb7waTGa/Ml4I+B70laJqnyl3xQqvHaDDk1XpebgScl3QcsAv4hIp5sTMX1U+O1+STwN5LuAb4DTBvM/wPuj3kzMzNLHimamZklh6KZmVlyKJqZmSWHopmZWXIompmZJYeimZlZciiamZml/wUGb6Me4Ax9zwAAAABJRU5ErkJggg==\n",
            "text/plain": "<Figure size 432x288 with 1 Axes>"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Αρχικά παρατηρούμε ότι ο Dummy Classifier δεν έχει βελτιωθεί καθόλου , που ηταν και αναμενόμενο\nΣτη συνέχεια παρατηρούμε μια βελτίωση της τάξης του 20% στον kNN που είναι μια αισθητή μεταβολή"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"Ο χρόνος για κάθε fit φαίνεται στον παρακάτω πίνακα ξεκινώντας απο τον:\\n\")\nprint('Dummy-Uniform            ',xron[0],'sec\\n')\nprint('Dummy-Const1             ',xron[1],'sec\\n')\nprint('Dummy-Const0             ',xron[2],'sec\\n')\nprint('Dummy-Most_Freq          ',xron[3],'sec\\n')\nprint('Dummy-Strat              ',xron[4],'sec\\n')\nprint('kNN-opt                  ',xron[5],'sec\\n')",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Ο χρόνος για κάθε fit φαίνεται στον παρακάτω πίνακα ξεκινώντας απο τον:\n\nDummy-Uniform             0.006105899810791016 sec\n\nDummy-Const1              0.0007739067077636719 sec\n\nDummy-Const0              0.0011639595031738281 sec\n\nDummy-Most_Freq           0.0019199848175048828 sec\n\nDummy-Strat               0.0008587837219238281 sec\n\nkNN-opt                   3.6716461181640625e-05 sec\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Αντίστοιχα με την αποπάνω σειρά εμφανίζεται η διαφορά στην απόδοση πριν και μετα την βελτιστοποιηση για τις μετρικες\n* f1-macro\n* f1_micro\n* f1_weighted"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "for i in range(6):\n    print(fmac1[i]-fmac[i],'\\n')\n    print(fmic1[i]-fmic[i],'\\n')\n    print(fwei1[i]-fwei[i],'\\n')\n    print('--------------------')",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": "0.029619657881539974 \n\n0.030918617809905014 \n\n0.036981226593921335 \n\n--------------------\n-0.1398553635998393 \n\n0.1706709521896344 \n\n-0.030815588589795107 \n\n--------------------\n-0.19493851765502201 \n\n0.15974128530064302 \n\n0.03519723235437899 \n\n--------------------\n-0.19493851765502201 \n\n0.15974128530064302 \n\n0.03519723235437899 \n\n--------------------\n0.012805477590861258 \n\n0.014140908522087436 \n\n0.018895364427838568 \n\n--------------------\n0.19732678190167008 \n\n0.2020078848823652 \n\n0.20703152884379872 \n\n--------------------\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Φαίνεται και εδώ ότι οι μεγάλες βελτιώσεις ειναι στη τελευταία περίπτωση , οι υπόλοιπες μικροαλλαγές στηρίζονται στη τυχαιότητα του dummy"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "O χρόνος εκτέλεσης του kNN έχει διαφόρα καθώς λαμβάνεται υπόψη η υπερπαράμετρος n_neighbors "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Για τις υπόλοιπες μετρικές σχολιάζουμε παραπάνω τα αναμενόμενα αποτελέσματα , όταν προκύπτει η τελική αρχιτεκτονική ."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}